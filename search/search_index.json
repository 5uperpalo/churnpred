{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Churn prediction assignment for EcoVadis","text":"<p>Main purpose of this library is to provide solution for an asisgnemnt in the interview process of EcoVadis.</p> <pre><code>In this assignment you're tasked with developing a machine learning solution for churn prediction to identify which customers are likely to leave a service (column \"Exited\" in the attached dataset). This assignment is meant to assess\n\n- analytical skills and reasoning\n- design and modelling choices, e.g. choices with respect to measuring model performance\n- coding skills, e.g. modularity, readability, reproducibility, any other best practices in software development\n\nPlease note that multiple solutions may exist and we do not expect a production ready solution, though any reflections on how you may wish to productionalise your solution are welcome. You are free to choose the medium (e.g., notebooks, python scripts). \n\nPlease return your solution by May 2 (9am CET). Once returned, our colleagues with the HR department will schedule the final interview where you'll be asked to walk us through your solution and reflect on any decisions made.\n\nAdditional explanation of independent variables:\n\nNumberOfProducts - the number of accounts and bank-affiliated products \nHasCreditCard - whether a customer has a credit card\nCustomerFeedback - latest customer feedback, if available\n</code></pre>"},{"location":"index.html#solution","title":"Solution","text":"<p>Please see the Notebooks section. The notebooks are sorted from 0 to 5. Notebooks start with gathering auxiliary data that I could extract from the provided dataset, e.g. 'country origin of the surname'. This is followed by Exploratory Data Analysis of features and target in the notebooks 2, 3. In the notebook 4, I presented a <code>Trainer</code> object that handles training an hyperparameter search of the model. In the notebook 5 I made a quick analysis of the model and it's predictions using SHAP values.</p> <p>The final solution uses LightGBM, a GBM model of my choice. I chose GBM as 4 out of top 5 models in H2O AutoML were GBMs.</p>"},{"location":"index.html#additional-work-note-mentioning","title":"Additional work note mentioning","text":"<p>In notebook <code>00_auxiliary_features_surname_origin_country_classification.ipynb</code> I adjusted(copy/paste+adjust) a BERT model for surname origin prediction. Due to lack of time I could not gather additional data that would help with model training, but I left some ideas in the notebook.</p> <p>The solution was tested in a virtual machine, spawned from <code>jupyter/datascience-notebook:python-3.10</code> image in Zero-to-JupyterHub solution. As the bare metal server with GPU was down in the kubernetes, I had to do additional troubleshooting and fixing.</p> <p>The code is easily extendable to <code>multiclass</code>, <code>regression</code> and <code>quantile_regression</code> tasks.</p>"},{"location":"cicd.html","title":"CI/CD","text":"<p>This section includes some ideas for model developmnet and deployment within Azure services - i.e. EcoVadis cloud services vendor.</p> <ul> <li>MLFlow for experiment tracking and endpoint deployment</li> <li>https://mlflow.org/docs/1.25.1/python_api/mlflow.azureml.html</li> <li>https://mlflow.org/docs/latest/deployment/index.html</li> <li>https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-mlflow-models-online-endpoints?view=azureml-api-2&amp;tabs=mlflow</li> <li>DVC for dataset versioning </li> <li>python api: https://dvc.org/doc/api-reference</li> <li>Dataset storage in Azure Blob Storage<ul> <li>https://dvc.org/doc/user-guide/data-management/remote-storage/azure-blob-storage#microsoft-azure-blob-storage </li> </ul> </li> <li>Dataset and predictions(dev) visualization from Azure Blob Storage<ul> <li>https://learn.microsoft.com/en-us/azure/data-explorer/azure-data-explorer-dashboards</li> <li>https://learn.microsoft.com/en-us/azure/data-explorer/create-event-grid-connection?tabs=portal-adx%2Cazure-blob-storage</li> </ul> </li> <li>Data handling in PROD</li> <li>databricks: https://learn.microsoft.com/en-us/azure/databricks/getting-started/data-pipeline-get-started</li> <li>create and share dashboards within organization: https://learn.microsoft.com/en-us/azure/databricks/sql/get-started/sample-dashboards</li> </ul>"},{"location":"code_profiling.html","title":"Code profiling","text":"<p>his section incldues some ideas for code profiling - i.e. CO2, RAM, CPU, GPU tracking.</p>"},{"location":"code_profiling.html#carbon-emission-monitoring","title":"Carbon emission monitoring:","text":"<ul> <li>https://mlco2.github.io/codecarbon/usage.html#</li> <li>https://github.com/sb-ai-lab/Eco2AI</li> <li>https://github.com/lfwa/carbontracker</li> </ul>"},{"location":"code_profiling.html#ram-usage-profiling-and-code-execution-timing","title":"RAM usage profiling and Code execution timing","text":""},{"location":"code_profiling.html#ram-usage-profiling","title":"RAM usage profiling","text":"Max RAM used  To get max RAM used during executition of the function import the decorator and put it above it function to log max RAM used into specified logging file, e.g.: **NOTE**: this applies only to functions and NOT classes or class methods. In case somebody figures out how to use it also on methods please let me know[Pavol Mulinka]. Posts relevant to the issue I was unable to debug: * https://stackoverflow.com/questions/75409483/why-do-i-get-missing-required-argument-self-when-using-a-decorator-written-as * https://stackoverflow.com/questions/16593246/how-to-use-memory-profiler-python-module-with-class-methods <pre><code>from churn_pred.code_profiling import ram_usage\n\n@ram_usage\ndef training(config: TrainingConfig, custom_params: CustomParameters):\n</code></pre> Per line RAM usage analysis To analyze RAM usage per line of the code import profile decorator, put it above the function you want to analyze:  <pre><code>from memory_profiler import profile\n\n@profile\ndef training(config: TrainingConfig, custom_params: CustomParameters):\n</code></pre>  , run the code using memory_profile command line util, and analyze the RAM usage, e.g.:  <pre><code>$ python -m memory_profiler local_run.py\n\nFilename: /XXX/main.py\n\nLine #    Mem usage    Increment  Occurrences   Line Contents\n=============================================================\n    53    230.8 MiB    230.8 MiB           1   @ram_usage\n    54                                         @profile\n    55                                         def training(config: TrainingConfig, custom_params: CustomParameters):\n    56    230.9 MiB      0.1 MiB           1       data_config = DataConfig.load(config.data_config)\n    57    230.9 MiB      0.0 MiB           1       hyperparameters = Hyperparameters.parse_obj(config.hyperparameters)\n    58                                         \n    59    687.5 MiB    456.6 MiB           1       queries, df_data = get_data(config, custom_params)\n    60    687.5 MiB      0.0 MiB           1       (\n</code></pre>"},{"location":"code_profiling.html#code-execution-timing","title":"Code Execution timing","text":"Timer decorator Import and prepend the time decorator to log time(into specified log file) that it takes to execute analyzed function/class, e.g.:  <pre><code>from churn_pred.code_profiling import timer\n\n@timer\ndef training(config: TrainingConfig, custom_params: CustomParameters):\n</code></pre>"},{"location":"contributing.html","title":"Code","text":"<p>Before making a pushing a code and making a pull request please run codestyle checks and tests</p> <pre><code>./code_style.sh\npytest --doctest-modules churn_pred --cov-report xml --cov-report term --disable-pytest-warnings --cov=eda tests/\n</code></pre>"},{"location":"contributing.html#documentation","title":"Documentation","text":"<p>Documentation is created using github pages and mkdocs, see</p> <pre><code># to build locally\ncd docs\npip install -r requirements.txt\nmkdocs build\n# to push to github pages\nmkdocs gh-deploy\n# if you want to run webserver locally\nmkdocs serve\n</code></pre>"},{"location":"installation.html","title":"Installation","text":""},{"location":"installation.html#install-using-pip-directly-from-github","title":"Install using pip directly from github:","text":"<pre><code>pip install git+https://github.com/5uperpalo/churn_pred.git\n</code></pre>"},{"location":"installation.html#locally","title":"Locally","text":"<pre><code>git clone https://github.com/5uperpalo/churn_pred.git\ncd churn_pred\npip install .\n</code></pre>"},{"location":"installation.html#additional-reqs-on-a-newly-spawned-machine","title":"Additional reqs on a newly spawned machine","text":"<p>H20 AutoML requires JRE and language models are faster on GPU.</p> <pre><code>sudo apt install nvidia-utils-535\nsudo apt install openjdk-17-jdk\n</code></pre>"},{"location":"churn_pred/code_profiling.html","title":"Code profiling","text":""},{"location":"churn_pred/code_profiling.html#churn_pred.code_profiling.ram_usage","title":"<code>ram_usage(func)</code>","text":"<p>Wrapper to monitor and log RAM usage during the function execution. NOTE: can be applied to function but not to method of a class. Parameters:     func: function</p> Source code in <code>churn_pred/code_profiling.py</code> <pre><code>def ram_usage(func):\n    \"\"\"Wrapper to monitor and log RAM usage during the function execution.\n    NOTE: can be applied to function but not to method of a class.\n    Parameters:\n        func: function\n    \"\"\"\n\n    @wraps(func)\n    def ram_usage_func(*args, **kwargs):\n        ram, value = memory_usage(\n            (func, args, *kwargs), interval=1.0, retval=True, max_usage=True\n        )\n        logging.info(\n            f\"Finished {func.__name__,}. Max RAM used {(ram / 1000):.4f} GB.\"\n        )  # noqa\n        return value\n\n    return ram_usage_func\n</code></pre>"},{"location":"churn_pred/code_profiling.html#churn_pred.code_profiling.timer","title":"<code>timer(func)</code>","text":"<p>Wrapper to time and log the function execution. Parameters:     func: function</p> Source code in <code>churn_pred/code_profiling.py</code> <pre><code>def timer(func):\n    \"\"\"Wrapper to time and log the function execution.\n    Parameters:\n        func: function\n    \"\"\"\n\n    @wraps(func)\n    def timer_func(*args, **kwargs):\n        start_time = time()\n        value = func(*args, **kwargs)\n        end_time = time()\n        logging.info(\n            f\"Finished {func.__name__} in {(end_time - start_time):.4f} seconds.\"  # noqa\n        )\n        return value\n\n    return timer_func\n</code></pre>"},{"location":"churn_pred/eda.html","title":"Preprocess data","text":""},{"location":"churn_pred/eda.html#churn_pred.eda.features.analysis.entropy","title":"<code>entropy(df, scale='linear', plot=False)</code>","text":"<p>Procedure to plot features sorted by their entropy.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>dataset</p> required <code>scale</code> <code>str</code> <p>y scale of the plot</p> <code>'linear'</code> <code>plot</code> <code>bool</code> <p>whether to output the plot</p> <code>False</code> <p>Returns:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>plot with sorted entropy of the features</p> Source code in <code>churn_pred/eda/features/analysis.py</code> <pre><code>def entropy(\n    df: pd.DataFrame, scale: Literal[\"log\", \"linear\"] = \"linear\", plot: bool = False\n) -&gt; Tuple[pd.DataFrame, Figure]:\n    \"\"\"Procedure to plot features sorted by their entropy.\n\n    Args:\n        df (DataFrame): dataset\n        scale (str): y scale of the plot\n        plot (bool): whether to output the plot\n\n    Returns:\n        fig (Figure): plot with sorted entropy of the features\n    \"\"\"\n    data = df.copy()\n\n    data = data.astype(str)\n    col_entropies = data.apply(entropy_calc, axis=0)\n    col_entropies.sort_values(ascending=False, inplace=True)\n\n    if plot:\n        fig, ax = plt.subplots(figsize=(10, 5))\n        bar_plot(\n            col_entropies.dropna(), ax, title=\"Features entropies (NA are dropped)\"\n        )\n    else:\n        fig = None\n    ax.set_yscale(scale)\n    return col_entropies, fig\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.features.analysis.init_check","title":"<code>init_check(df, identifier=None, cat_cols=None, cont_cols=None, verbose=False)</code>","text":"<p>Procedure to check: * duplicated rows in teh dataset * general stats of numerical features * general stats of categorical features</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pandas dataframe</p> required <code>identifier</code> <code>str</code> <p>column which identifies unique user IDs</p> <code>None</code> <code>cat_cols</code> <code>list</code> <p>categorical features in the dataset</p> <code>None</code> <code>cont_cols</code> <code>list</code> <p>numerical features in the dataset</p> <code>None</code> <p>Returns:</p> Name Type Description <code>duplicated_ids</code> <code>int</code> <code>cont_cols_desc</code> <code>DataFrame</code> <code>cat_cols_desc</code> <code>DataFrame</code> Source code in <code>churn_pred/eda/features/analysis.py</code> <pre><code>def init_check(\n    df: pd.DataFrame,\n    identifier: Optional[str] = None,\n    cat_cols: Optional[list] = None,\n    cont_cols: Optional[list] = None,\n    verbose: bool = False,\n) -&gt; Tuple[int, pd.DataFrame, pd.DataFrame]:\n    \"\"\"Procedure to check:\n    * duplicated rows in teh dataset\n    * general stats of numerical features\n    * general stats of categorical features\n\n    Args:\n        df (DataFrame): pandas dataframe\n        identifier (str): column which identifies unique user IDs\n        cat_cols (list): categorical features in the dataset\n        cont_cols (list): numerical features in the dataset\n\n    Returns:\n        duplicated_ids (int):\n        cont_cols_desc (pd.DataFrame):\n        cat_cols_desc (pd.DataFrame):\n    \"\"\"\n    data = df.copy()\n\n    if identifier:\n        duplicated_ids = data[identifier].duplicated().sum()\n        if verbose:\n            print(\"[CHECK] Number of duplicated ids: {}\".format(duplicated_ids))\n\n    if cont_cols:\n        cont_cols_f = intsec(data.columns.values, cont_cols)\n        cont_cols_desc = data[cont_cols_f].describe().transpose()\n        if verbose:\n            print(\"[CHECK] Numerical columns\")\n            with pd.option_context(\"display.precision\", 2):\n                print(cont_cols_desc)\n\n    if cat_cols:\n        cat_cols_f = intsec(data.columns.values, cat_cols)\n        cat_cols_desc = data[cat_cols_f].describe().transpose()\n        if verbose:\n            print(\"[CHECK] Categorical columns\")\n            with pd.option_context(\"display.precision\", 2):\n                print(cat_cols_desc)\n    return duplicated_ids, cont_cols_desc, cat_cols_desc\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.features.analysis.missing","title":"<code>missing(df, scale='linear', plot=False)</code>","text":"<p>Procedure to check fraction of missing values in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pandas dataframe</p> required <code>scale</code> <code>str</code> <p>y scale of the plot</p> <code>'linear'</code> <code>plot</code> <code>bool</code> <p>whether to output the plot</p> <code>False</code> <p>Returns:</p> Name Type Description <code>missing_val_frac</code> <code>DataFrame</code> <p>sorted dataframe with fraction of missing values per feature</p> <code>fig</code> <code>Figure</code> <p>plot with sorted fractions of missing values in each column</p> Source code in <code>churn_pred/eda/features/analysis.py</code> <pre><code>def missing(\n    df: pd.DataFrame,\n    scale: Literal[\"log\", \"linear\"] = \"linear\",\n    plot: bool = False,\n) -&gt; Tuple[pd.DataFrame, Figure]:\n    \"\"\"Procedure to check fraction of missing values in the dataset.\n\n    Args:\n        df (DataFrame): pandas dataframe\n        scale (str): y scale of the plot\n        plot (bool): whether to output the plot\n\n    Returns:\n        missing_val_frac (DataFrame): sorted dataframe with fraction of missing values\n            per feature\n        fig (Figure): plot with sorted fractions of missing values in each column\n    \"\"\"\n    data = df.copy()\n    missing_val_frac = data.isna().sum() / len(data)\n    missing_val_frac.sort_values(ascending=False, inplace=True)\n\n    if plot:\n        fig, ax = plt.subplots(figsize=(10, 5))\n        bar_plot(\n            missing_val_frac,\n            ax,\n            title=\"Fraction of missing values in the dataset\",\n        )\n    else:\n        fig = None\n    ax.set_yscale(scale)\n    return missing_val_frac, fig\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.features.analysis.nunique","title":"<code>nunique(df, scale='linear', plot=False)</code>","text":"<p>Procedure to plot features sorted by their number of unique values.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>dataset</p> required <code>scale</code> <code>str</code> <p>y scale of the plot</p> <code>'linear'</code> <code>plot</code> <code>bool</code> <p>whether to output the plot</p> <code>False</code> <p>Returns:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>plot with sorted number of unique values in features</p> Source code in <code>churn_pred/eda/features/analysis.py</code> <pre><code>def nunique(\n    df: pd.DataFrame,\n    scale: Literal[\"log\", \"linear\"] = \"linear\",\n    plot: bool = False,\n) -&gt; Tuple[pd.DataFrame, Figure]:\n    \"\"\"Procedure to plot features sorted by their number of unique values.\n\n    Args:\n        df (DataFrame): dataset\n        scale (str): y scale of the plot\n        plot (bool): whether to output the plot\n\n    Returns:\n        fig (Figure): plot with sorted number of unique values in features\n    \"\"\"\n    data = df.copy()\n\n    data_nunique = data.nunique()\n    data_nunique.sort_values(ascending=True, inplace=True)\n\n    if plot:\n        fig, ax = plt.subplots(figsize=(10, 5))\n        bar_plot(\n            data_nunique.dropna(),\n            ax,\n            title=\"Features number of unique values (NA are dropped)\",\n        )\n    else:\n        fig = None\n    ax.set_yscale(scale)\n    return data_nunique, fig\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.features.analysis.std","title":"<code>std(df, scale='linear', plot=False)</code>","text":"<p>Procedure to plot features sorted by their variance.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>dataset</p> required <code>scale</code> <code>str</code> <p>y scale of the plot</p> <code>'linear'</code> <code>plot</code> <code>bool</code> <p>whether to output the plot</p> <code>False</code> <p>Returns:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>plot with sorted standard deviation of continuous features</p> Source code in <code>churn_pred/eda/features/analysis.py</code> <pre><code>def std(\n    df: pd.DataFrame,\n    scale: Literal[\"log\", \"linear\"] = \"linear\",\n    plot: bool = False,\n) -&gt; Tuple[pd.DataFrame, Figure]:\n    \"\"\"Procedure to plot features sorted by their variance.\n\n    Args:\n        df (DataFrame): dataset\n        scale (str): y scale of the plot\n        plot (bool): whether to output the plot\n\n    Returns:\n        fig (Figure): plot with sorted standard deviation of continuous features\n    \"\"\"\n    data = df.copy()\n\n    data_std = data.std()\n\n    data_std.sort_values(ascending=False, inplace=True)\n\n    if plot:\n        fig, ax = plt.subplots(figsize=(10, 5))\n        bar_plot(data_std.dropna(), ax, title=\"Features variance (NA are dropped)\")\n    else:\n        fig = None\n    ax.set_yscale(scale)\n    return data_std, fig\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.features.analysis.zero","title":"<code>zero(df, scale='linear', plot=False)</code>","text":"<p>Procedure to check fraction of zero values in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pandas dataframe</p> required <code>scale</code> <code>str</code> <p>y scale of the plot</p> <code>'linear'</code> <code>plot</code> <code>bool</code> <p>whether to output the plot</p> <code>False</code> <p>Returns:</p> Name Type Description <code>zero_val_frac</code> <code>DataFrame</code> <p>sorted dataframe with fraction of '0' values per feature</p> <code>fig</code> <code>Figure</code> <p>plot with sorted fractions of '0' values in each column</p> Source code in <code>churn_pred/eda/features/analysis.py</code> <pre><code>def zero(\n    df: pd.DataFrame,\n    scale: Literal[\"log\", \"linear\"] = \"linear\",\n    plot: bool = False,\n) -&gt; Tuple[pd.DataFrame, Figure]:\n    \"\"\"Procedure to check fraction of zero values in the dataset.\n\n    Args:\n        df (DataFrame): pandas dataframe\n        scale (str): y scale of the plot\n        plot (bool): whether to output the plot\n\n    Returns:\n        zero_val_frac (DataFrame): sorted dataframe with fraction of '0' values per\n            feature\n        fig (Figure): plot with sorted fractions of '0' values in each column\n    \"\"\"\n    data = df.copy()\n    zero_val_frac = data.isin([0]).sum() / len(data)\n    zero_val_frac.sort_values(ascending=False, inplace=True)\n\n    if plot:\n        fig, ax = plt.subplots(figsize=(10, 5))\n        bar_plot(zero_val_frac, ax, title=\"Fraction of zero values in the dataset\")\n    else:\n        fig = None\n    ax.set_yscale(scale)\n    return zero_val_frac, fig\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.features.plotting.cross_correlation","title":"<code>cross_correlation(df, n=10, verbose=False)</code>","text":"<p>Procedure to calculate and plot cross-correlation of features in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pandas dataframe</p> required <code>verbose</code> <code>bool</code> <p>show n most correlated features</p> <code>False</code> <code>n</code> <code>int</code> <p>number correlated features in verbose output</p> <code>10</code> <p>Returns:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>heatmap of continuous features cross correlations</p> Source code in <code>churn_pred/eda/features/plotting.py</code> <pre><code>def cross_correlation(\n    df: pd.DataFrame,\n    n: int = 10,\n    verbose: bool = False,\n) -&gt; Figure:\n    \"\"\"Procedure to calculate and plot cross-correlation of features\n    in the dataset.\n\n    Args:\n        df (DataFrame): pandas dataframe\n        verbose (bool): show n most correlated features\n        n (int): number correlated features in verbose output\n\n    Returns:\n        fig (Figure): heatmap of continuous features cross correlations\n    \"\"\"\n    data = df.copy()\n\n    # corrwith uses numpy which does not like pandas Float dtypes\n    corr_matrix = data.astype(float).corr()\n    upper_stacked_sorted = (\n        corr_matrix.abs()\n        .where(np.triu(np.ones(corr_matrix.shape), k=1).astype(\"bool\"))\n        .stack()\n        .sort_values(ascending=False)\n    )\n\n    fig, ax = plt.subplots(figsize=(10, 10))\n    ax.set_title(\"Cross-correlation matrix\", size=20)\n    sns.set(font_scale=1.0)\n    sns.heatmap(\n        corr_matrix,\n        ax=ax,\n        cbar=True,\n        square=True,\n        # linewidths=0.5,\n        fmt=\".2f\",\n    )\n    if verbose:\n        print(\"Top {} absolute correlations\".format(n))\n        print(upper_stacked_sorted[:n])\n    return fig\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.features.plotting.distributions","title":"<code>distributions(df, low_per_cut=0, high_per_cut=1, type='box')</code>","text":"<p>Procedure to plot distributions of the features splitted by column split_col using workaround for violinplots in seaborn: * https://stackoverflow.com/a/64787568/8147433 DISCALIMER: for now the cont_cols NA vals are filled with 0</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pandas dataframe</p> required <code>low_per_cut</code> <code>float</code> <p>lower percentile where to cut the plot for better readability</p> <code>0</code> <code>high_per_cut</code> <code>float</code> <p>higher percentile where to cut the plot for better readability</p> <code>1</code> <code>type</code> <code>str</code> <p>type of distribution plot</p> <code>'box'</code> <p>Returns:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>ditribution plot per each feature</p> Source code in <code>churn_pred/eda/features/plotting.py</code> <pre><code>def distributions(\n    df: pd.DataFrame,\n    low_per_cut: float = 0,\n    high_per_cut: float = 1,\n    type: Literal[\"box\", \"violin\"] = \"box\",\n) -&gt; Figure:\n    \"\"\"Procedure to plot distributions of the features splitted\n    by column split_col using workaround for violinplots in seaborn:\n    * https://stackoverflow.com/a/64787568/8147433\n    DISCALIMER: for now the cont_cols NA vals are filled with 0\n\n    Args:\n        df (DataFrame): pandas dataframe\n        low_per_cut (float): lower percentile where to cut the plot for better\n            readability\n        high_per_cut (float): higher percentile where to cut the plot for better\n            readability\n        type (str): type of distribution plot\n\n    Returns:\n        fig (Figure): ditribution plot per each feature\n    \"\"\"\n    data = df.copy()\n    cols = data.columns.values\n    data = data.fillna(0).astype(float)\n    fig, ax = plt.subplots(len(cols), 1, figsize=(16, len(cols) * 2))\n    fig.suptitle(\"Distribution of feature values\", size=20)\n    for col, i in zip(cols, range(len(cols))):\n        if type == \"violin\":\n            sns.violinplot(\n                ax=ax[i],\n                x=col,\n                orient=\"h\",\n                # cut=0,\n                # showextrem=False,\n                data=data,\n            )\n        if type == \"box\":\n            sns.boxplot(\n                ax=ax[i],\n                x=col,\n                orient=\"h\",\n                data=data,\n            )\n        ax[i].set_xlim(\n            data[col].quantile(low_per_cut), data[col].quantile(high_per_cut)\n        )\n        ax[i].get_yaxis().set_visible(False)\n    plt.subplots_adjust(hspace=0.9)\n    return fig\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.target.analysis.correlation","title":"<code>correlation(df, target, scale='linear', plot=False)</code>","text":"<p>Procedure to plot most correlated numerical features with target column.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pandas dataframe</p> required <code>target</code> <code>Series</code> <p>target values</p> required <code>scale</code> <code>str</code> <p>y scale of the plot</p> <code>'linear'</code> <code>plot</code> <code>bool</code> <p>whether to output the plot</p> <code>False</code> <p>Returns:</p> Name Type Description <code>sorted_corr_cols</code> <code>DataFrame</code> <p>sorted dataframe with feature and target value correlation</p> <code>fig</code> <code>Figure</code> <p>sorted bar plot with feature and target value correlation</p> Source code in <code>churn_pred/eda/target/analysis.py</code> <pre><code>def correlation(\n    df: pd.DataFrame,\n    target: pd.Series,\n    scale: Literal[\"log\", \"linear\"] = \"linear\",\n    plot: bool = False,\n) -&gt; Tuple[pd.DataFrame, Figure]:\n    \"\"\"Procedure to plot most correlated numerical features with\n    target column.\n\n    Args:\n        df (pd.DataFrame): pandas dataframe\n        target (pd.Series): target values\n        scale (str): y scale of the plot\n        plot (bool): whether to output the plot\n\n    Returns:\n        sorted_corr_cols (pd.DataFrame): sorted dataframe with feature and target value\n            correlation\n        fig (Figure): sorted bar plot with feature and target value correlation\n    \"\"\"\n    data = df.copy()\n    target_col = target.name\n    correlation_df = pd.concat([data, target], axis=1).corr()\n    sorted_corr_cols = correlation_df[target_col].drop(index=[target_col])\n    sorted_corr_cols.sort_values(ascending=False, inplace=True)\n\n    if plot:\n        fig, ax = plt.subplots(figsize=(10, 5))\n        bar_plot(\n            sorted_corr_cols,\n            ax,\n            title=f\"Sorted features by their correlation with {target_col}\",\n        )\n    else:\n        fig = None\n    ax.set_yscale(scale)\n    return sorted_corr_cols, fig\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.target.plotting.distributions_in_binary_cls","title":"<code>distributions_in_binary_cls(df, target, low_per_cut=0, high_per_cut=1)</code>","text":"<p>Procedure to plot distributions of the features splitted by column split_col using workaround for violinplots in seaborn: * https://stackoverflow.com/a/64787568/8147433 DISCALIMER: for now the cont_cols NA vals are filled with 0</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pandas dataframe</p> required <code>target</code> <code>Series</code> <p>target values, i.e. binary classes</p> required <p>Returns:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>ditribution plot per each feature</p> Source code in <code>churn_pred/eda/target/plotting.py</code> <pre><code>def distributions_in_binary_cls(\n    df: pd.DataFrame,\n    target: pd.Series,\n    low_per_cut: float = 0,\n    high_per_cut: float = 1,\n) -&gt; Figure:\n    \"\"\"Procedure to plot distributions of the features splitted\n    by column split_col using workaround for violinplots in seaborn:\n    * https://stackoverflow.com/a/64787568/8147433\n    DISCALIMER: for now the cont_cols NA vals are filled with 0\n\n    Args:\n        df (DataFrame): pandas dataframe\n        target (pd.Series): target values, i.e. binary classes\n\n    Returns:\n        fig (Figure): ditribution plot per each feature\n    \"\"\"\n    data = pd.concat([df, target], axis=1)\n    cols = data.columns.values\n    data[\"dummy\"] = 0\n    data = data.fillna(0).astype(float)\n    fig, ax = plt.subplots(len(cols), 1, figsize=(16, len(cols) * 2))\n    fig.suptitle(f\"Distribution of feature values splitted by {target.name}\", size=20)\n    for col, i in zip(cols, range(len(cols))):\n        if col != target.name:\n            sns.violinplot(\n                ax=ax[i],\n                hue=target.name,\n                x=col,\n                y=\"dummy\",\n                orient=\"h\",\n                cut=0,\n                showextrem=False,\n                split=True,\n                data=data,\n            )\n            ax[i].get_legend().remove()\n            ax[i].set_xlim(\n                data[col].quantile(low_per_cut), data[col].quantile(high_per_cut)\n            )\n            ax[i].get_yaxis().set_visible(False)\n    plt.subplots_adjust(hspace=0.9, top=0.97)\n    return fig\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.target.plotting.prob_distrib_per_class","title":"<code>prob_distrib_per_class(predicted_probs, actual, task)</code>","text":"<p>Procedure to plot probability density distributions per class from LightGBM predictions.</p> <p>Parameters:</p> Name Type Description Default <code>predicted_probs</code> <code>ndarray</code> <p>predicted probs</p> required <code>actual</code> <code>ndarray</code> <p>ground truth classes</p> required <code>task</code> <code>str</code> <p>type of task</p> required <p>Returns:</p> Name Type Description <code>fig</code> <code>Figure</code> <p>probability density ditributions plot per each class</p> Source code in <code>churn_pred/eda/target/plotting.py</code> <pre><code>def prob_distrib_per_class(\n    predicted_probs: np.ndarray,\n    actual: np.ndarray,\n    task: Literal[\"binary\", \"multiclass\"],\n) -&gt; Figure:\n    \"\"\"Procedure to plot probability density distributions per class from LightGBM\n    predictions.\n\n    Args:\n        predicted_probs (ndarray): predicted probs\n        actual (ndarray): ground truth classes\n        task (str): type of task\n\n    Returns:\n        fig (Figure): probability density ditributions plot per each class\n    \"\"\"\n    if task == \"binary\":\n        temp = pd.DataFrame({\"predicted_proba\": predicted_probs, \"actual\": actual})\n\n        fig, ax = plt.subplots(figsize=(3, 2))\n        fig.suptitle(\"Predicted probability density per class\")\n        for label, alpha, color in zip([0, 1], [1, 0.7], [\"black\", \"red\"]):\n            ax.hist(\n                temp[temp[\"actual\"] == label][\"predicted_proba\"],\n                density=True,\n                bins=np.linspace(0, 1, 10),\n                alpha=alpha,\n                color=color,\n                ec=\"k\",\n            )\n        ax.set_xlim([0, 1])\n        ax.set_xlabel(\"probability\")\n        ax.set_ylabel(\"probability_density\")\n    elif task == \"multiclass\":\n        temp = pd.DataFrame(\n            {\n                \"predicted_proba\": np.take_along_axis(\n                    predicted_probs, np.vstack(actual), axis=1  # type: ignore\n                ).flatten(),\n                \"actual\": actual,\n            }\n        )\n\n        # Dictionary of color for each label\n        color_d = dict(\n            zip_longest(\n                temp[\"actual\"].unique(),\n                plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"],\n            )\n        )\n\n        n_classes = temp[\"actual\"].nunique()\n        fig, ax = plt.subplots(\n            ncols=n_classes, figsize=(n_classes * 3, 2), sharex=True, sharey=True\n        )\n        fig.suptitle(\"Predicted probability density per class\")\n        plt.subplots_adjust(wspace=0.3, top=0.75)\n\n        for i, (label, gp) in enumerate(temp.groupby(\"actual\")):\n            ax[i].hist(\n                gp[\"predicted_proba\"],\n                density=True,\n                bins=np.linspace(0, 1, 10),\n                color=color_d[label],\n                ec=\"k\",\n            )\n            ax[i].set_title(label)\n            ax[i].set_xlim([0, 1])\n            ax[i].set_xlabel(\"probability\")\n            ax[i].set_ylabel(\"probability_density\")\n    return fig\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.plotting.bar_plot","title":"<code>bar_plot(df, ax, title)</code>","text":"<p>Helper method for unified bar plot</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>dataframe to plot</p> required <code>ax</code> <code>Axes</code> <p>axes defining where to plot it</p> required <p>Returns:</p> Name Type Description <code>adjusted_plot</code> <code>Axes</code> <p>adjusted axes</p> Source code in <code>churn_pred/eda/plotting.py</code> <pre><code>def bar_plot(df: pd.DataFrame, ax: Axes, title: str) -&gt; Axes:\n    \"\"\"Helper method for unified bar plot\n\n    Args:\n        df (DataFrame): dataframe to plot\n        ax (Axes): axes defining where to plot it\n\n    Returns:\n        adjusted_plot (Axes): adjusted axes\n    \"\"\"\n    data = df.copy()\n    ax.set_title(title, size=20)\n    ax.tick_params(labelsize=8)\n    ax.set_xlabel(\"sorted features\", size=12)\n    return data.plot.bar(ax=ax)\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.general_utils.entropy_calc","title":"<code>entropy_calc(labels, base=np.e)</code>","text":"<p>Computes entropy of both continuous and categorical features. Shamelessly stolen from : https://stackoverflow.com/a/45091961 Args:     labels (list, ndarray, Series): list of values Returns:     ent (float): entropy of the list of values</p> Source code in <code>churn_pred/eda/general_utils.py</code> <pre><code>def entropy_calc(labels: list, base: float = np.e) -&gt; float:\n    \"\"\"Computes entropy of both continuous and categorical features.\n    Shamelessly stolen from :\n    https://stackoverflow.com/a/45091961\n    Args:\n        labels (list, ndarray, Series): list of values\n    Returns:\n        ent (float): entropy of the list of values\n    \"\"\"\n    n_labels = len(labels)\n    value, counts = np.unique(labels, return_counts=True)\n    probs = counts / n_labels\n    n_classes = np.count_nonzero(probs)\n\n    ent = float(0)\n    if n_classes &gt; 1:\n        for i in probs:\n            ent -= i * math.log(i, base)\n    return ent\n</code></pre>"},{"location":"churn_pred/eda.html#churn_pred.eda.general_utils.intsec","title":"<code>intsec(list1, list2)</code>","text":"<p>Simple intesection of two lists. Args:     list1 (list): list1     list2 (list): list2 Returns:     list (list): intersection of lists</p> Source code in <code>churn_pred/eda/general_utils.py</code> <pre><code>def intsec(list1: list, list2: list) -&gt; list:\n    \"\"\"Simple intesection of two lists.\n    Args:\n        list1 (list): list1\n        list2 (list): list2\n    Returns:\n        list (list): intersection of lists\n    \"\"\"\n    return list(set.intersection(set(list1), set(list2)))\n</code></pre>"},{"location":"churn_pred/preprocessing.html","title":"Preprocess data","text":""},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.auxiliary_data.age_categories","title":"<code>age_categories(df, age_col)</code>","text":"<p>Returns string pd.DataFrame identifing different age classification categories according to the age: * working_class (https://ourworldindata.org/age-structure)   * children_and_adolescents: &lt;0, 15)   * working_age: &lt;15, 65)   * elderly: &lt;65, inf) * stage_of_life (https://integrishealth.org/resources/on-your-health/2015/october/stages-of-life-health-for-every-age)   * infant: &lt;0, 2)   * toddler: &lt;2, 5)   * child: &lt;5, 13)   * teen: &lt;13, 20)   * adult: &lt;20, 40)   * middle_age_adult: &lt;40, 60)   * senior_adult: &lt;60, inf) * generation (https://www.beresfordresearch.com/age-range-by-generation/)   * gen_z: &lt;12, 28)   * millennials: &lt;28, 44)   * gen_x: &lt;44, 60)   * boomers_2: &lt;60, 70)   * boomers_1: &lt;70, 79)   * post_war: &lt;79, 97)   * ww2: &lt;97, 102)   * vampire: &lt;102, inf)</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataset</p> required <code>age_col</code> <code>str</code> <p>age column</p> required Source code in <code>churn_pred/preprocessing/auxiliary_data.py</code> <pre><code>def age_categories(df: pd.DataFrame, age_col: str) -&gt; pd.DataFrame:\n    \"\"\"Returns string pd.DataFrame identifing different age classification\n    categories according to the age:\n    * working_class (https://ourworldindata.org/age-structure)\n      * children_and_adolescents: &lt;0, 15)\n      * working_age: &lt;15, 65)\n      * elderly: &lt;65, inf)\n    * stage_of_life (https://integrishealth.org/resources/on-your-health/2015/october/stages-of-life-health-for-every-age)\n      * infant: &lt;0, 2)\n      * toddler: &lt;2, 5)\n      * child: &lt;5, 13)\n      * teen: &lt;13, 20)\n      * adult: &lt;20, 40)\n      * middle_age_adult: &lt;40, 60)\n      * senior_adult: &lt;60, inf)\n    * generation (https://www.beresfordresearch.com/age-range-by-generation/)\n      * gen_z: &lt;12, 28)\n      * millennials: &lt;28, 44)\n      * gen_x: &lt;44, 60)\n      * boomers_2: &lt;60, 70)\n      * boomers_1: &lt;70, 79)\n      * post_war: &lt;79, 97)\n      * ww2: &lt;97, 102)\n      * vampire: &lt;102, inf)\n\n    Args:\n        df (pd.DataFrame): input dataset\n        age_col (str): age column\n    \"\"\"\n    dfc = df.copy()\n    dfc[\"working_class\"] = pd.cut(\n        dfc[age_col],\n        bins=[0, 15, 65, np.inf],\n        labels=[\"children_and_adolescents\", \"working_age\", \"elderly\"],\n        include_lowest=True,\n    )\n    dfc[\"stage_of_life\"] = pd.cut(\n        dfc[age_col],\n        bins=[0, 2, 5, 13, 20, 40, 60, np.inf],\n        labels=[\n            \"infant\",\n            \"toddler\",\n            \"child\",\n            \"teen\",\n            \"adult\",\n            \"middle_age_adult\",\n            \"senior_adult\",\n        ],\n        include_lowest=True,\n    )\n    dfc[\"generation\"] = pd.cut(\n        dfc[age_col],\n        bins=[0, 28, 44, 60, 70, 79, 97, 102, np.inf],\n        labels=[\n            \"gen_z\",\n            \"millennials\",\n            \"gen_x\",\n            \"boomers_2\",\n            \"boomers_1\",\n            \"post_war\",\n            \"ww2\",\n            \"vampire\",\n        ],\n        include_lowest=True,\n    )\n    return dfc\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.auxiliary_data.big_mac_index","title":"<code>big_mac_index(df, country_name_col)</code>","text":"<p>Returns dataframe with Big Max Index corresponding to country codes. Downloaded on 26/4/2024.</p> Note <p>Unfortunatelly Spain, France, Germany (unique companies in the dataset) are not included, other index to explore: https://en.wikipedia.org/wiki/Big_Mac_Index</p> Based on Downloaded from <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataset</p> required <code>country_name_col</code> <code>str</code> <p>column name with country names</p> required Source code in <code>churn_pred/preprocessing/auxiliary_data.py</code> <pre><code>def big_mac_index(df: pd.DataFrame, country_name_col: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Returns dataframe with Big Max Index corresponding to country codes.\n    Downloaded on 26/4/2024.\n\n    Note:\n        Unfortunatelly Spain, France, Germany (unique companies in the dataset) are not included, other index to explore:\n        https://en.wikipedia.org/wiki/Big_Mac_Index\n\n    Based on:\n        https://www.economist.com/big-mac-index\n\n    Downloaded from:\n        https://github.com/TheEconomist/big-mac-data\n        https://raw.githubusercontent.com/TheEconomist/big-mac-data/master/output-data/big-mac-full-index.csv\n\n    Args:\n        df (pd.DataFrame): input dataset\n        country_name_col: column name with country names\n    \"\"\"\n    big_mac_index = pd.read_csv(BIG_MAC_INDEX)\n    # filter the last available price\n    big_mac_index[\"date\"] = pd.to_datetime(big_mac_index[\"date\"])\n    big_mac_index = (\n        big_mac_index.sort_values(\"date\").groupby(\"iso_a3\").tail(1).reset_index()\n    )\n    big_mac_index = big_mac_index[[\"iso_a3\", \"dollar_price\"]]\n    big_mac_index.rename(\n        columns={\"dollar_price\": \"big_mac_index_dollar_price\"}, inplace=True\n    )\n\n    big_mac_index = big_mac_index.dropna()\n\n    dfc = df.copy()\n    dfc[\"iso_a3\"] = get_iso_a3(df=dfc, country_name_col=country_name_col)\n    dfc = dfc.merge(big_mac_index, on=\"iso_a3\", how=\"left\")\n    dfc.drop(columns=[\"iso_a3\"], inplace=True)\n    return dfc\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.auxiliary_data.gdppc","title":"<code>gdppc(df, country_name_col)</code>","text":"<p>Returns dataframe with Gross Domestic Product Per Capita corresponding to country codes. Uses information from worldbank API downloaded on 26/4/2024. Last file update: 3/28/2024. Posprocessed file has initial 3 lines removed for easier processing using pandas df.</p> Downloaded from <ul> <li>https://data.worldbank.org/indicator/NY.GDP.PCAP.PP.CD</li> <li>https://api.worldbank.org/v2/en/indicator/NY.GDP.PCAP.PP.CD?downloadformat=csv</li> </ul> <p>Main file before preprocessing:     'data/gdpp/API_NY.GDP.PCAP.PP.CD_DS2_en_csv_v2_213153.csv' Other included files:     'data/gdpp/Metadata_Country_API_NY.GDP.PCAP.PP.CD_DS2_en_csv_v2_213153.csv'     'data/gdpp/Metadata_Indicator_API_NY.GDP.PCAP.PP.CD_DS2_en_csv_v2_213153.csv'</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataset</p> required <code>country_name_col</code> <code>str</code> <p>column name with country names</p> required Source code in <code>churn_pred/preprocessing/auxiliary_data.py</code> <pre><code>def gdppc(df: pd.DataFrame, country_name_col: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Returns dataframe with Gross Domestic Product Per Capita corresponding to country\n    codes. Uses information from worldbank API downloaded on 26/4/2024.\n    Last file update: 3/28/2024.\n    Posprocessed file has initial 3 lines removed for easier processing using pandas df.\n\n    Downloaded from:\n        * https://data.worldbank.org/indicator/NY.GDP.PCAP.PP.CD\n        * https://api.worldbank.org/v2/en/indicator/NY.GDP.PCAP.PP.CD?downloadformat=csv\n    Main file before preprocessing:\n        'data/gdpp/API_NY.GDP.PCAP.PP.CD_DS2_en_csv_v2_213153.csv'\n    Other included files:\n        'data/gdpp/Metadata_Country_API_NY.GDP.PCAP.PP.CD_DS2_en_csv_v2_213153.csv'\n        'data/gdpp/Metadata_Indicator_API_NY.GDP.PCAP.PP.CD_DS2_en_csv_v2_213153.csv'\n\n    Args:\n        df (pd.DataFrame): input dataset\n        country_name_col: column name with country names\n    \"\"\"\n    gdp_per_capita_raw = pd.read_csv(GDP_PER_CAPITA)\n    gdp_per_capita_ic = pd.read_csv(GDP_PER_CAPITA_INCOMEGROUP)\n    # add last available year\n    gdp_per_capita = gdp_per_capita_raw[[\"Country Code\"]]\n    gdp_per_capita.rename(columns={\"Country Code\": \"iso_a3\"}, inplace=True)\n    gdp_per_capita[\"gdp_per_capita\"] = (\n        gdp_per_capita_raw.drop(\n            columns=[\"Country Name\", \"Country Code\", \"Indicator Name\", \"Indicator Code\"]\n        )\n        .ffill(axis=1)\n        .iloc[:, -1]\n    )\n\n    gdp_per_capita_ic = gdp_per_capita_ic[[\"Country Code\", \"IncomeGroup\"]]\n    gdp_per_capita_ic.rename(columns={\"Country Code\": \"iso_a3\"}, inplace=True)\n\n    gdp_per_capita = gdp_per_capita.dropna()\n    gdp_per_capita_ic = gdp_per_capita_ic.dropna()\n\n    dfc = df.copy()\n    dfc[\"iso_a3\"] = get_iso_a3(df=dfc, country_name_col=country_name_col)\n\n    dfc = dfc.merge(gdp_per_capita, on=\"iso_a3\", how=\"left\")\n    dfc = dfc.merge(gdp_per_capita_ic, on=\"iso_a3\", how=\"left\")\n    dfc.drop(columns=[\"iso_a3\"], inplace=True)\n\n    return dfc\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.auxiliary_data.get_country_name","title":"<code>get_country_name(df, country_name_col)</code>","text":"<p>Returns pd.Series with mapped country iso_a2 to names.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>Series</code> <p>input country name pandas series</p> required Source code in <code>churn_pred/preprocessing/auxiliary_data.py</code> <pre><code>def get_country_name(df: pd.DataFrame, country_name_col: str):\n    \"\"\"Returns pd.Series with mapped country iso_a2 to names.\n\n    Args:\n        df (pd.Series): input country name pandas series\n    \"\"\"\n    dfc = df.copy()\n\n    def _get_country_name_map(country_name: str) -&gt; str:\n        \"\"\"Helper function for get_country_name\"\"\"\n        try:\n            result = pycountry.countries.get(alpha_2=country_name)\n            name_str = result.name\n        except:\n            name_str = \"NA\"\n        return name_str\n\n    dfc[\"res\"] = \"NA\"\n    for country_name in dfc[country_name_col].unique():\n        dfc.loc[dfc[country_name_col] == country_name, [\"res\"]] = _get_country_name_map(\n            country_name\n        )\n    return dfc[\"res\"]\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.auxiliary_data.get_country_region_subregion","title":"<code>get_country_region_subregion(df, country_name_col)</code>","text":"<p>Returns pd.Series with mapped country iso_a2 to names.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>Series</code> <p>input country name pandas series</p> required Source code in <code>churn_pred/preprocessing/auxiliary_data.py</code> <pre><code>def get_country_region_subregion(df: pd.DataFrame, country_name_col: str):\n    \"\"\"Returns pd.Series with mapped country iso_a2 to names.\n\n    Args:\n        df (pd.Series): input country name pandas series\n    \"\"\"\n    dfc = df.copy()\n\n    def _get_country_region_subregion_map(country_name: str) -&gt; Tuple[str, str]:\n        \"\"\"Helper function for get_country_name\"\"\"\n        try:\n            result = CountryInfo(country_name)\n            region_str = result.region()\n            subregion_str = result.subregion()\n        except:\n            region_str = \"NA\"\n            subregion_str = \"NA\"\n        return (region_str, subregion_str)\n\n    dfc[[country_name_col + \"_region\", country_name_col + \"_subregion\"]] = (\"NA\", \"NA\")\n    for country_name in dfc[country_name_col].unique():\n        dfc.loc[\n            dfc[country_name_col] == country_name,\n            [country_name_col + \"_region\", country_name_col + \"_subregion\"],\n        ] = _get_country_region_subregion_map(country_name)\n    return dfc[[country_name_col + \"_region\", country_name_col + \"_subregion\"]]\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.auxiliary_data.get_iso_a3","title":"<code>get_iso_a3(df, country_name_col)</code>","text":"<p>Returns pd.Series with mapped country names to iso_a3.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>Series</code> <p>input country name pandas series</p> required Source code in <code>churn_pred/preprocessing/auxiliary_data.py</code> <pre><code>def get_iso_a3(df: pd.DataFrame, country_name_col: str):\n    \"\"\"Returns pd.Series with mapped country names to iso_a3.\n\n    Args:\n        df (pd.Series): input country name pandas series\n    \"\"\"\n    dfc = df.copy()\n\n    def _get_iso_a3_map(country_name: str) -&gt; str:\n        \"\"\"Helper function for get_iso_a3\"\"\"\n        try:\n            result = pycountry.countries.search_fuzzy(country_name)\n            iso_a3_str = result[0].alpha_3  # type: ignore\n        except:\n            iso_a3_str = \"NA\"\n        return iso_a3_str\n\n    dfc[\"res\"] = \"NA\"\n    for country_name in dfc[country_name_col].unique():\n        dfc.loc[dfc[country_name_col] == country_name, [\"res\"]] = _get_iso_a3_map(\n            country_name\n        )\n    return dfc[\"res\"]\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.auxiliary_data.hemisphere","title":"<code>hemisphere(df, cc_col, loc_db_df=None, city_col=None)</code>","text":"<p>Returns string pd.Series identifing hemisphere: \"northern\" or \"southern\".</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataframe</p> required <code>city_col</code> <code>str</code> <p>city name column</p> <code>None</code> <code>cc_col</code> <code>str</code> <p>country code column</p> required <code>loc_db_df</code> <code>DataFrame</code> <p>pandas dataframe with previously saved locations</p> <code>None</code> Source code in <code>churn_pred/preprocessing/auxiliary_data.py</code> <pre><code>def hemisphere(\n    df: pd.DataFrame,\n    cc_col: str,\n    loc_db_df: Optional[pd.DataFrame] = None,\n    city_col: Optional[str] = None,\n) -&gt; pd.Series:\n    \"\"\"Returns string pd.Series identifing hemisphere: \"northern\" or \"southern\".\n\n    Args:\n        df (pd.DataFrame): input dataframe\n        city_col (str): city name column\n        cc_col (str): country code column\n        loc_db_df (pd.DataFrame): pandas dataframe with previously saved locations\n    \"\"\"\n    if city_col:\n        uq_locs = (df[city_col] + \",\" + df[cc_col]).unique()\n    else:\n        uq_locs = (\" ,\" + df[cc_col]).unique()\n    dfc = df.copy()\n    geolocator = Nominatim(user_agent=\"hemisphere_identification\")\n    dfc[\"hemisphere\"] = \"northern\"\n\n    for uq_loc in uq_locs:\n        if (loc_db_df is not None) and (uq_loc in loc_db_df[\"location\"].values):\n            location = loc_db_df[loc_db_df[\"location\"] == uq_loc][\n                [\"latitude\", \"longitude\"]\n            ]\n            latitude = float(location.latitude)\n        else:\n            latitude = geolocator.geocode(uq_loc).latitude\n\n        if latitude &lt; 0:\n            city, country = uq_loc.split(\",\")\n            dfc.loc[\n                (dfc[city_col] == city) &amp; (dfc[cc_col] == country), \"hemisphere\"\n            ] = \"southern\"\n\n    return dfc\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.auxiliary_data.surname_origin","title":"<code>surname_origin(df, surname_col)</code>","text":"<p>Surname classification that uses db of names leaked from FB, see: https://github.com/philipperemy/name-dataset</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataset</p> required <code>surname_col</code> <code>str</code> <p>column name with surnames</p> required Source code in <code>churn_pred/preprocessing/auxiliary_data.py</code> <pre><code>def surname_origin(df: pd.DataFrame, surname_col: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Surname classification that uses db of names leaked from FB, see:\n    https://github.com/philipperemy/name-dataset\n\n    Args:\n        df (pd.DataFrame): input dataset\n        surname_col (str): column name with surnames\n    \"\"\"\n    dfc = df.copy()\n    nd = NameDataset()\n\n    def _search_surname(surname):\n        try:\n            res = nd.search(surname)\n            origin_country = max(\n                res[\"last_name\"][\"country\"], key=res[\"last_name\"][\"country\"].get\n            )\n        except:\n            origin_country = \"NA\"\n        return origin_country\n\n    dfc[\"res\"] = \"NA\"\n    for surname in dfc[surname_col].unique():\n        dfc.loc[dfc[surname_col] == surname, [\"res\"]] = _search_surname(surname)\n\n    return dfc[\"res\"]\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.auxiliary_data.surname_origin_bert","title":"<code>surname_origin_bert(df, surname_col)</code>","text":"<p>THIS IS WORK IN PROGRESS!!! Surname classification that uses adjusted script scripts/surname_classification_with_bert.py) from: https://www.kaggle.com/code/yonatankpl/surname-classification-with-bert to train a bert model for surname classification</p> <p>additional data from: https://github.com/greenelab/wiki-nationality-estimate/tree/master</p> <p>and possibly data from: https://github.com/philipperemy/name-dataset?tab=readme-ov-file#full-dataset</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataset</p> required <code>surname_col</code> <code>str</code> <p>column name with surnames</p> required Source code in <code>churn_pred/preprocessing/auxiliary_data.py</code> <pre><code>def surname_origin_bert(df: pd.DataFrame, surname_col: str) -&gt; pd.DataFrame:\n    \"\"\"\n    THIS IS WORK IN PROGRESS!!!\n    Surname classification that uses adjusted script\n    scripts/surname_classification_with_bert.py) from:\n    https://www.kaggle.com/code/yonatankpl/surname-classification-with-bert\n    to train a bert model for surname classification\n\n    additional data from:\n    https://github.com/greenelab/wiki-nationality-estimate/tree/master\n\n    and possibly data from:\n    https://github.com/philipperemy/name-dataset?tab=readme-ov-file#full-dataset\n\n    Args:\n        df (pd.DataFrame): input dataset\n        surname_col (str): column name with surnames\n    \"\"\"\n    dfc = df.copy()\n    return dfc\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.label_encoder.LabelEncoder","title":"<code>LabelEncoder</code>","text":"<p>             Bases: <code>object</code></p> <p>Label Encode categorical values for multiple columns at once</p> <p> NOTE: Shamlessly copied from https://github.com/jrzaurin/pytorch-widedeep</p> <p> NOTE: LabelEncoder reserves 0 for <code>unseen</code> new categories. This is convenient when defining the embedding layers, since we can just set padding idx to 0.</p> <p>Parameters:</p> Name Type Description Default <code>columns_to_encode</code> <code>list, Optional, default = None</code> <p>List of strings containing the names of the columns to encode. If <code>None</code> all columns of type <code>object</code> in the dataframe will be label encoded.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>encoding_dict</code> <code>Dict</code> <p>Dictionary containing the encoding mappings in the format, e.g. :  <code>{'colname1': {'cat1': 1, 'cat2': 2, ...}, 'colname2': {'cat1': 1, 'cat2': 2, ...}, ...}</code>  # noqa</p> <code>inverse_encoding_dict(Dict)</code> <code>Dict</code> <p>Dictionary containing the inverse encoding mappings in the format, e.g. :  <code>{'colname1': {1: 'cat1', 2: 'cat2', ...}, 'colname2': {1: 'cat1', 2: 'cat2', ...}, ...}</code>  # noqa</p> Source code in <code>churn_pred/preprocessing/label_encoder.py</code> <pre><code>class LabelEncoder(object):\n    r\"\"\"Label Encode categorical values for multiple columns at once\n\n    :information_source: **NOTE**:\n    Shamlessly copied from https://github.com/jrzaurin/pytorch-widedeep\n\n    :information_source: **NOTE**:\n    LabelEncoder reserves 0 for `unseen` new categories. This is convenient\n    when defining the embedding layers, since we can just set padding idx to 0.\n\n    Parameters:\n        columns_to_encode (list, Optional, default = None): List of strings containing\n            the names of the columns to encode. If `None` all columns of type `object`\n            in the dataframe will be label encoded.\n\n    Attributes:\n        encoding_dict (Dict): Dictionary containing the encoding mappings in the format,\n            e.g. : &lt;br/&gt; `{'colname1': {'cat1': 1, 'cat2': 2, ...}, 'colname2': {'cat1': 1, 'cat2': 2, ...}, ...}`  # noqa\n        inverse_encoding_dict(Dict): Dictionary containing the inverse encoding mappings\n            in the format, e.g. : &lt;br/&gt; `{'colname1': {1: 'cat1', 2: 'cat2', ...}, 'colname2': {1: 'cat1', 2: 'cat2', ...}, ...}`  # noqa\n    \"\"\"\n\n    def __init__(\n        self,\n        columns_to_encode: Optional[List[str]] = None,\n    ):\n        self.columns_to_encode = columns_to_encode\n\n    def fit(self, df: pd.DataFrame) -&gt; \"LabelEncoder\":\n        \"\"\"Creates encoding attributes\n\n        Returns:\n            LabelEncoder: `LabelEncoder` fitted object\n        \"\"\"\n\n        df_inp = df.copy()\n\n        if self.columns_to_encode is None:\n            self.columns_to_encode = list(\n                df_inp.select_dtypes(include=[\"object\"]).columns\n            )\n        else:\n            # sanity check to make sure all categorical columns are in an adequate\n            # format\n            for col in self.columns_to_encode:\n                df_inp[col] = df_inp[col].astype(\"O\")\n\n        unique_column_vals = dict()\n        for c in self.columns_to_encode:\n            unique_column_vals[c] = df_inp[c].unique()\n\n        self.encoding_dict = dict()\n\n        # leave 0 for padding/\"unseen\" categories\n        idx = 1\n        for k, v in unique_column_vals.items():\n            self.encoding_dict[k] = {\n                o: i + idx for i, o in enumerate(unique_column_vals[k])\n            }\n            idx = 1\n\n        self.inverse_encoding_dict = dict()\n        for c in self.encoding_dict:\n            self.inverse_encoding_dict[c] = {\n                v: k for k, v in self.encoding_dict[c].items()\n            }\n            self.inverse_encoding_dict[c][0] = \"unseen\"\n\n        return self\n\n    def transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Label Encoded the categories in `columns_to_encode`\n\n        Returns:\n            pd.DataFrame: label-encoded dataframe\n        \"\"\"\n        try:\n            self.encoding_dict\n        except AttributeError:\n            raise NotFittedError(\n                \"This LabelEncoder instance is not fitted yet. \"\n                \"Call 'fit' with appropriate arguments before using this LabelEncoder.\"\n            )\n\n        df_inp = df.copy()\n        # sanity check to make sure all categorical columns are in an adequate\n        # format\n        for col in self.columns_to_encode:  # type: ignore\n            df_inp[col] = df_inp[col].astype(\"O\")\n\n        for k, v in self.encoding_dict.items():\n            df_inp[k] = df_inp[k].apply(lambda x: v[x] if x in v.keys() else 0)\n\n        return df_inp\n\n    def fit_transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Combines `fit` and `transform`\n\n        Returns:\n            pd.DataFrame: label-encoded dataframe\n\n        Examples:\n            &gt;&gt;&gt; import pandas as pd\n            &gt;&gt;&gt; from churn_pred.preprocessing.label_encoder import LabelEncoder\n            &gt;&gt;&gt; df = pd.DataFrame({'col1': [1,2,3], 'col2': ['me', 'you', 'him']})\n            &gt;&gt;&gt; columns_to_encode = ['col2']\n            &gt;&gt;&gt; encoder = LabelEncoder(columns_to_encode)\n            &gt;&gt;&gt; encoder.fit_transform(df)\n               col1  col2\n            0     1     1\n            1     2     2\n            2     3     3\n            &gt;&gt;&gt; encoder.encoding_dict\n            {'col2': {'me': 1, 'you': 2, 'him': 3}}\n        \"\"\"\n        return self.fit(df).transform(df)\n\n    def inverse_transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Returns the original categories\n\n        Returns:\n            pd.DataFrame: label-encoded dataframe\n\n        Examples:\n            &gt;&gt;&gt; import pandas as pd\n            &gt;&gt;&gt; from churn_pred.preprocessing.label_encoder import LabelEncoder\n            &gt;&gt;&gt; df = pd.DataFrame({'col1': [1,2,3], 'col2': ['me', 'you', 'him']})\n            &gt;&gt;&gt; columns_to_encode = ['col2']\n            &gt;&gt;&gt; encoder = LabelEncoder(columns_to_encode)\n            &gt;&gt;&gt; df_enc = encoder.fit_transform(df)\n            &gt;&gt;&gt; encoder.inverse_transform(df_enc)\n               col1 col2\n            0     1   me\n            1     2  you\n            2     3  him\n        \"\"\"\n        for k, v in self.inverse_encoding_dict.items():\n            df[k] = df[k].apply(lambda x: v[x])\n        return df\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.label_encoder.LabelEncoder.fit","title":"<code>fit(df)</code>","text":"<p>Creates encoding attributes</p> <p>Returns:</p> Name Type Description <code>LabelEncoder</code> <code>LabelEncoder</code> <p><code>LabelEncoder</code> fitted object</p> Source code in <code>churn_pred/preprocessing/label_encoder.py</code> <pre><code>def fit(self, df: pd.DataFrame) -&gt; \"LabelEncoder\":\n    \"\"\"Creates encoding attributes\n\n    Returns:\n        LabelEncoder: `LabelEncoder` fitted object\n    \"\"\"\n\n    df_inp = df.copy()\n\n    if self.columns_to_encode is None:\n        self.columns_to_encode = list(\n            df_inp.select_dtypes(include=[\"object\"]).columns\n        )\n    else:\n        # sanity check to make sure all categorical columns are in an adequate\n        # format\n        for col in self.columns_to_encode:\n            df_inp[col] = df_inp[col].astype(\"O\")\n\n    unique_column_vals = dict()\n    for c in self.columns_to_encode:\n        unique_column_vals[c] = df_inp[c].unique()\n\n    self.encoding_dict = dict()\n\n    # leave 0 for padding/\"unseen\" categories\n    idx = 1\n    for k, v in unique_column_vals.items():\n        self.encoding_dict[k] = {\n            o: i + idx for i, o in enumerate(unique_column_vals[k])\n        }\n        idx = 1\n\n    self.inverse_encoding_dict = dict()\n    for c in self.encoding_dict:\n        self.inverse_encoding_dict[c] = {\n            v: k for k, v in self.encoding_dict[c].items()\n        }\n        self.inverse_encoding_dict[c][0] = \"unseen\"\n\n    return self\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.label_encoder.LabelEncoder.fit_transform","title":"<code>fit_transform(df)</code>","text":"<p>Combines <code>fit</code> and <code>transform</code></p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: label-encoded dataframe</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from churn_pred.preprocessing.label_encoder import LabelEncoder\n&gt;&gt;&gt; df = pd.DataFrame({'col1': [1,2,3], 'col2': ['me', 'you', 'him']})\n&gt;&gt;&gt; columns_to_encode = ['col2']\n&gt;&gt;&gt; encoder = LabelEncoder(columns_to_encode)\n&gt;&gt;&gt; encoder.fit_transform(df)\n   col1  col2\n0     1     1\n1     2     2\n2     3     3\n&gt;&gt;&gt; encoder.encoding_dict\n{'col2': {'me': 1, 'you': 2, 'him': 3}}\n</code></pre> Source code in <code>churn_pred/preprocessing/label_encoder.py</code> <pre><code>def fit_transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Combines `fit` and `transform`\n\n    Returns:\n        pd.DataFrame: label-encoded dataframe\n\n    Examples:\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; from churn_pred.preprocessing.label_encoder import LabelEncoder\n        &gt;&gt;&gt; df = pd.DataFrame({'col1': [1,2,3], 'col2': ['me', 'you', 'him']})\n        &gt;&gt;&gt; columns_to_encode = ['col2']\n        &gt;&gt;&gt; encoder = LabelEncoder(columns_to_encode)\n        &gt;&gt;&gt; encoder.fit_transform(df)\n           col1  col2\n        0     1     1\n        1     2     2\n        2     3     3\n        &gt;&gt;&gt; encoder.encoding_dict\n        {'col2': {'me': 1, 'you': 2, 'him': 3}}\n    \"\"\"\n    return self.fit(df).transform(df)\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.label_encoder.LabelEncoder.inverse_transform","title":"<code>inverse_transform(df)</code>","text":"<p>Returns the original categories</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: label-encoded dataframe</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from churn_pred.preprocessing.label_encoder import LabelEncoder\n&gt;&gt;&gt; df = pd.DataFrame({'col1': [1,2,3], 'col2': ['me', 'you', 'him']})\n&gt;&gt;&gt; columns_to_encode = ['col2']\n&gt;&gt;&gt; encoder = LabelEncoder(columns_to_encode)\n&gt;&gt;&gt; df_enc = encoder.fit_transform(df)\n&gt;&gt;&gt; encoder.inverse_transform(df_enc)\n   col1 col2\n0     1   me\n1     2  you\n2     3  him\n</code></pre> Source code in <code>churn_pred/preprocessing/label_encoder.py</code> <pre><code>def inverse_transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Returns the original categories\n\n    Returns:\n        pd.DataFrame: label-encoded dataframe\n\n    Examples:\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; from churn_pred.preprocessing.label_encoder import LabelEncoder\n        &gt;&gt;&gt; df = pd.DataFrame({'col1': [1,2,3], 'col2': ['me', 'you', 'him']})\n        &gt;&gt;&gt; columns_to_encode = ['col2']\n        &gt;&gt;&gt; encoder = LabelEncoder(columns_to_encode)\n        &gt;&gt;&gt; df_enc = encoder.fit_transform(df)\n        &gt;&gt;&gt; encoder.inverse_transform(df_enc)\n           col1 col2\n        0     1   me\n        1     2  you\n        2     3  him\n    \"\"\"\n    for k, v in self.inverse_encoding_dict.items():\n        df[k] = df[k].apply(lambda x: v[x])\n    return df\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.label_encoder.LabelEncoder.transform","title":"<code>transform(df)</code>","text":"<p>Label Encoded the categories in <code>columns_to_encode</code></p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: label-encoded dataframe</p> Source code in <code>churn_pred/preprocessing/label_encoder.py</code> <pre><code>def transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Label Encoded the categories in `columns_to_encode`\n\n    Returns:\n        pd.DataFrame: label-encoded dataframe\n    \"\"\"\n    try:\n        self.encoding_dict\n    except AttributeError:\n        raise NotFittedError(\n            \"This LabelEncoder instance is not fitted yet. \"\n            \"Call 'fit' with appropriate arguments before using this LabelEncoder.\"\n        )\n\n    df_inp = df.copy()\n    # sanity check to make sure all categorical columns are in an adequate\n    # format\n    for col in self.columns_to_encode:  # type: ignore\n        df_inp[col] = df_inp[col].astype(\"O\")\n\n    for k, v in self.encoding_dict.items():\n        df_inp[k] = df_inp[k].apply(lambda x: v[x] if x in v.keys() else 0)\n\n    return df_inp\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess_data.drop_constant_cols","title":"<code>drop_constant_cols(df, verbose=False)</code>","text":"<p>Returns dataframe without constant columns, i.e. those with just 1 unique value for all rows.</p> Source code in <code>churn_pred/preprocessing/preprocess_data.py</code> <pre><code>def drop_constant_cols(df: pd.DataFrame, verbose: bool = False) -&gt; pd.DataFrame:\n    \"\"\"Returns dataframe without constant columns, i.e. those with just 1 unique\n    value for all rows.\"\"\"\n    nunique_per_col = df.apply(lambda x: x.nunique(), axis=0)\n    const_cols = nunique_per_col[nunique_per_col == 1].index.values\n    df = df.drop(const_cols, axis=1)\n    if verbose:\n        print(\n            \"\"\"\n            Dropped {} constant columns.\n            Affected columns: {}\n            \"\"\".format(\n                len(const_cols), const_cols\n            )\n        )\n    return df\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess_data.drop_high_nan_cols","title":"<code>drop_high_nan_cols(df, threshold=0.8, verbose=False)</code>","text":"<p>Returns dataframe without columns that have ratio of missingness above threshold.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataframe</p> required <code>threshold</code> <code>float = 0.8</code> <p>ratio of missingness applied per column</p> <code>0.8</code> <code>verbose</code> <code>bool</code> <p>whether the output should be verbose</p> <code>False</code> Source code in <code>churn_pred/preprocessing/preprocess_data.py</code> <pre><code>def drop_high_nan_cols(\n    df: pd.DataFrame, threshold: float = 0.8, verbose: bool = False\n) -&gt; pd.DataFrame:\n    \"\"\"Returns dataframe without columns that have ratio of missingness above threshold.\n\n    Args:\n        df (pd.DataFrame): input dataframe\n        threshold (float = 0.8): ratio of missingness applied per column\n        verbose (bool): whether the output should be verbose\n    \"\"\"\n    n_rows = df.shape[0]\n    nan_fraction_per_col = df.apply(lambda x: x.isna().sum() / n_rows, axis=0)\n    high_nan_percentage_cols = nan_fraction_per_col[\n        nan_fraction_per_col &gt; threshold\n    ].index.values\n    df = df.drop(high_nan_percentage_cols, axis=1)\n    if verbose:\n        print(\n            \"\"\"\n            Dropped {} columns with fraction of NaN above threshold = {}.\n            Affected columns: {}\n            \"\"\".format(\n                len(high_nan_percentage_cols), threshold, high_nan_percentage_cols\n            )\n        )\n    return df\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess_data.drop_high_uq_cat_cols","title":"<code>drop_high_uq_cat_cols(df, cat_cols, uq_val_count, verbose=False)</code>","text":"<p>Returns dataframe without categorical columns that have too many unique values</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataframe</p> required <code>cat_cols</code> <code>list</code> <p>list of categorical columns</p> required <code>uq_val_count</code> <code>int</code> <p>unique value count</p> required <code>verbose</code> <code>bool</code> <p>whether the output should be verbose</p> <code>False</code> Source code in <code>churn_pred/preprocessing/preprocess_data.py</code> <pre><code>def drop_high_uq_cat_cols(\n    df: pd.DataFrame, cat_cols: list, uq_val_count: int, verbose: bool = False\n) -&gt; pd.DataFrame:\n    \"\"\"Returns dataframe without categorical columns that have too many unique values\n\n    Args:\n        df (pd.DataFrame): input dataframe\n        cat_cols (list): list of categorical columns\n        uq_val_count (int): unique value count\n        verbose (bool): whether the output should be verbose\n    \"\"\"\n    nunique_per_col = df[cat_cols].apply(lambda x: x.nunique(), axis=0)\n    high_uq_value_cat_cols = nunique_per_col[\n        nunique_per_col &gt; uq_val_count\n    ].index.values\n    df = df.drop(high_uq_value_cat_cols, axis=1)\n    if verbose:\n        print(\n            \"\"\"\n            Dropped {} high unique value columns.\n            Affected columns: {}\n            \"\"\".format(\n                len(high_uq_value_cat_cols), high_uq_value_cat_cols\n            )\n        )\n    return df\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess_data.drop_highly_correlated_columns","title":"<code>drop_highly_correlated_columns(df, cont_cols, crosscorr_val=0.95, verbose=False)</code>","text":"<p>Returns dataframe without highly correlated columns, cross correlation is evaluated with crosscorr_val.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataframe</p> required <code>cont_cols</code> <code>list</code> <p>list of columns to evaluate correlation for</p> required <code>crosscorr_val</code> <code>float = 0.95</code> <p>threshold value of correlation</p> <code>0.95</code> <code>verbose</code> <code>bool</code> <p>whether the output should be verbose</p> <code>False</code> Source code in <code>churn_pred/preprocessing/preprocess_data.py</code> <pre><code>def drop_highly_correlated_columns(\n    df: pd.DataFrame,\n    cont_cols: list,\n    crosscorr_val: float = 0.95,\n    verbose: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Returns dataframe without highly correlated columns, cross correlation is\n    evaluated with crosscorr_val.\n\n    Args:\n        df (pd.DataFrame): input dataframe\n        cont_cols (list): list of columns to evaluate correlation for\n        crosscorr_val (float = 0.95): threshold value of correlation\n        verbose (bool): whether the output should be verbose\n    \"\"\"\n    corr_matrix = df[cont_cols].corr().abs()\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(\"bool\"))\n    upper_above = upper.apply(lambda x: any(x &gt; crosscorr_val), axis=1)\n    to_drop = upper_above[upper_above].index.values\n    df = df.drop(to_drop, axis=1)\n    if verbose:\n        print(\n            \"\"\"\n            Dropped {} highly correlated columns.\n            Affected columns: {}\n            \"\"\".format(\n                len(to_drop), to_drop\n            )\n        )\n    return df\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess_data.most_frequent_in_list_col","title":"<code>most_frequent_in_list_col(dfs)</code>","text":"<p>Returns pd.Series with the most frequent values in the lists.</p> <p>Parameters:</p> Name Type Description Default <code>dfs</code> <code>Series</code> <p>input pandas series containing string list values</p> required Source code in <code>churn_pred/preprocessing/preprocess_data.py</code> <pre><code>def most_frequent_in_list_col(dfs: pd.Series):\n    \"\"\"Returns pd.Series with the most frequent values in the lists.\n\n    Args:\n        dfs (pd.Series): input pandas series containing string list values\n    \"\"\"\n    dfsc = dfs.copy()\n    dfsc.apply(\n        lambda string: (\n            _most_frequent(list(string.replace(\"[\", \"\").replace(\"]\", \"\").split(\", \")))\n            if isinstance(string, str)\n            else string\n        )\n    )\n    return dfsc\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess_data.nan_with_number_imputer","title":"<code>nan_with_number_imputer(df, columns, fill_number=-1.0, verbose=False)</code>","text":"<p>Fills NAs with surrogate float, -1 is default value used, it can be customized.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataframe</p> required <code>columns</code> <code>List[str]</code> <p>list of columns that will be filled</p> required <code>fill_number</code> <code>float = -1</code> <p>number used to replace NAs. Defaults to</p> <code>-1.0</code> <code>verbose</code> <code>bool</code> <p>whether the output should be verbose</p> <code>False</code> Source code in <code>churn_pred/preprocessing/preprocess_data.py</code> <pre><code>def nan_with_number_imputer(\n    df: pd.DataFrame,\n    columns: List[str],\n    fill_number: float = -1.0,\n    verbose: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Fills NAs with surrogate float, -1 is default value used, it can be customized.\n\n    Args:\n        df (pd.DataFrame): input dataframe\n        columns (List[str]): list of columns that will be filled\n        fill_number (float = -1): number used to replace NAs. Defaults to\n        verbose (bool): whether the output should be verbose\n    \"\"\"\n    dfc = df.copy()\n    if verbose:\n        sum_nan_vals = df[columns].isna().sum()\n        nans_cols = []\n        for c in columns:\n            nans_cols.append((c, df[c].isna().sum()))\n    dfc = df.copy()\n    dfc[columns] = dfc[columns].apply(lambda x: x.astype(float).fillna(fill_number))\n    if verbose:\n        print(\n            \"\"\"\n            Imputed {} NaN values with {}.\n            Affected columns (col, num_NaNs): {}\n            \"\"\".format(\n                sum_nan_vals, fill_number, nans_cols\n            )\n        )\n    return dfc\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess_data.nan_with_unknown_imputer","title":"<code>nan_with_unknown_imputer(df, columns, fill_token='unknown', verbose=False)</code>","text":"<p>Fills NAs with surrogate string, 'unknown' is default value used, it can be customized.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataframe</p> required <code>columns</code> <code>List[str]</code> <p>ist of columns that will be filled</p> required <code>fill_token</code> <code>str = \"unknown\"</code> <p>string used to replace NAs</p> <code>'unknown'</code> <code>verbose</code> <code>bool</code> <p>whether the output should be verbose</p> <code>False</code> Source code in <code>churn_pred/preprocessing/preprocess_data.py</code> <pre><code>def nan_with_unknown_imputer(\n    df: pd.DataFrame,\n    columns: List[str],\n    fill_token: str = \"unknown\",\n    verbose: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"Fills NAs with surrogate string, 'unknown' is default value used, it can be customized.\n\n    Args:\n        df (pd.DataFrame): input dataframe\n        columns (List[str]): ist of columns that will be filled\n        fill_token (str = \"unknown\"): string used to replace NAs\n        verbose (bool): whether the output should be verbose\n    \"\"\"\n    df = df.copy()\n    if verbose:\n        sum_nan_vals = df[columns].isna().sum()\n        nans_cols = []\n        for c in columns:\n            nans_cols.append((c, df[c].isna().sum()))\n    for c in columns:\n        df[c] = df[c].astype(object).fillna(fill_token)\n\n    dfc = df.copy()\n    dfc[columns] = dfc[columns].apply(lambda x: x.astype(object).fillna(fill_token))\n    if verbose:\n        print(\n            \"\"\"\n            Imputed {} NaN values with {}.\n            Affected columns (col, num_NaNs): {}\n            \"\"\".format(\n                sum_nan_vals, fill_token, nans_cols\n            )\n        )\n    return df\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess_data.nuq_in_list_col","title":"<code>nuq_in_list_col(dfs)</code>","text":"<p>Returns pd.Series with the number of unique values in the lists.</p> <p>Parameters:</p> Name Type Description Default <code>dfs</code> <code>Series</code> <p>input pandas series containing string list values</p> required Source code in <code>churn_pred/preprocessing/preprocess_data.py</code> <pre><code>def nuq_in_list_col(dfs: pd.Series):\n    \"\"\"Returns pd.Series with the number of unique values in the lists.\n\n    Args:\n        dfs (pd.Series): input pandas series containing string list values\n    \"\"\"\n    dfsc = dfs.copy()\n    dfsc.apply(\n        lambda string: (\n            _nunique(list(string.replace(\"[\", \"\").replace(\"]\", \"\").split(\", \")))\n            if isinstance(string, str)\n            else string\n        )\n    )\n    return dfsc\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess_data.replace_rare_categories_with_str_other","title":"<code>replace_rare_categories_with_str_other(df, categorical_cols, quantile=0.05, surrogate_value='other', verbose=False)</code>","text":"<p>Replaces rare category value with surrogate string.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataframe</p> required <code>categorical_cols</code> <code>List[str]</code> <p>list of columns in dataframe to process.</p> required <code>quantile</code> <code>float = 0.05</code> <p>determines what values are considered as rare</p> <code>0.05</code> <code>surrogate_value</code> <code>str = \"other\"</code> <p>string used to replace rare values</p> <code>'other'</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, Dict]</code> <p>Tuple[pd.DataFrame, Dict]: New dataframe and a dict. with mapping between orig. and surrogate values.</p> Source code in <code>churn_pred/preprocessing/preprocess_data.py</code> <pre><code>def replace_rare_categories_with_str_other(\n    df: pd.DataFrame,\n    categorical_cols: List[str],\n    quantile: float = 0.05,\n    surrogate_value: str = \"other\",\n    verbose: bool = False,\n) -&gt; Tuple[pd.DataFrame, Dict]:\n    \"\"\"Replaces rare category value with surrogate string.\n\n    Args:\n        df (pd.DataFrame): input dataframe\n        categorical_cols (List[str]): list of columns in dataframe to process.\n        quantile (float = 0.05): determines what values are considered as rare\n        surrogate_value (str = \"other\"): string used to replace rare values\n\n    Returns:\n        Tuple[pd.DataFrame, Dict]:\n            New dataframe and a dict. with mapping between orig. and surrogate values.\n    \"\"\"\n    if surrogate_value in df[categorical_cols].values:\n        raise ValueError(\n            \"Surrogate string - \"\n            + surrogate_value\n            + \" - is already present, choose another one.\"\n        )\n\n    dfc = df.copy()\n    replace_dict_per_col = (\n        df[categorical_cols]\n        .apply(_replace_rare_dict, args=[surrogate_value, quantile])\n        .to_dict()\n    )\n    dfc = dfc.replace(replace_dict_per_col)\n    if verbose:\n        sum_rare_cats = sum(\n            [len(replace_dict_per_col[col]) for col in replace_dict_per_col]\n        )\n        rare_cats_per_col = [\n            (col, list(replace_dict_per_col[col].keys()))\n            for col in replace_dict_per_col\n        ]\n        print(\n            \"\"\"\n            Replaced {} rare categories (val_count &lt; {}) with {}.\n            Affected columns (List[(col, rare_cats)]): {}\n            \"\"\".format(\n                sum_rare_cats,\n                quantile,\n                surrogate_value,\n                rare_cats_per_col,\n            )\n        )\n    return dfc, replace_dict_per_col\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess_text.language_detection","title":"<code>language_detection(df, text_col, model_type='fasttext')</code>","text":"Source code in <code>churn_pred/preprocessing/preprocess_text.py</code> <pre><code>def language_detection(\n    df: pd.DataFrame,\n    text_col: str,\n    model_type: Literal[\"roberta\", \"fasttext\"] = \"fasttext\",\n) -&gt; pd.DataFrame:\n    \"\"\"\n    https://huggingface.co/papluca/xlm-roberta-base-language-detection\n    https://spacy.io/universe/project/spacy_fastlang\n    \"\"\"\n    dfc = df.copy()\n\n    if model_type == \"fasttext\":\n\n        def _get_language(token: Doc) -&gt; str:\n            return token._.language\n\n        def _get_language_score(token: Doc) -&gt; str:\n            return token._.language_score\n\n        nlp = spacy.load(\"en_core_web_sm\")\n        nlp.add_pipe(\"language_detector\")\n        res = df[text_col].astype(str).apply(nlp)\n        dfc[text_col + \"_language\"] = res.apply(_get_language)\n        dfc[text_col + \"_language_score\"] = res.apply(_get_language_score)\n    elif model_type == \"roberta\":\n\n        def _get_language(token: Doc) -&gt; str:\n            return token._.language\n\n        def _get_language_score(token: Doc) -&gt; str:\n            return token._.language_score\n\n        pipe = pipeline(\n            \"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\"\n        )\n        res = pipe(dfc[\"CustomerFeedback\"].astype(str).to_list())\n        dfc[text_col + \"_language\"] = pipe(dfc[text_col].astype(str))\n    else:\n        raise NotImplementedError\n    return dfc\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess_text.sentiment_analysis","title":"<code>sentiment_analysis(df, text_col, sentiment_depth=3)</code>","text":"<p>Returns dataframe with new column that analysis sentintent in the text_col.</p> <p>initial idea: Inspired by https://www.nature.com/articles/s41598-024-60210-7 I also used the 3 most popular models with voting: 1. cardiffnlp/twitter-roberta-base-sentiment-latest 2. nlptown/bert-base-multilingual-uncased-sentiment 3. mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis 4. lxyuan/distilbert-base-multilingual-cased-sentiments-student 5. finiteautomata/bertweet-base-sentiment-analysis</p> <p>issues: 1. 3(pos, neutral, neg) vs 5(1-5 stars) sentiments; models 1,3 vs 2 2. maximum sequence length models 4-5</p> <p>final idea: Either 3 sentimnets(model 1) or 5 stars (model 2)</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataset</p> required <code>text_col</code> <code>str</code> <p>column name with text</p> required <code>sentiment_depth</code> <code>[3, 5]</code> <p>depth of sentiment analysis</p> <code>3</code> Source code in <code>churn_pred/preprocessing/preprocess_text.py</code> <pre><code>def sentiment_analysis(\n    df: pd.DataFrame, text_col: str, sentiment_depth: Literal[3, 5] = 3\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Returns dataframe with new column that analysis sentintent in the text_col.\n\n    initial idea:\n    Inspired by https://www.nature.com/articles/s41598-024-60210-7 I also used\n    the 3 most popular models with voting:\n    1. cardiffnlp/twitter-roberta-base-sentiment-latest\n    2. nlptown/bert-base-multilingual-uncased-sentiment\n    3. mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\n    4. lxyuan/distilbert-base-multilingual-cased-sentiments-student\n    5. finiteautomata/bertweet-base-sentiment-analysis\n\n    issues:\n    1. 3(pos, neutral, neg) vs 5(1-5 stars) sentiments; models 1,3 vs 2\n    2. maximum sequence length models 4-5\n\n    final idea:\n    Either 3 sentimnets(model 1) or 5 stars (model 2)\n\n    Args:\n        df (pd.DataFrame): input dataset\n        text_col (str): column name with text\n        sentiment_depth ([3, 5]): depth of sentiment analysis\n    \"\"\"\n    dfc = df.copy()\n    if sentiment_depth == 3:\n        pipe = pipeline(\n            \"text-classification\",\n            model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n            device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n        )\n    elif sentiment_depth == 5:\n        pipe = pipeline(\n            \"text-classification\",\n            model=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n            device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n        )\n    else:\n        raise NotImplementedError\n    res = pipe(dfc[text_col].astype(str).to_list())\n    res = pd.DataFrame(res).rename(\n        columns={\n            \"label\": text_col + \"_sentiment\",\n            \"score\": text_col + \"_sentiment_score\",\n        }\n    )\n    return pd.concat([dfc, res], axis=1)\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess_text.text_cleaning","title":"<code>text_cleaning(df, text_col)</code>","text":"<p>Returns dataframe with preprocessed/cleaned text column. Spacy-cleaner that uses spacy functionalities. https://spacy.io/universe/project/spacy-cleaner</p> Note <p>The spacy-cleaner library does not do much. Future task - develop own cleaner</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>input dataset</p> required <code>text_col</code> <code>str</code> <p>column name with text</p> required Source code in <code>churn_pred/preprocessing/preprocess_text.py</code> <pre><code>def text_cleaning(df: pd.DataFrame, text_col: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Returns dataframe with preprocessed/cleaned text column.\n    Spacy-cleaner that uses spacy functionalities.\n    https://spacy.io/universe/project/spacy-cleaner\n\n    Note:\n        The spacy-cleaner library does not do much.\n        Future task - develop own cleaner\n\n    Args:\n        df (pd.DataFrame): input dataset\n        text_col: column name with text\n    \"\"\"\n    dfc = df.copy()\n    model = spacy.load(\"en_core_web_sm\")\n    cleaner = spacy_cleaner.Cleaner(\n        model,\n        removers.remove_stopword_token,\n        replacers.replace_punctuation_token,\n        mutators.mutate_lemma_token,\n    )\n    dfc[text_col] = cleaner.clean(dfc[text_col].astype(str))\n\n    return dfc\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess.PreprocessData","title":"<code>PreprocessData</code>","text":"<p>Object to preprocess the dataset. Args:     target_col (str): target column name     id_cols (List[str]): id columns     cat_cols (Optional[List[str]]): list of categorical column names     cont_cols (Optional[List[str]]): list of continuous column names</p> Source code in <code>churn_pred/preprocessing/preprocess.py</code> <pre><code>class PreprocessData:\n    \"\"\"Object to preprocess the dataset.\n    Args:\n        target_col (str): target column name\n        id_cols (List[str]): id columns\n        cat_cols (Optional[List[str]]): list of categorical column names\n        cont_cols (Optional[List[str]]): list of continuous column names\n    \"\"\"\n\n    def __init__(\n        self,\n        target_col: str,\n        id_cols: str,\n        cat_cols: Optional[List[str]] = None,\n        cont_cols: Optional[List[str]] = None,\n    ):\n        self.target_col = target_col\n        self.id_cols = id_cols\n        self.cat_cols = cat_cols\n        self.cont_cols = cont_cols\n\n        self.is_fitted = False\n\n    def fit_transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Fit peprocessor and transform dataset in training step.\"\"\"\n\n        dfc = df.drop(columns=self.id_cols).copy()\n\n        dfc = dfc.pipe(drop_constant_cols)\n\n        self.cat_cols = intsec(list(dfc), self.cat_cols)\n\n        if self.cat_cols is None:\n            self.cat_cols = self._infere_cat_cols(dfc)\n            dfc_cat_cols = drop_high_nan_cols(dfc[self.cat_cols])\n            dfc = dfc.drop(columns=self.cat_cols)\n            dfc = pd.concat([dfc, dfc_cat_cols], axis=1)\n            self.cat_cols = dfc_cat_cols.columns.values.tolist()\n\n        if self.cont_cols is None:\n            self.init_cont_cols = self._infere_cont_cols(dfc, self.cat_cols)\n            dfc_init_cont_cols = drop_high_nan_cols(dfc[self.init_cont_cols])\n            dfc = dfc.drop(columns=self.init_cont_cols)\n            dfc = pd.concat([dfc, dfc_init_cont_cols], axis=1)\n            self.init_cont_cols = dfc_init_cont_cols.columns.values.tolist()\n\n            dfc = nan_with_number_imputer(dfc, self.init_cont_cols, -9999.0)\n\n            (\n                dfc,\n                self.final_cont_cols,\n            ) = self._drop_highly_corr_cols_and_get_final_cont_cols(\n                dfc, self.init_cont_cols\n            )\n\n        else:\n            self.final_cont_cols = list(\n                set(self.cont_cols).intersection(set(dfc.columns.values))\n            )\n\n            dfc = nan_with_number_imputer(dfc, self.final_cont_cols, -9999.0)\n\n        dfc = nan_with_unknown_imputer(dfc, self.cat_cols)\n\n        dfc = dfc[self.cat_cols + self.final_cont_cols + [self.target_col]]\n\n        self.label_encoder = LabelEncoder(self.cat_cols)\n        dfc_le = self.label_encoder.fit_transform(dfc)\n\n        dfc_le = self._change_int_float_types(dfc_le)\n\n        dfc_le[self.id_cols] = df[self.id_cols]\n\n        self.is_fitted = True\n\n        return dfc_le\n\n    def transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Transform dataset in inference step.\"\"\"\n\n        if not self.is_fitted:\n            raise NotFittedError(\n                \"\"\"This instance of 'PreprocessData' has not been fitted yet.\n                Please, run 'fit' first\"\"\"\n            )\n\n        dfc = df.drop(columns=self.id_cols).copy()\n\n        try:\n            dfc = dfc[self.cat_cols + self.final_cont_cols + [self.target_col]]\n        except KeyError:\n            dfc = dfc[self.cat_cols + self.final_cont_cols]\n\n        # dfc = dfc.replace(self.replace_rare_categories_dict)\n\n        dfc = nan_with_unknown_imputer(dfc, self.cat_cols)\n\n        dfc = nan_with_number_imputer(\n            dfc,\n            list(set(self.final_cont_cols)),\n            -9999.0,  # noqa\n        )\n\n        dfc_le = self.label_encoder.transform(dfc)\n\n        dfc_le = self._change_int_float_types(dfc_le)\n\n        dfc_le[self.id_cols] = df[self.id_cols]\n\n        return dfc_le\n\n    def fit(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Just to keep familiar naming convention with sklearn.\"\"\"\n        return self.fit_transform(df)\n\n    def _drop_highly_corr_cols_and_get_final_cont_cols(\n        self, df: pd.DataFrame, cont_cols: List[str]\n    ) -&gt; Tuple[pd.DataFrame, List[str]]:\n        \"\"\"Drop highly correlated columns to decrease the size of the dataset\n        by dropping redundant information.\"\"\"\n\n        df = drop_highly_correlated_columns(df, cont_cols)\n\n        final_cont_cols = [\n            c for c in df.columns if c not in self.cat_cols + [self.target_col]\n        ]\n\n        return df, final_cont_cols\n\n    def _infere_cat_cols(self, df: pd.DataFrame):\n        \"\"\"Guess the categorical columns by excluding clearly continuous\n        columns - int, float\"\"\"\n\n        cat_cols = []\n        for col in df.columns:\n            if (\n                df[col].dtype not in [\"int32\", \"int64\"]\n                and df[col].dtype not in [\"float32\", \"float64\"]\n                and col not in [self.target_col]\n            ):\n                cat_cols.append(col)\n        return cat_cols\n\n    def _infere_cont_cols(\n        self, df: pd.DataFrame, cat_cols: Optional[List[str]]\n    ):  # noqa\n        \"\"\"Guess the continuous columns by excluding clearly categorical,\n        and target_col and including only int or float.\"\"\"\n\n        if cat_cols is not None:\n            cont_cols = [c for c in df.columns if c not in cat_cols + [self.target_col]]\n        else:\n            cont_cols = []\n            for col in df.columns:\n                if (df[col].dtype == \"int\" or df[col].dtype == \"float\") and col not in [\n                    self.target_col\n                ]:\n                    cont_cols.append(col)\n\n        return cont_cols\n\n    def _change_int_float_types(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Change int to float as int causes data type issues in some ml\n        methods, eg. lightgbm.\"\"\"\n        dfc = df.copy()\n        dfc = dfc.astype(\n            dict.fromkeys(dfc.select_dtypes(np.int64).columns, np.int32)\n        )  # noqa\n        dfc = dfc.astype(\n            dict.fromkeys(dfc.select_dtypes(np.float64).columns, np.float32)\n        )\n\n        return dfc\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess.PreprocessData.fit","title":"<code>fit(df)</code>","text":"<p>Just to keep familiar naming convention with sklearn.</p> Source code in <code>churn_pred/preprocessing/preprocess.py</code> <pre><code>def fit(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Just to keep familiar naming convention with sklearn.\"\"\"\n    return self.fit_transform(df)\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess.PreprocessData.fit_transform","title":"<code>fit_transform(df)</code>","text":"<p>Fit peprocessor and transform dataset in training step.</p> Source code in <code>churn_pred/preprocessing/preprocess.py</code> <pre><code>def fit_transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Fit peprocessor and transform dataset in training step.\"\"\"\n\n    dfc = df.drop(columns=self.id_cols).copy()\n\n    dfc = dfc.pipe(drop_constant_cols)\n\n    self.cat_cols = intsec(list(dfc), self.cat_cols)\n\n    if self.cat_cols is None:\n        self.cat_cols = self._infere_cat_cols(dfc)\n        dfc_cat_cols = drop_high_nan_cols(dfc[self.cat_cols])\n        dfc = dfc.drop(columns=self.cat_cols)\n        dfc = pd.concat([dfc, dfc_cat_cols], axis=1)\n        self.cat_cols = dfc_cat_cols.columns.values.tolist()\n\n    if self.cont_cols is None:\n        self.init_cont_cols = self._infere_cont_cols(dfc, self.cat_cols)\n        dfc_init_cont_cols = drop_high_nan_cols(dfc[self.init_cont_cols])\n        dfc = dfc.drop(columns=self.init_cont_cols)\n        dfc = pd.concat([dfc, dfc_init_cont_cols], axis=1)\n        self.init_cont_cols = dfc_init_cont_cols.columns.values.tolist()\n\n        dfc = nan_with_number_imputer(dfc, self.init_cont_cols, -9999.0)\n\n        (\n            dfc,\n            self.final_cont_cols,\n        ) = self._drop_highly_corr_cols_and_get_final_cont_cols(\n            dfc, self.init_cont_cols\n        )\n\n    else:\n        self.final_cont_cols = list(\n            set(self.cont_cols).intersection(set(dfc.columns.values))\n        )\n\n        dfc = nan_with_number_imputer(dfc, self.final_cont_cols, -9999.0)\n\n    dfc = nan_with_unknown_imputer(dfc, self.cat_cols)\n\n    dfc = dfc[self.cat_cols + self.final_cont_cols + [self.target_col]]\n\n    self.label_encoder = LabelEncoder(self.cat_cols)\n    dfc_le = self.label_encoder.fit_transform(dfc)\n\n    dfc_le = self._change_int_float_types(dfc_le)\n\n    dfc_le[self.id_cols] = df[self.id_cols]\n\n    self.is_fitted = True\n\n    return dfc_le\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.preprocess.PreprocessData.transform","title":"<code>transform(df)</code>","text":"<p>Transform dataset in inference step.</p> Source code in <code>churn_pred/preprocessing/preprocess.py</code> <pre><code>def transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Transform dataset in inference step.\"\"\"\n\n    if not self.is_fitted:\n        raise NotFittedError(\n            \"\"\"This instance of 'PreprocessData' has not been fitted yet.\n            Please, run 'fit' first\"\"\"\n        )\n\n    dfc = df.drop(columns=self.id_cols).copy()\n\n    try:\n        dfc = dfc[self.cat_cols + self.final_cont_cols + [self.target_col]]\n    except KeyError:\n        dfc = dfc[self.cat_cols + self.final_cont_cols]\n\n    # dfc = dfc.replace(self.replace_rare_categories_dict)\n\n    dfc = nan_with_unknown_imputer(dfc, self.cat_cols)\n\n    dfc = nan_with_number_imputer(\n        dfc,\n        list(set(self.final_cont_cols)),\n        -9999.0,  # noqa\n    )\n\n    dfc_le = self.label_encoder.transform(dfc)\n\n    dfc_le = self._change_int_float_types(dfc_le)\n\n    dfc_le[self.id_cols] = df[self.id_cols]\n\n    return dfc_le\n</code></pre>"},{"location":"churn_pred/preprocessing.html#churn_pred.preprocessing.scaler.scaler_mapper","title":"<code>scaler_mapper(cont_cols, cat_cols, id_cols, scaler_mapper_def=None)</code>","text":"<p>Function that maps scaler functions to appropriate columns.</p> <p>By default does not assign any scaler to continuous, categorical or identifier columns. The scalers must be set in scaler_mapper_def. Use sklearn scalers. Only columns defined in mapper object will be present in the transformed dataset.</p> <p>Parameters:</p> Name Type Description Default <code>cont_cols</code> <code>list</code> <p>list of continuous feature columns in the dataset</p> required <code>cat_cols</code> <code>list</code> <p>list of categorical feature columns in the dataset</p> required <code>id_cols</code> <code>list</code> <p>identifier columns</p> required <code>scaler_mapper_def</code> <code>dict</code> <p>optional dictionary that contains keys ['cont_cols', 'cat_cols', 'id_cols'] with their corresponding scalers (defined by names, not instantiated) from sklearn library</p> <code>None</code> Source code in <code>churn_pred/preprocessing/scaler.py</code> <pre><code>def scaler_mapper(\n    cont_cols: List[str],\n    cat_cols: List[str],\n    id_cols: List[str],\n    scaler_mapper_def: Optional[dict] = None,\n) -&gt; DataFrameMapper:\n    \"\"\"Function that maps scaler functions to appropriate columns.\n\n    By default does not assign any scaler to continuous, categorical or\n    identifier columns. The scalers must be set in scaler_mapper_def. Use sklearn scalers.\n    Only columns defined in mapper object will be present in the transformed dataset.\n\n    Args:\n        cont_cols (list): list of continuous feature columns in the dataset\n        cat_cols (list): list of categorical feature columns in the dataset\n        id_cols (list): identifier columns\n        scaler_mapper_def (dict): optional dictionary that contains keys\n            ['cont_cols', 'cat_cols', 'id_cols'] with their corresponding\n            scalers (defined by names, not instantiated) from sklearn library\n    Returns:\n        scaler (DataFrameMapper): scaler object mapping sklearn scalers to columns in\n            pandas dataframe\n    \"\"\"\n    if scaler_mapper_def:\n        cont_cols_def = gen_features(\n            columns=list(map(lambda x: [x], cont_cols)),\n            classes=[scaler_mapper_def[\"cont_cols\"]],\n        )\n\n        cat_cols_def = gen_features(\n            columns=list(map(lambda x: [x], cat_cols)),\n            classes=[scaler_mapper_def[\"cat_cols\"]],\n        )\n\n        id_cols_def = gen_features(\n            columns=list(map(lambda x: [x], id_cols)),\n            classes=[scaler_mapper_def[\"id_cols\"]],\n        )\n\n    else:\n        cont_cols_def = gen_features(\n            columns=list(map(lambda x: [x], cont_cols)), classes=[None]\n        )\n\n        cat_cols_def = gen_features(\n            columns=list(map(lambda x: [x], cat_cols)), classes=[None]\n        )\n\n        id_cols_def = gen_features(\n            columns=list(map(lambda x: [x], id_cols)), classes=[None]\n        )\n\n    scaler = DataFrameMapper(cont_cols_def + cat_cols_def + id_cols_def, df_out=True)\n    return scaler\n</code></pre>"},{"location":"churn_pred/training.html","title":"Training","text":""},{"location":"churn_pred/training.html#churn_pred.training.metrics.aiqc","title":"<code>aiqc(actual, high_quantile, low_quantile)</code>","text":"<p>Average InterQuantile Coverage for Quantile Regression. Check if the interquantile coverage is close to the coverage of in the test dataset.</p> <p>Parameters:</p> Name Type Description Default <code>actual</code> <code>ndarray</code> <p>actual values</p> required <code>high_quantile</code> <code>ndarray</code> <p>high quantile predicted values</p> required <code>low_quantile</code> <code>ndarray</code> <p>low quantile predicted values</p> required Source code in <code>churn_pred/training/metrics.py</code> <pre><code>def aiqc(actual: np.ndarray, high_quantile: np.ndarray, low_quantile: np.ndarray):\n    \"\"\"Average InterQuantile Coverage for Quantile Regression.\n    Check if the interquantile coverage is close to the coverage of in the test dataset.\n\n    Args:\n        actual (np.ndarray): actual values\n        high_quantile (np.ndarray): high quantile predicted values\n        low_quantile (np.ndarray): low quantile predicted values\n    Returns:\n        aiqc (float): average interquantile coverage\n    \"\"\"\n    return np.sum((actual &lt; high_quantile) &amp; (actual &gt; low_quantile)) / len(actual)\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.metrics.nacil","title":"<code>nacil(actual, high_quantile_predicted, low_quantile_predicted)</code>","text":"<p>Normalized Average Confidence Interval Length for Quantile Regression. The value is normalized to actual(expected) value.</p> <p>Parameters:</p> Name Type Description Default <code>actual</code> <code>ndarray</code> <p>actual values</p> required <code>high_quantile_predicted</code> <code>ndarray</code> <p>high quantile predicted values</p> required <code>low_quantile_predicted</code> <code>ndarray</code> <p>low quantile predicted values</p> required Source code in <code>churn_pred/training/metrics.py</code> <pre><code>def nacil(\n    actual: np.ndarray,\n    high_quantile_predicted: np.ndarray,\n    low_quantile_predicted: np.ndarray,\n):\n    \"\"\"Normalized Average Confidence Interval Length for Quantile Regression.\n    The value is normalized to actual(expected) value.\n\n    Args:\n        actual (np.ndarray): actual values\n        high_quantile_predicted (np.ndarray): high quantile predicted values\n        low_quantile_predicted (np.ndarray): low quantile predicted values\n    Returns:\n        nacil (float): normalized average confidence interval length\n    \"\"\"\n    return np.mean((high_quantile_predicted - low_quantile_predicted) / actual)\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.metrics.ndcg","title":"<code>ndcg(actual, predicted)</code>","text":"<p>Normalized Discounted Cumulative Gain</p> <p>Parameters:</p> Name Type Description Default <code>actual</code> <code>ndarray</code> <p>actual values</p> required <code>predicted</code> <code>ndarray</code> <p>predicted values</p> required Source code in <code>churn_pred/training/metrics.py</code> <pre><code>def ndcg(actual: np.ndarray, predicted: Union[np.ndarray, list]) -&gt; float:\n    \"\"\"Normalized Discounted Cumulative Gain\n\n    Args:\n        actual (np.ndarray): actual values\n        predicted (np.ndarray): predicted values\n    Return:\n        ndcg (float): normalized discounted cumulative gain\n    \"\"\"\n    return ndcg_score(\n        [rankdata(actual, method=\"ordinal\")],\n        [rankdata(predicted, method=\"ordinal\")],\n    )\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.metrics.rmse","title":"<code>rmse(actual, predicted)</code>","text":"<p>Root Mean Squared Error</p> <p>Parameters:</p> Name Type Description Default <code>actual</code> <code>ndarray</code> <p>actual values</p> required <code>predicted</code> <code>ndarray</code> <p>predicted values</p> required Source code in <code>churn_pred/training/metrics.py</code> <pre><code>def rmse(actual: np.ndarray, predicted: Union[np.ndarray, list]) -&gt; float:\n    \"\"\"Root Mean Squared Error\n\n    Args:\n        actual (np.ndarray): actual values\n        predicted (np.ndarray): predicted values\n    Returns:\n        rmse (float): root mean square error\n    \"\"\"\n    return mean_squared_error(actual, predicted, squared=False)\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.metrics.smape","title":"<code>smape(actual, predicted)</code>","text":"<p>Symmetric Mean Absolute Percentage Error https://vedexcel.com/how-to-calculate-smape-in-python/</p> <p>Parameters:</p> Name Type Description Default <code>actual</code> <code>ndarray</code> <p>actual values</p> required <code>predicted</code> <code>ndarray</code> <p>predicted values</p> required Source code in <code>churn_pred/training/metrics.py</code> <pre><code>def smape(actual: np.ndarray, predicted: Union[np.ndarray, list]) -&gt; float:\n    \"\"\"Symmetric Mean Absolute Percentage Error\n    https://vedexcel.com/how-to-calculate-smape-in-python/\n\n    Args:\n        actual (np.ndarray): actual values\n        predicted (np.ndarray): predicted values\n    Returns:\n        smape (float): symmetric mean absolute percentage error\n    \"\"\"\n    return (\n        100\n        / len(actual)\n        * np.sum(2 * np.abs(predicted - actual) / (np.abs(actual) + np.abs(predicted)))\n    )\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.optuna_optimizer.LGBOptunaOptimizer","title":"<code>LGBOptunaOptimizer</code>","text":"<p>             Bases: <code>BaseOptimizer</code></p> Source code in <code>churn_pred/training/optuna_optimizer.py</code> <pre><code>class LGBOptunaOptimizer(BaseOptimizer):\n    def __init__(\n        self,\n        objective: Literal[\"binary\", \"multiclass\", \"regression\"],\n        n_class: Optional[int] = None,\n    ):\n        \"\"\"Fallback/backup Optuna optimizer. Development is focused on Raytune.\n        Kepping this code as backup.\n\n        Args:\n            objective (str): objective of the model\n            n_class (int): number of classes in the dataset\n        \"\"\"\n        # Optuna does not support original lighgbm implemenattion and with a workaroud it\n        # is possible to get the binarry classfier with focal_loss(any custom loss)\n        # running but the multiclass requires changes to Optuna code, eg. this post:\n        # https://lightrun.com/answers/optuna-optuna-error-when-using-custom-metrics-in-optunaintegrationlightgbm  # noqa\n        super(LGBOptunaOptimizer, self).__init__(objective, n_class)\n        self.params = self.base_params\n\n    def optimize(self, dtrain: lgbDataset, deval: lgbDataset):\n        \"\"\"Optimize LGBM model on provided datasets.\n\n        Args:\n            dtrain (lgbDataset): training lgb dataset\n            deval (lgbDataset): evaluation lgb dataset\n        \"\"\"\n        dtrain_copy = deepcopy(dtrain)\n        deval_copy = deepcopy(deval) if deval is not None else None\n\n        tuner = LightGBMTuner(\n            params=self.params,\n            train_set=dtrain_copy,\n            valid_sets=deval_copy,\n            num_boost_round=1000,\n            callbacks=[lgb.early_stopping(stopping_rounds=50)],\n            feval=self.feval,\n            # fobj=self.fobj,\n        )\n        tuner.run()\n\n        self.best = tuner.best_params\n        # since n_estimators is not among the params that Optuna optimizes we\n        # need to add it manually. We add a high value since it will be used\n        # with early_stopping_rounds\n        self.best[\"n_estimators\"] = 1000  # type: ignore\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.optuna_optimizer.LGBOptunaOptimizer.__init__","title":"<code>__init__(objective, n_class=None)</code>","text":"<p>Fallback/backup Optuna optimizer. Development is focused on Raytune. Kepping this code as backup.</p> <p>Parameters:</p> Name Type Description Default <code>objective</code> <code>str</code> <p>objective of the model</p> required <code>n_class</code> <code>int</code> <p>number of classes in the dataset</p> <code>None</code> Source code in <code>churn_pred/training/optuna_optimizer.py</code> <pre><code>def __init__(\n    self,\n    objective: Literal[\"binary\", \"multiclass\", \"regression\"],\n    n_class: Optional[int] = None,\n):\n    \"\"\"Fallback/backup Optuna optimizer. Development is focused on Raytune.\n    Kepping this code as backup.\n\n    Args:\n        objective (str): objective of the model\n        n_class (int): number of classes in the dataset\n    \"\"\"\n    # Optuna does not support original lighgbm implemenattion and with a workaroud it\n    # is possible to get the binarry classfier with focal_loss(any custom loss)\n    # running but the multiclass requires changes to Optuna code, eg. this post:\n    # https://lightrun.com/answers/optuna-optuna-error-when-using-custom-metrics-in-optunaintegrationlightgbm  # noqa\n    super(LGBOptunaOptimizer, self).__init__(objective, n_class)\n    self.params = self.base_params\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.optuna_optimizer.LGBOptunaOptimizer.optimize","title":"<code>optimize(dtrain, deval)</code>","text":"<p>Optimize LGBM model on provided datasets.</p> <p>Parameters:</p> Name Type Description Default <code>dtrain</code> <code>Dataset</code> <p>training lgb dataset</p> required <code>deval</code> <code>Dataset</code> <p>evaluation lgb dataset</p> required Source code in <code>churn_pred/training/optuna_optimizer.py</code> <pre><code>def optimize(self, dtrain: lgbDataset, deval: lgbDataset):\n    \"\"\"Optimize LGBM model on provided datasets.\n\n    Args:\n        dtrain (lgbDataset): training lgb dataset\n        deval (lgbDataset): evaluation lgb dataset\n    \"\"\"\n    dtrain_copy = deepcopy(dtrain)\n    deval_copy = deepcopy(deval) if deval is not None else None\n\n    tuner = LightGBMTuner(\n        params=self.params,\n        train_set=dtrain_copy,\n        valid_sets=deval_copy,\n        num_boost_round=1000,\n        callbacks=[lgb.early_stopping(stopping_rounds=50)],\n        feval=self.feval,\n        # fobj=self.fobj,\n    )\n    tuner.run()\n\n    self.best = tuner.best_params\n    # since n_estimators is not among the params that Optuna optimizes we\n    # need to add it manually. We add a high value since it will be used\n    # with early_stopping_rounds\n    self.best[\"n_estimators\"] = 1000  # type: ignore\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.trainer.Trainer","title":"<code>Trainer</code>","text":"<p>             Bases: <code>BaseTrainer</code></p> Source code in <code>churn_pred/training/trainer.py</code> <pre><code>class Trainer(BaseTrainer):\n    def __init__(\n        self,\n        cat_cols: List[str],\n        target_col: str,\n        id_cols: List[str],\n        objective: Literal[\"binary\"],\n        optimizer: Union[Any, BaseOptimizer, None] = None,\n        n_class: Optional[int] = None,\n        preprocessors: Optional[List[Union[Any, PreprocessData]]] = None,\n    ):\n        \"\"\"Objects that governs training and parameter optimization of the lgbm model.\n\n        Args:\n            cat_cols (list): list of categorical feature column names\n            target_col (str): column name that represents target\n            id_cols (list): identification column names\n            objective (str): type of the task/objective\n            optimizer (BaseOptimizer): parameter optimizer object\n        \"\"\"\n        super(Trainer, self).__init__(\n            cat_cols=cat_cols,\n            target_col=target_col,\n            id_cols=id_cols,\n            objective=objective,\n            n_class=n_class,\n            preprocessors=preprocessors,\n        )\n        if optimizer is not None:\n            if not hasattr(optimizer, \"optimize\"):\n                raise AttributeError(\n                    \"{} optimizer must have {} method\".format(optimizer, \"optimize\")\n                )\n        self.optimizer = optimizer\n\n    def train(\n        self,\n        df_train: pd.DataFrame,\n        params: Optional[Dict] = None,\n        df_valid: Optional[pd.DataFrame] = None,\n    ):\n        \"\"\"Train the model with the parameters.\n\n        Args:\n            df_train (pd.DataFrame): training dataset\n            params (dict): model paramaters\n            df_valid (pd.DataFrame): optional validation dataset\n        Returns:\n            model (lgb.basic.Booster): trained model\n        \"\"\"\n        if self.preprocessors:\n            for prep in self.preprocessors:\n                df_train_prep = prep.transform(df_train.drop(columns=[self.target_col]))\n                df_valid_prep = (\n                    prep.transform(df_valid.drop(columns=[self.target_col]))\n                    if df_valid is not None\n                    else None\n                )\n            if self.objective in [\"binary\"]:\n                df_train_prep[self.target_col] = df_train[self.target_col].astype(int)\n                if df_valid is not None:\n                    df_valid_prep[self.target_col] = df_valid[self.target_col].astype(\n                        int\n                    )\n            else:\n                raise NotImplementedError\n        else:\n            df_train_prep = df_train.copy()\n            df_valid_prep = df_valid.copy() if df_valid is not None else None\n\n        cat_cols = self.cat_cols\n        if params:\n            config = params\n        elif (params is None) and (self.optimizer):\n            config = self.optimizer.best\n            if hasattr(self.optimizer, \"best_to_drop\"):\n                df_train_prep.drop(\n                    columns=self.optimizer.best_to_drop,  # type: ignore\n                    inplace=True,\n                )\n                if df_valid is not None:\n                    df_valid_prep.drop(\n                        columns=self.optimizer.best_to_drop,  # type: ignore\n                        inplace=True,\n                    )\n                cat_cols = intsec(self.cat_cols, df_train_prep.columns.values)\n\n        elif (params is None) and (self.optimizer is None):\n            config = self.base_params\n\n        lgb_train, lgb_valid = to_lgbdataset(\n            train=df_train_prep,\n            cat_cols=cat_cols,\n            target_col=self.target_col,\n            id_cols=self.id_cols,\n            valid=df_valid_prep,\n        )\n\n        self.model = lgb_train_function(\n            config=config,\n            lgbtrain=lgb_train,\n            lgbeval=lgb_valid,\n            feval=self.feval,\n        )\n\n    def fit(\n        self,\n        df_train: pd.DataFrame,\n        df_valid: pd.DataFrame,\n        df_test: pd.DataFrame,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Train the model and optimize the parameters.\n\n        Args:\n            df_train (pd.DataFrame): training dataset\n            df_valid (pd.DataFrame): validation dataset\n            df_test (pd.DataFrame): testing dataset\n        Returns:\n            model (lgb.basic.Booster): trained model\n        \"\"\"\n        if self.preprocessors:\n            # this should be\n            # df_train_prep = prep.transform(df_train_prep.drop(columns=[self.target_col]))\n            for prep in self.preprocessors:\n                df_train_prep = prep.transform(df_train.drop(columns=[self.target_col]))\n                df_valid_prep = prep.transform(df_valid.drop(columns=[self.target_col]))\n            if self.objective in [\"binary\"]:\n                df_train_prep[self.target_col] = df_train[self.target_col].astype(int)\n                df_valid_prep[self.target_col] = df_valid[self.target_col].astype(int)\n            else:\n                raise NotImplementedError\n        else:\n            df_train_prep = df_train.copy()\n            df_valid_prep = df_valid.copy()\n\n        lgb_train, lgb_valid = to_lgbdataset(\n            train=df_train_prep,\n            cat_cols=self.cat_cols,\n            target_col=self.target_col,\n            id_cols=self.id_cols,\n            valid=df_valid_prep,\n        )\n        self.optimizer.optimize(dtrain=lgb_train, deval=lgb_valid)\n\n        df_train_valid = pd.concat([df_train, df_valid], ignore_index=True)\n        df_train_valid = df_train_valid.reset_index(drop=True)\n        self.train(df_train=df_train_valid)\n        metrics_dict = self.compute_metrics(df_test)\n        return metrics_dict\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.trainer.Trainer.__init__","title":"<code>__init__(cat_cols, target_col, id_cols, objective, optimizer=None, n_class=None, preprocessors=None)</code>","text":"<p>Objects that governs training and parameter optimization of the lgbm model.</p> <p>Parameters:</p> Name Type Description Default <code>cat_cols</code> <code>list</code> <p>list of categorical feature column names</p> required <code>target_col</code> <code>str</code> <p>column name that represents target</p> required <code>id_cols</code> <code>list</code> <p>identification column names</p> required <code>objective</code> <code>str</code> <p>type of the task/objective</p> required <code>optimizer</code> <code>BaseOptimizer</code> <p>parameter optimizer object</p> <code>None</code> Source code in <code>churn_pred/training/trainer.py</code> <pre><code>def __init__(\n    self,\n    cat_cols: List[str],\n    target_col: str,\n    id_cols: List[str],\n    objective: Literal[\"binary\"],\n    optimizer: Union[Any, BaseOptimizer, None] = None,\n    n_class: Optional[int] = None,\n    preprocessors: Optional[List[Union[Any, PreprocessData]]] = None,\n):\n    \"\"\"Objects that governs training and parameter optimization of the lgbm model.\n\n    Args:\n        cat_cols (list): list of categorical feature column names\n        target_col (str): column name that represents target\n        id_cols (list): identification column names\n        objective (str): type of the task/objective\n        optimizer (BaseOptimizer): parameter optimizer object\n    \"\"\"\n    super(Trainer, self).__init__(\n        cat_cols=cat_cols,\n        target_col=target_col,\n        id_cols=id_cols,\n        objective=objective,\n        n_class=n_class,\n        preprocessors=preprocessors,\n    )\n    if optimizer is not None:\n        if not hasattr(optimizer, \"optimize\"):\n            raise AttributeError(\n                \"{} optimizer must have {} method\".format(optimizer, \"optimize\")\n            )\n    self.optimizer = optimizer\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.trainer.Trainer.fit","title":"<code>fit(df_train, df_valid, df_test)</code>","text":"<p>Train the model and optimize the parameters.</p> <p>Parameters:</p> Name Type Description Default <code>df_train</code> <code>DataFrame</code> <p>training dataset</p> required <code>df_valid</code> <code>DataFrame</code> <p>validation dataset</p> required <code>df_test</code> <code>DataFrame</code> <p>testing dataset</p> required Source code in <code>churn_pred/training/trainer.py</code> <pre><code>def fit(\n    self,\n    df_train: pd.DataFrame,\n    df_valid: pd.DataFrame,\n    df_test: pd.DataFrame,\n) -&gt; pd.DataFrame:\n    \"\"\"Train the model and optimize the parameters.\n\n    Args:\n        df_train (pd.DataFrame): training dataset\n        df_valid (pd.DataFrame): validation dataset\n        df_test (pd.DataFrame): testing dataset\n    Returns:\n        model (lgb.basic.Booster): trained model\n    \"\"\"\n    if self.preprocessors:\n        # this should be\n        # df_train_prep = prep.transform(df_train_prep.drop(columns=[self.target_col]))\n        for prep in self.preprocessors:\n            df_train_prep = prep.transform(df_train.drop(columns=[self.target_col]))\n            df_valid_prep = prep.transform(df_valid.drop(columns=[self.target_col]))\n        if self.objective in [\"binary\"]:\n            df_train_prep[self.target_col] = df_train[self.target_col].astype(int)\n            df_valid_prep[self.target_col] = df_valid[self.target_col].astype(int)\n        else:\n            raise NotImplementedError\n    else:\n        df_train_prep = df_train.copy()\n        df_valid_prep = df_valid.copy()\n\n    lgb_train, lgb_valid = to_lgbdataset(\n        train=df_train_prep,\n        cat_cols=self.cat_cols,\n        target_col=self.target_col,\n        id_cols=self.id_cols,\n        valid=df_valid_prep,\n    )\n    self.optimizer.optimize(dtrain=lgb_train, deval=lgb_valid)\n\n    df_train_valid = pd.concat([df_train, df_valid], ignore_index=True)\n    df_train_valid = df_train_valid.reset_index(drop=True)\n    self.train(df_train=df_train_valid)\n    metrics_dict = self.compute_metrics(df_test)\n    return metrics_dict\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.trainer.Trainer.train","title":"<code>train(df_train, params=None, df_valid=None)</code>","text":"<p>Train the model with the parameters.</p> <p>Parameters:</p> Name Type Description Default <code>df_train</code> <code>DataFrame</code> <p>training dataset</p> required <code>params</code> <code>dict</code> <p>model paramaters</p> <code>None</code> <code>df_valid</code> <code>DataFrame</code> <p>optional validation dataset</p> <code>None</code> Source code in <code>churn_pred/training/trainer.py</code> <pre><code>def train(\n    self,\n    df_train: pd.DataFrame,\n    params: Optional[Dict] = None,\n    df_valid: Optional[pd.DataFrame] = None,\n):\n    \"\"\"Train the model with the parameters.\n\n    Args:\n        df_train (pd.DataFrame): training dataset\n        params (dict): model paramaters\n        df_valid (pd.DataFrame): optional validation dataset\n    Returns:\n        model (lgb.basic.Booster): trained model\n    \"\"\"\n    if self.preprocessors:\n        for prep in self.preprocessors:\n            df_train_prep = prep.transform(df_train.drop(columns=[self.target_col]))\n            df_valid_prep = (\n                prep.transform(df_valid.drop(columns=[self.target_col]))\n                if df_valid is not None\n                else None\n            )\n        if self.objective in [\"binary\"]:\n            df_train_prep[self.target_col] = df_train[self.target_col].astype(int)\n            if df_valid is not None:\n                df_valid_prep[self.target_col] = df_valid[self.target_col].astype(\n                    int\n                )\n        else:\n            raise NotImplementedError\n    else:\n        df_train_prep = df_train.copy()\n        df_valid_prep = df_valid.copy() if df_valid is not None else None\n\n    cat_cols = self.cat_cols\n    if params:\n        config = params\n    elif (params is None) and (self.optimizer):\n        config = self.optimizer.best\n        if hasattr(self.optimizer, \"best_to_drop\"):\n            df_train_prep.drop(\n                columns=self.optimizer.best_to_drop,  # type: ignore\n                inplace=True,\n            )\n            if df_valid is not None:\n                df_valid_prep.drop(\n                    columns=self.optimizer.best_to_drop,  # type: ignore\n                    inplace=True,\n                )\n            cat_cols = intsec(self.cat_cols, df_train_prep.columns.values)\n\n    elif (params is None) and (self.optimizer is None):\n        config = self.base_params\n\n    lgb_train, lgb_valid = to_lgbdataset(\n        train=df_train_prep,\n        cat_cols=cat_cols,\n        target_col=self.target_col,\n        id_cols=self.id_cols,\n        valid=df_valid_prep,\n    )\n\n    self.model = lgb_train_function(\n        config=config,\n        lgbtrain=lgb_train,\n        lgbeval=lgb_valid,\n        feval=self.feval,\n    )\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.utils.get_feature_importance","title":"<code>get_feature_importance(model)</code>","text":"<p>Extract model feature importances and return sorted dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Booster</code> <p>LightGBM model</p> required <p>Returns:</p> Name Type Description <code>feature_imp</code> <code>DataFrame</code> <p>sorted dataframe with features and their importances</p> Source code in <code>churn_pred/training/utils.py</code> <pre><code>def get_feature_importance(model: lgb.basic.Booster) -&gt; pd.DataFrame:\n    \"\"\"Extract model feature importances and return sorted dataframe.\n\n    Args:\n        model (lgb.basic.Booster): LightGBM model\n\n    Returns:\n        feature_imp (pd.DataFrame): sorted dataframe with features and their\n            importances\n    \"\"\"\n    feature_imp = pd.DataFrame(\n        {\"value\": model.feature_importance(), \"feature\": model.feature_name()}\n    )\n    feature_imp.sort_values(by=\"value\", inplace=True)\n    feature_imp.reset_index(drop=True, inplace=True)\n    return feature_imp\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.utils.predict_cls_lgbm_from_raw","title":"<code>predict_cls_lgbm_from_raw(preds_raw, task)</code>","text":"<p>Helper function to convert raw margin predictions through a sigmoid to represent a probability.</p> <p>Parameters:</p> Name Type Description Default <code>preds_raw</code> <code>ndarray</code> <p>predictions</p> required <code>task</code> <code>Literal['binary', 'multiclass']</code> <p>task type</p> required Source code in <code>churn_pred/training/utils.py</code> <pre><code>def predict_cls_lgbm_from_raw(\n    preds_raw: np.ndarray, task: Literal[\"binary\", \"multiclass\"]\n) -&gt; np.ndarray:\n    \"\"\"Helper function to convert raw margin predictions through a\n    sigmoid to represent a probability.\n\n    Args:\n        preds_raw (ndarray):\n            predictions\n        task (Literal[\"binary\", \"multiclass\"]):\n            task type\n    Returns:\n        (y_true, preds):\n            tuple containg labels and predictions for further evaluation\n    \"\"\"\n    predicted_probs = predict_proba_lgbm_from_raw(preds_raw=preds_raw, task=task)\n    if task == \"binary\":\n        pred_cls = np.array([int(p &gt; 0.5) for p in predicted_probs])\n    elif task == \"multiclass\":\n        pred_cls = predicted_probs.argmax(axis=1)\n\n    return pred_cls\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.utils.predict_proba_lgbm_from_raw","title":"<code>predict_proba_lgbm_from_raw(preds_raw, task, binary2d=False)</code>","text":"<p>Apply softmax to array of arrays that is an output of lightgbm.predct(). This replaces predict_proba().</p> <p>Parameters:</p> Name Type Description Default <code>preds_raw</code> <code>ndarray</code> <p>1D numpy array of arrays</p> required <code>task</code> <code>str</code> <p>type of task/objective</p> required <code>binary2d</code> <code>boolean</code> <p>wether the output of binary classification should be 1 or 2d vector</p> <code>False</code> Source code in <code>churn_pred/training/utils.py</code> <pre><code>def predict_proba_lgbm_from_raw(\n    preds_raw: np.ndarray,\n    task: Literal[\"binary\", \"multiclass\"],\n    binary2d: Optional[bool] = False,\n) -&gt; np.ndarray:\n    \"\"\"Apply softmax to array of arrays that is an output of lightgbm.predct().\n    This replaces predict_proba().\n\n    Args:\n        preds_raw (ndarray):\n            1D numpy array of arrays\n        task (str):\n            type of task/objective\n        binary2d (boolean):\n            wether the output of binary classification should be 1 or 2d vector\n    Returns:\n        predicted_probs (ndarray): array with predicted probabilities\n    \"\"\"\n    if task == \"binary\":\n        predicted_probs = _sigmoid(preds_raw)\n        if binary2d:\n            predicted_probs = np.apply_along_axis(\n                _binary_margin_to_prob, 1, np.vstack(tuple(predicted_probs))\n            )\n    elif task == \"multiclass\":\n        predicted_probs = np.apply_along_axis(_softmax, 1, np.stack(tuple(preds_raw)))\n    return predicted_probs\n</code></pre>"},{"location":"churn_pred/training.html#churn_pred.training.utils.to_lgbdataset","title":"<code>to_lgbdataset(train, cat_cols, target_col, id_cols=[], valid=None)</code>","text":"<p>Transform pandas dataframe to lgbm dataset, or datasets(eval).</p> <p>Parameters:</p> Name Type Description Default <code>train</code> <code>DataFrame</code> <p>training dataset</p> required <code>cat_cols</code> <code>list</code> <p>list of categorical columns</p> required <code>target_col</code> <code>str</code> <p>target column in the dataset</p> required <code>id_cols</code> <code>list</code> <p>list of identifier columns</p> <code>[]</code> <code>valid</code> <code>DataFrame</code> <p>validation dataset</p> <code>None</code> Source code in <code>churn_pred/training/utils.py</code> <pre><code>def to_lgbdataset(\n    train: pd.DataFrame,\n    cat_cols: List[str],\n    target_col: str,\n    id_cols: List[str] = [],\n    valid: Optional[pd.DataFrame] = None,\n) -&gt; Tuple[lgbDataset, Optional[lgbDataset]]:\n    \"\"\"Transform pandas dataframe to lgbm dataset, or datasets(eval).\n\n    Args:\n        train (pd.DataFrame):\n            training dataset\n        cat_cols (list):\n            list of categorical columns\n        target_col (str):\n            target column in the dataset\n        id_cols (list):\n            list of identifier columns\n        valid (pd.DataFrame):\n            validation dataset\n    Returns:\n        lgb_train (lgbDataset):\n            lgbm training dataset\n        lgb_valid (lgbDataset):\n            lgbm valid dataset\n    \"\"\"\n\n    lgb_train = lgbDataset(\n        train.drop(columns=[target_col] + id_cols),\n        train[target_col],\n        categorical_feature=cat_cols,\n        free_raw_data=False,\n    )\n\n    if valid is not None:\n        lgb_valid = lgbDataset(\n            valid.drop(columns=[target_col] + id_cols),\n            valid[target_col],\n            reference=lgb_train,\n            free_raw_data=False,\n        )\n    else:\n        lgb_valid = None\n\n    return lgb_train, lgb_valid\n</code></pre>"},{"location":"notebooks/00_auxiliary_features.html","title":"00_auxiliary_features","text":"In\u00a0[1]: Copied! <pre>import os\nimport sys\n\nsys.path.append(os.getcwd())\nos.chdir(\"../..\")\n\nimport pandas as pd\nfrom churn_pred.preprocessing import auxiliary_data, preprocess_text\nimport spacy_fastlang\n</pre> import os import sys  sys.path.append(os.getcwd()) os.chdir(\"../..\")  import pandas as pd from churn_pred.preprocessing import auxiliary_data, preprocess_text import spacy_fastlang In\u00a0[2]: Copied! <pre>df_pd = pd.read_csv(\"data/dataset.csv\")\ndf_pd.head()\n</pre> df_pd = pd.read_csv(\"data/dataset.csv\") df_pd.head() Out[2]: RowNumber CustomerId Surname CreditScore Country Gender Age Tenure CustomerFeedback Balance (EUR) NumberOfProducts HasCreditCard IsActiveMember EstimatedSalary Exited 0 747 15787619 Hsieh 844 France Male 18 2 I can not link my card to any third-party plat... 160980.03 1 0 0 145936.28 0 1 1620 15770309 McDonald 656 France Male 18 10 Last week, I reached out to my bank's support ... 151762.74 1 0 1 127014.32 0 2 1679 15569178 Kharlamov 570 France Female 18 4 NaN 82767.42 1 1 0 71811.90 0 3 2022 15795519 Vasiliev 716 Germany Female 18 3 NaN 128743.80 1 0 0 197322.13 0 4 2137 15621893 Bellucci 727 France Male 18 4 Yo, I gotta give some love to this bank's cust... 133550.67 1 1 1 46941.41 0 In\u00a0[3]: Copied! <pre>df_pd = preprocess_text.text_cleaning(df=df_pd, text_col=\"CustomerFeedback\")\ndf_pd = preprocess_text.language_detection(\n    df=df_pd, text_col=\"CustomerFeedback\", model_type=\"fasttext\"\n)\n</pre> df_pd = preprocess_text.text_cleaning(df=df_pd, text_col=\"CustomerFeedback\") df_pd = preprocess_text.language_detection(     df=df_pd, text_col=\"CustomerFeedback\", model_type=\"fasttext\" ) <pre>Cleaning Progress: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10000/10000 [00:34&lt;00:00, 287.95it/s]\nWarning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n</pre> In\u00a0[4]: Copied! <pre>df_pd.head()\n</pre> df_pd.head() Out[4]: RowNumber CustomerId Surname CreditScore Country Gender Age Tenure CustomerFeedback Balance (EUR) NumberOfProducts HasCreditCard IsActiveMember EstimatedSalary Exited CustomerFeedback_language CustomerFeedback_language_score 0 747 15787619 Hsieh 844 France Male 18 2 link card _IS_PUNCT_ party platform _IS_PUNCT_ 160980.03 1 0 0 145936.28 0 en 0.786177 1 1620 15770309 McDonald 656 France Male 18 10 week _IS_PUNCT_ reach bank support team confus... 151762.74 1 0 1 127014.32 0 en 0.911405 2 1679 15569178 Kharlamov 570 France Female 18 4 nan 82767.42 1 1 0 71811.90 0 ht 0.974604 3 2022 15795519 Vasiliev 716 Germany Female 18 3 nan 128743.80 1 0 0 197322.13 0 ht 0.974604 4 2137 15621893 Bellucci 727 France Male 18 4 Yo _IS_PUNCT_ get to love bank customer servic... 133550.67 1 1 1 46941.41 0 en 0.758962 In\u00a0[5]: Copied! <pre>df_pd[df_pd[\"CustomerFeedback\"].astype(str) != \"nan\"][\n    \"CustomerFeedback_language\"\n].unique()\n</pre> df_pd[df_pd[\"CustomerFeedback\"].astype(str) != \"nan\"][     \"CustomerFeedback_language\" ].unique() Out[5]: <pre>array(['en'], dtype=object)</pre> In\u00a0[6]: Copied! <pre>df_pd[\n    (df_pd[\"CustomerFeedback\"].astype(str) != \"nan\")\n    &amp; (df_pd[\"CustomerFeedback_language_score\"] &lt; 0.5)\n]\n</pre> df_pd[     (df_pd[\"CustomerFeedback\"].astype(str) != \"nan\")     &amp; (df_pd[\"CustomerFeedback_language_score\"] &lt; 0.5) ] Out[6]: RowNumber CustomerId Surname CreditScore Country Gender Age Tenure CustomerFeedback Balance (EUR) NumberOfProducts HasCreditCard IsActiveMember EstimatedSalary Exited CustomerFeedback_language CustomerFeedback_language_score 105 2866 15590228 Greenwalt 715 France Male 21 6 hsi 76467.16 1 1 1 173511.72 0 en 0.124504 6270 7107 15723989 Carroll 646 France Male 40 5 fund accessible anticipate date _IS_PUNCT_ _IS... 93680.43 2 1 1 179473.26 0 en 0.468742 In\u00a0[7]: Copied! <pre>df_pd.loc[105, [\"CustomerFeedback\"]] = \"nan\"\n</pre> df_pd.loc[105, [\"CustomerFeedback\"]] = \"nan\" In\u00a0[8]: Copied! <pre>df_pd[df_pd[\"CustomerFeedback\"].astype(str) != \"nan\"][\n    \"CustomerFeedback_language_score\"\n].plot.hist(bins=50)\n</pre> df_pd[df_pd[\"CustomerFeedback\"].astype(str) != \"nan\"][     \"CustomerFeedback_language_score\" ].plot.hist(bins=50) Out[8]: <pre>&lt;Axes: ylabel='Frequency'&gt;</pre> In\u00a0[9]: Copied! <pre>df_pd[[\"CustomerFeedback_sentiment3\", \"CustomerFeedback_sentiment3_score\"]] = (\n    preprocess_text.sentiment_analysis(\n        df=df_pd, text_col=\"CustomerFeedback\", sentiment_depth=3\n    )[[\"CustomerFeedback_sentiment\", \"CustomerFeedback_sentiment_score\"]]\n)\ndf_pd.head()\n</pre> df_pd[[\"CustomerFeedback_sentiment3\", \"CustomerFeedback_sentiment3_score\"]] = (     preprocess_text.sentiment_analysis(         df=df_pd, text_col=\"CustomerFeedback\", sentiment_depth=3     )[[\"CustomerFeedback_sentiment\", \"CustomerFeedback_sentiment_score\"]] ) df_pd.head() <pre>Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n</pre> Out[9]: RowNumber CustomerId Surname CreditScore Country Gender Age Tenure CustomerFeedback Balance (EUR) NumberOfProducts HasCreditCard IsActiveMember EstimatedSalary Exited CustomerFeedback_language CustomerFeedback_language_score CustomerFeedback_sentiment3 CustomerFeedback_sentiment3_score 0 747 15787619 Hsieh 844 France Male 18 2 link card _IS_PUNCT_ party platform _IS_PUNCT_ 160980.03 1 0 0 145936.28 0 en 0.786177 neutral 0.827256 1 1620 15770309 McDonald 656 France Male 18 10 week _IS_PUNCT_ reach bank support team confus... 151762.74 1 0 1 127014.32 0 en 0.911405 neutral 0.671348 2 1679 15569178 Kharlamov 570 France Female 18 4 nan 82767.42 1 1 0 71811.90 0 ht 0.974604 neutral 0.680865 3 2022 15795519 Vasiliev 716 Germany Female 18 3 nan 128743.80 1 0 0 197322.13 0 ht 0.974604 neutral 0.680865 4 2137 15621893 Bellucci 727 France Male 18 4 Yo _IS_PUNCT_ get to love bank customer servic... 133550.67 1 1 1 46941.41 0 en 0.758962 positive 0.878306 In\u00a0[10]: Copied! <pre>df_pd[[\"CustomerFeedback_sentiment5\", \"CustomerFeedback_sentiment5_score\"]] = (\n    preprocess_text.sentiment_analysis(\n        df=df_pd, text_col=\"CustomerFeedback\", sentiment_depth=5\n    )[[\"CustomerFeedback_sentiment\", \"CustomerFeedback_sentiment_score\"]]\n)\ndf_pd.head()\n</pre> df_pd[[\"CustomerFeedback_sentiment5\", \"CustomerFeedback_sentiment5_score\"]] = (     preprocess_text.sentiment_analysis(         df=df_pd, text_col=\"CustomerFeedback\", sentiment_depth=5     )[[\"CustomerFeedback_sentiment\", \"CustomerFeedback_sentiment_score\"]] ) df_pd.head() Out[10]: RowNumber CustomerId Surname CreditScore Country Gender Age Tenure CustomerFeedback Balance (EUR) ... HasCreditCard IsActiveMember EstimatedSalary Exited CustomerFeedback_language CustomerFeedback_language_score CustomerFeedback_sentiment3 CustomerFeedback_sentiment3_score CustomerFeedback_sentiment5 CustomerFeedback_sentiment5_score 0 747 15787619 Hsieh 844 France Male 18 2 link card _IS_PUNCT_ party platform _IS_PUNCT_ 160980.03 ... 0 0 145936.28 0 en 0.786177 neutral 0.827256 4 stars 0.259499 1 1620 15770309 McDonald 656 France Male 18 10 week _IS_PUNCT_ reach bank support team confus... 151762.74 ... 0 1 127014.32 0 en 0.911405 neutral 0.671348 1 star 0.359483 2 1679 15569178 Kharlamov 570 France Female 18 4 nan 82767.42 ... 1 0 71811.90 0 ht 0.974604 neutral 0.680865 2 stars 0.260568 3 2022 15795519 Vasiliev 716 Germany Female 18 3 nan 128743.80 ... 0 0 197322.13 0 ht 0.974604 neutral 0.680865 2 stars 0.260568 4 2137 15621893 Bellucci 727 France Male 18 4 Yo _IS_PUNCT_ get to love bank customer servic... 133550.67 ... 1 1 46941.41 0 en 0.758962 positive 0.878306 1 star 0.291449 <p>5 rows \u00d7 21 columns</p> In\u00a0[11]: Copied! <pre># save intermediate results\ndf_pd.to_parquet(\"data/dataset_sentiment.parquet\")\n</pre> # save intermediate results df_pd.to_parquet(\"data/dataset_sentiment.parquet\") In\u00a0[3]: Copied! <pre># df_pd = pd.read_parquet(\"data/dataset_sentiment.parquet\")\n</pre> # df_pd = pd.read_parquet(\"data/dataset_sentiment.parquet\") In\u00a0[12]: Copied! <pre>df_pd[\"Surname\" + \"_Country\"] = auxiliary_data.surname_origin(\n    df=df_pd, surname_col=\"Surname\"\n)\ndf_pd.head()\n</pre> df_pd[\"Surname\" + \"_Country\"] = auxiliary_data.surname_origin(     df=df_pd, surname_col=\"Surname\" ) df_pd.head() Out[12]: RowNumber CustomerId Surname CreditScore Country Gender Age Tenure CustomerFeedback Balance (EUR) ... IsActiveMember EstimatedSalary Exited CustomerFeedback_language CustomerFeedback_language_score CustomerFeedback_sentiment3 CustomerFeedback_sentiment3_score CustomerFeedback_sentiment5 CustomerFeedback_sentiment5_score Surname_Country 0 747 15787619 Hsieh 844 France Male 18 2 link card _IS_PUNCT_ party platform _IS_PUNCT_ 160980.03 ... 0 145936.28 0 en 0.786177 neutral 0.827256 4 stars 0.259499 Taiwan, Province of China 1 1620 15770309 McDonald 656 France Male 18 10 week _IS_PUNCT_ reach bank support team confus... 151762.74 ... 1 127014.32 0 en 0.911405 neutral 0.671348 1 star 0.359483 United States 2 1679 15569178 Kharlamov 570 France Female 18 4 nan 82767.42 ... 0 71811.90 0 ht 0.974604 neutral 0.680865 2 stars 0.260568 Russian Federation 3 2022 15795519 Vasiliev 716 Germany Female 18 3 nan 128743.80 ... 0 197322.13 0 ht 0.974604 neutral 0.680865 2 stars 0.260568 Russian Federation 4 2137 15621893 Bellucci 727 France Male 18 4 Yo _IS_PUNCT_ get to love bank customer servic... 133550.67 ... 1 46941.41 0 en 0.758962 positive 0.878306 1 star 0.291449 Italy <p>5 rows \u00d7 22 columns</p> In\u00a0[13]: Copied! <pre>df_pd[(df_pd[\"Surname_Country\"] == \"NA\")][\"Surname\"].nunique()\n</pre> df_pd[(df_pd[\"Surname_Country\"] == \"NA\")][\"Surname\"].nunique() Out[13]: <pre>496</pre> <p>less than 500 so I can use Namsor free trial to get data, I will use their online csv tool and not API function<code>auxiliary_data.surname_origin_namsor</code> to avoid wasting another email address for free trail</p> In\u00a0[6]: Copied! <pre>namsor_csv = pd.DataFrame(\n    {\"Surname\": df_pd[(df_pd[\"Surname_Country\"] == \"NA\")][\"Surname\"].unique()}\n)\nnamsor_csv[\"first_name\"] = \"unset\"\nnamsor_csv.to_csv(\"data/surnames/surnames_for_namsor.csv\", index=False)\n</pre> namsor_csv = pd.DataFrame(     {\"Surname\": df_pd[(df_pd[\"Surname_Country\"] == \"NA\")][\"Surname\"].unique()} ) namsor_csv[\"first_name\"] = \"unset\" namsor_csv.to_csv(\"data/surnames/surnames_for_namsor.csv\", index=False) <p>after namsor processing</p> In\u00a0[14]: Copied! <pre># keep_default_na=False as NA-Namibia is intrepreted as NaN\nnamsor_surnames = pd.read_csv(\n    \"data/surnames/namsor_name-origin_surnames_for_namsor.csv\",\n    keep_default_na=False,\n    na_values=[\"_\"],\n)\nnamsor_surnames = namsor_surnames[[\"lastName\", \"countryOrigin\"]].rename(\n    columns={\"lastName\": \"Surname\", \"countryOrigin\": \"Surname_Country_namsor\"}\n)\n</pre> # keep_default_na=False as NA-Namibia is intrepreted as NaN namsor_surnames = pd.read_csv(     \"data/surnames/namsor_name-origin_surnames_for_namsor.csv\",     keep_default_na=False,     na_values=[\"_\"], ) namsor_surnames = namsor_surnames[[\"lastName\", \"countryOrigin\"]].rename(     columns={\"lastName\": \"Surname\", \"countryOrigin\": \"Surname_Country_namsor\"} ) In\u00a0[15]: Copied! <pre>namsor_surnames[\"Surname_Country_namsor\"] = auxiliary_data.get_country_name(\n    df=namsor_surnames, country_name_col=\"Surname_Country_namsor\"\n)\nnamsor_surnames.head()\n</pre> namsor_surnames[\"Surname_Country_namsor\"] = auxiliary_data.get_country_name(     df=namsor_surnames, country_name_col=\"Surname_Country_namsor\" ) namsor_surnames.head() Out[15]: Surname Surname_Country_namsor 0 Vaguine France 1 Onyekaozulu Nigeria 2 Chiazagomekpele Nigeria 3 Fleetwood-Smith United Kingdom 4 Anayolisa Nigeria In\u00a0[16]: Copied! <pre>df_pd = df_pd.merge(namsor_surnames, on=\"Surname\", how=\"left\")\n</pre> df_pd = df_pd.merge(namsor_surnames, on=\"Surname\", how=\"left\") In\u00a0[17]: Copied! <pre>df_pd.loc[(df_pd[\"Surname_Country\"] == \"NA\"), \"Surname_Country\"] = df_pd.loc[\n    (df_pd[\"Surname_Country\"] == \"NA\"), \"Surname_Country_namsor\"\n]\n</pre> df_pd.loc[(df_pd[\"Surname_Country\"] == \"NA\"), \"Surname_Country\"] = df_pd.loc[     (df_pd[\"Surname_Country\"] == \"NA\"), \"Surname_Country_namsor\" ] In\u00a0[18]: Copied! <pre>df_pd = df_pd.drop(columns=[\"Surname_Country_namsor\"])\n</pre> df_pd = df_pd.drop(columns=[\"Surname_Country_namsor\"]) In\u00a0[19]: Copied! <pre>df_pd[\"Surname_Country\"].unique()\n</pre> df_pd[\"Surname_Country\"].unique() Out[19]: <pre>array(['Taiwan, Province of China', 'United States', 'Russian Federation',\n       'Italy', 'Macao', 'Ireland', 'United Kingdom', 'Nigeria', 'France',\n       'Algeria', 'Germany', 'Malaysia', 'Mexico', 'Hong Kong', 'China',\n       'Israel', 'Kazakhstan', 'Colombia', 'Lesotho', 'Saudi Arabia',\n       'Uruguay', 'Togo', 'Ethiopia', 'Spain', 'Egypt', 'Ukraine',\n       'Lebanon', 'Zimbabwe', 'India', 'Thailand', 'Brazil', 'Panama',\n       'T\u00fcrkiye', \"C\u00f4te d'Ivoire\", 'South Africa', 'Azerbaijan', 'Congo',\n       'Czechia', 'Burkina Faso', 'Uzbekistan', 'Morocco', 'Ghana',\n       'Portugal', 'Austria', 'Sri Lanka', 'Bulgaria', 'Norway', 'Greece',\n       'Estonia', 'Bangladesh', 'Viet Nam', 'Netherlands', 'Cameroon',\n       'Sweden', 'Costa Rica', 'Japan', 'Liberia', 'Myanmar',\n       'Brunei Darussalam', 'Canada', 'Moldova, Republic of', 'Denmark',\n       'Benin', 'Niger', 'Latvia', 'Finland', 'Chile', 'Poland',\n       'Switzerland', 'Mozambique', 'Indonesia', 'Rwanda', 'Argentina',\n       'Namibia', 'Belgium', 'Botswana', 'Romania', 'Mali', 'Belarus',\n       'Cyprus', 'Palestine, State of', 'Hungary', 'Mauritius',\n       'Pakistan', 'Senegal', 'Slovakia', 'Iran, Islamic Republic of',\n       'Malawi', 'Jamaica'], dtype=object)</pre> In\u00a0[20]: Copied! <pre>country_info_problematic_vals = {\n    \"Iran, Islamic Republic of\": \"Iran\",\n    \"Moldova, Republic of\": \"Moldova\",\n    \"Taiwan, Province of China\": \"Taiwan\",\n    \"Czechia\": \"Czech republic\",\n    \"C\u00f4te d'Ivoire\": \"Ivory Coast\",\n    \"Brunei Darussalam\": \"Brunei\",\n    \"Viet Nam\": \"Vietnam\",\n    \"Macao\": \"Macau\",\n    \"T\u00fcrkiye\": \"Turkey\",\n    \"Congo\": \"Democratic Republic of the Congo\",\n    \"Palestine, State of\": \"Palestine\",\n}\ndf_pd[\"Surname_Country\"] = df_pd[\"Surname_Country\"].replace(\n    country_info_problematic_vals\n)\n</pre> country_info_problematic_vals = {     \"Iran, Islamic Republic of\": \"Iran\",     \"Moldova, Republic of\": \"Moldova\",     \"Taiwan, Province of China\": \"Taiwan\",     \"Czechia\": \"Czech republic\",     \"C\u00f4te d'Ivoire\": \"Ivory Coast\",     \"Brunei Darussalam\": \"Brunei\",     \"Viet Nam\": \"Vietnam\",     \"Macao\": \"Macau\",     \"T\u00fcrkiye\": \"Turkey\",     \"Congo\": \"Democratic Republic of the Congo\",     \"Palestine, State of\": \"Palestine\", } df_pd[\"Surname_Country\"] = df_pd[\"Surname_Country\"].replace(     country_info_problematic_vals ) In\u00a0[21]: Copied! <pre>df_pd[[\"Surname_Country_region\", \"Surname_Country_subregion\"]] = (\n    auxiliary_data.get_country_region_subregion(\n        df=df_pd, country_name_col=\"Surname_Country\"\n    )\n)\n</pre> df_pd[[\"Surname_Country_region\", \"Surname_Country_subregion\"]] = (     auxiliary_data.get_country_region_subregion(         df=df_pd, country_name_col=\"Surname_Country\"     ) ) In\u00a0[22]: Copied! <pre>df_pd[\n    (df_pd[\"Surname_Country_region\"] == \"NA\")\n    | (df_pd[\"Surname_Country_subregion\"] == \"NA\")\n][[\"Surname_Country\", \"Surname_Country_region\", \"Surname_Country_subregion\"]]\n</pre> df_pd[     (df_pd[\"Surname_Country_region\"] == \"NA\")     | (df_pd[\"Surname_Country_subregion\"] == \"NA\") ][[\"Surname_Country\", \"Surname_Country_region\", \"Surname_Country_subregion\"]] Out[22]: Surname_Country Surname_Country_region Surname_Country_subregion 2024 Myanmar NA NA 3322 Myanmar NA NA 4237 Myanmar NA NA 4626 Myanmar NA NA 4892 Myanmar NA NA 5348 Palestine NA NA 6190 Myanmar NA NA 7064 Myanmar NA NA 7098 Myanmar NA NA 7693 Myanmar NA NA 7895 Myanmar NA NA 8299 Myanmar NA NA 8789 Myanmar NA NA 9600 Myanmar NA NA In\u00a0[23]: Copied! <pre># https://en.wikipedia.org/wiki/Palestine_(region) - 'Western Asia' to follow countryinfo naming\ndf_pd.loc[\n    df_pd[\"Surname_Country\"] == \"Palestine\",\n    [\"Surname_Country_region\", \"Surname_Country_subregion\"],\n] = (\"Asia\", \"Western Asia\")\n# https://en.wikipedia.org/wiki/Myanmar - 'South-Eastern Asia' to follow countryinfo naming\ndf_pd.loc[\n    df_pd[\"Surname_Country\"] == \"Myanmar\",\n    [\"Surname_Country_region\", \"Surname_Country_subregion\"],\n] = (\"Asia\", \"South-Eastern Asia\")\n\ndf_pd[\n    (df_pd[\"Surname_Country_region\"] == \"NA\")\n    | (df_pd[\"Surname_Country_subregion\"] == \"NA\")\n]\n</pre> # https://en.wikipedia.org/wiki/Palestine_(region) - 'Western Asia' to follow countryinfo naming df_pd.loc[     df_pd[\"Surname_Country\"] == \"Palestine\",     [\"Surname_Country_region\", \"Surname_Country_subregion\"], ] = (\"Asia\", \"Western Asia\") # https://en.wikipedia.org/wiki/Myanmar - 'South-Eastern Asia' to follow countryinfo naming df_pd.loc[     df_pd[\"Surname_Country\"] == \"Myanmar\",     [\"Surname_Country_region\", \"Surname_Country_subregion\"], ] = (\"Asia\", \"South-Eastern Asia\")  df_pd[     (df_pd[\"Surname_Country_region\"] == \"NA\")     | (df_pd[\"Surname_Country_subregion\"] == \"NA\") ] Out[23]: RowNumber CustomerId Surname CreditScore Country Gender Age Tenure CustomerFeedback Balance (EUR) ... Exited CustomerFeedback_language CustomerFeedback_language_score CustomerFeedback_sentiment3 CustomerFeedback_sentiment3_score CustomerFeedback_sentiment5 CustomerFeedback_sentiment5_score Surname_Country Surname_Country_region Surname_Country_subregion <p>0 rows \u00d7 24 columns</p> In\u00a0[24]: Copied! <pre>df_pd[[\"Country_region\", \"Country_subregion\"]] = (\n    auxiliary_data.get_country_region_subregion(df=df_pd, country_name_col=\"Country\")\n)\n</pre> df_pd[[\"Country_region\", \"Country_subregion\"]] = (     auxiliary_data.get_country_region_subregion(df=df_pd, country_name_col=\"Country\") ) In\u00a0[25]: Copied! <pre>df_pd[(df_pd[\"Country_region\"] == \"NA\") | (df_pd[\"Country_subregion\"] == \"NA\")][\n    [\"Country\", \"Country_region\", \"Country_subregion\"]\n]\n</pre> df_pd[(df_pd[\"Country_region\"] == \"NA\") | (df_pd[\"Country_subregion\"] == \"NA\")][     [\"Country\", \"Country_region\", \"Country_subregion\"] ] Out[25]: Country Country_region Country_subregion In\u00a0[26]: Copied! <pre>df_pd[\"is_native\"] = (df_pd[\"Surname_Country\"] == df_pd[\"Country\"]).astype(int)\n</pre> df_pd[\"is_native\"] = (df_pd[\"Surname_Country\"] == df_pd[\"Country\"]).astype(int) In\u00a0[27]: Copied! <pre># no need to know the hemisphere of the surname origin country...\ndf_pd = auxiliary_data.hemisphere(df=df_pd, cc_col=\"Country\").rename(\n    columns={\"hemisphere\": \"Country_hemisphere\"}\n)\n</pre> # no need to know the hemisphere of the surname origin country... df_pd = auxiliary_data.hemisphere(df=df_pd, cc_col=\"Country\").rename(     columns={\"hemisphere\": \"Country_hemisphere\"} ) In\u00a0[28]: Copied! <pre>df_pd = auxiliary_data.gdppc(df=df_pd, country_name_col=\"Country\").rename(\n    columns={\n        \"gdp_per_capita\": \"Country_gdp_per_capita\",\n        \"IncomeGroup\": \"Country_IncomeGroup\",\n    }\n)\ndf_pd = auxiliary_data.gdppc(df=df_pd, country_name_col=\"Surname_Country\").rename(\n    columns={\n        \"gdp_per_capita\": \"Surname_Country_gdp_per_capita\",\n        \"IncomeGroup\": \"Surname_Country_IncomeGroup\",\n    }\n)\n</pre> df_pd = auxiliary_data.gdppc(df=df_pd, country_name_col=\"Country\").rename(     columns={         \"gdp_per_capita\": \"Country_gdp_per_capita\",         \"IncomeGroup\": \"Country_IncomeGroup\",     } ) df_pd = auxiliary_data.gdppc(df=df_pd, country_name_col=\"Surname_Country\").rename(     columns={         \"gdp_per_capita\": \"Surname_Country_gdp_per_capita\",         \"IncomeGroup\": \"Surname_Country_IncomeGroup\",     } ) <pre>/home/jovyan/assignment/ecovadis_assignment/churn_pred/preprocessing/auxiliary_data.py:283: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  gdp_per_capita.rename(columns={\"Country Code\": \"iso_a3\"}, inplace=True)\n/home/jovyan/assignment/ecovadis_assignment/churn_pred/preprocessing/auxiliary_data.py:284: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  gdp_per_capita[\"gdp_per_capita\"] = gdp_per_capita_raw.drop(columns=[\"Country Name\", \"Country Code\", \"Indicator Name\", \"Indicator Code\"]).ffill(axis=1).iloc[:, -1]\n/home/jovyan/assignment/ecovadis_assignment/churn_pred/preprocessing/auxiliary_data.py:283: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  gdp_per_capita.rename(columns={\"Country Code\": \"iso_a3\"}, inplace=True)\n/home/jovyan/assignment/ecovadis_assignment/churn_pred/preprocessing/auxiliary_data.py:284: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  gdp_per_capita[\"gdp_per_capita\"] = gdp_per_capita_raw.drop(columns=[\"Country Name\", \"Country Code\", \"Indicator Name\", \"Indicator Code\"]).ffill(axis=1).iloc[:, -1]\n</pre> <pre>SubdivisionHierarchy(code='MX-MEX', country_code='MX', name='M\u00e9xico', parent_code=None, type='State')\nSubdivisionHierarchy(code='PA-8', country_code='PA', name='Panam\u00e1', parent_code=None, type='Province')\nSubdivisionHierarchy(code='NG-NI', country_code='NG', name='Niger', parent_code=None, type='State')\nSubdivisionHierarchy(code='GN-ML', country_code='GN', name='Mali', parent='L', parent_code='GN-L', type='Prefecture')\n</pre> In\u00a0[29]: Copied! <pre>df_pd = auxiliary_data.age_categories(df=df_pd, age_col=\"Age\")\n</pre> df_pd = auxiliary_data.age_categories(df=df_pd, age_col=\"Age\") In\u00a0[30]: Copied! <pre>df_pd[df_pd[\"Surname_Country_gdp_per_capita\"].isna()][\"Surname_Country\"].unique()\n</pre> df_pd[df_pd[\"Surname_Country_gdp_per_capita\"].isna()][\"Surname_Country\"].unique() Out[30]: <pre>array(['Taiwan', 'Macau', 'Turkey', 'Ivory Coast',\n       'Democratic Republic of the Congo'], dtype=object)</pre> In\u00a0[31]: Copied! <pre># Taiwan is missing info in worldbank but it is present e.g. here https://www.ceicdata.com/en/indicator/taiwan/gdp-per-capita\ndf_pd.loc[df_pd[\"Surname_Country\"] == \"Taiwan\", [\"Surname_Country_gdp_per_capita\"]] = (\n    32756.0\n)\n# remaining countries have some naming issues - ToBeResolved; e.g. Macau -&gt; Macao, Turkey -&gt; Turkiye, etc\ndf_pd.loc[df_pd[\"Surname_Country\"] == \"Macau\", [\"Surname_Country_gdp_per_capita\"]] = (\n    61230.96247\n)\ndf_pd.loc[df_pd[\"Surname_Country\"] == \"Turkey\", [\"Surname_Country_gdp_per_capita\"]] = (\n    38355.15397\n)\ndf_pd.loc[\n    df_pd[\"Surname_Country\"] == \"Ivory Coast\", [\"Surname_Country_gdp_per_capita\"]\n] = 6540.462355\ndf_pd.loc[\n    df_pd[\"Surname_Country\"] == \"Democratic Republic of the Congo\",\n    [\"Surname_Country_gdp_per_capita\"],\n] = 1337.834149\n</pre> # Taiwan is missing info in worldbank but it is present e.g. here https://www.ceicdata.com/en/indicator/taiwan/gdp-per-capita df_pd.loc[df_pd[\"Surname_Country\"] == \"Taiwan\", [\"Surname_Country_gdp_per_capita\"]] = (     32756.0 ) # remaining countries have some naming issues - ToBeResolved; e.g. Macau -&gt; Macao, Turkey -&gt; Turkiye, etc df_pd.loc[df_pd[\"Surname_Country\"] == \"Macau\", [\"Surname_Country_gdp_per_capita\"]] = (     61230.96247 ) df_pd.loc[df_pd[\"Surname_Country\"] == \"Turkey\", [\"Surname_Country_gdp_per_capita\"]] = (     38355.15397 ) df_pd.loc[     df_pd[\"Surname_Country\"] == \"Ivory Coast\", [\"Surname_Country_gdp_per_capita\"] ] = 6540.462355 df_pd.loc[     df_pd[\"Surname_Country\"] == \"Democratic Republic of the Congo\",     [\"Surname_Country_gdp_per_capita\"], ] = 1337.834149 In\u00a0[32]: Copied! <pre>df_pd.to_parquet(\"data/dataset_auxiliary_features_raw.parquet\")\n</pre> df_pd.to_parquet(\"data/dataset_auxiliary_features_raw.parquet\") In\u00a0[33]: Copied! <pre>df_pd.columns\n</pre> df_pd.columns Out[33]: <pre>Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Country',\n       'Gender', 'Age', 'Tenure', 'CustomerFeedback', 'Balance (EUR)',\n       'NumberOfProducts', 'HasCreditCard', 'IsActiveMember',\n       'EstimatedSalary', 'Exited', 'CustomerFeedback_language',\n       'CustomerFeedback_language_score', 'CustomerFeedback_sentiment3',\n       'CustomerFeedback_sentiment3_score', 'CustomerFeedback_sentiment5',\n       'CustomerFeedback_sentiment5_score', 'Surname_Country',\n       'Surname_Country_region', 'Surname_Country_subregion', 'Country_region',\n       'Country_subregion', 'is_native', 'Country_hemisphere',\n       'Country_gdp_per_capita', 'Country_IncomeGroup',\n       'Surname_Country_gdp_per_capita', 'Surname_Country_IncomeGroup',\n       'working_class', 'stage_of_life', 'generation'],\n      dtype='object')</pre> In\u00a0[34]: Copied! <pre>df_pd.drop(\n    columns=[\n        \"RowNumber\",\n        \"Surname\",\n        \"CustomerFeedback\",\n        \"CustomerFeedback_language\",\n        \"CustomerFeedback_language_score\",\n        \"CustomerFeedback_sentiment3_score\",\n        \"CustomerFeedback_sentiment5_score\",\n    ]\n).to_parquet(\"data/dataset_auxiliary_features_cleaned.parquet\")\n</pre> df_pd.drop(     columns=[         \"RowNumber\",         \"Surname\",         \"CustomerFeedback\",         \"CustomerFeedback_language\",         \"CustomerFeedback_language_score\",         \"CustomerFeedback_sentiment3_score\",         \"CustomerFeedback_sentiment5_score\",     ] ).to_parquet(\"data/dataset_auxiliary_features_cleaned.parquet\")"},{"location":"notebooks/00_auxiliary_features.html#add-auxiliary-features-to-the-dataset","title":"Add auxiliary features to the dataset\u00b6","text":"<p><code>sudo apt install nvidia-utils-535</code> to get GPU running</p>"},{"location":"notebooks/00_auxiliary_features.html#sentiment-analysis","title":"Sentiment analysis\u00b6","text":""},{"location":"notebooks/00_auxiliary_features.html#cleaning-and-langauge-detection","title":"Cleaning and langauge detection\u00b6","text":""},{"location":"notebooks/00_auxiliary_features.html#sentiment-analysis-prediction","title":"Sentiment analysis prediction\u00b6","text":""},{"location":"notebooks/00_auxiliary_features.html#surname-origin-country","title":"Surname origin country\u00b6","text":""},{"location":"notebooks/00_auxiliary_features.html#additional-country-info","title":"Additional country info\u00b6","text":""},{"location":"notebooks/00_auxiliary_features.html#country-region-and-subregion","title":"Country region and subregion\u00b6","text":""},{"location":"notebooks/00_auxiliary_features.html#native-or-not","title":"Native or not\u00b6","text":"<ul> <li>if the client is possibly an immigrant(from immigrant family?) or not</li> </ul>"},{"location":"notebooks/00_auxiliary_features.html#country-hemisphere","title":"Country hemisphere\u00b6","text":"<ul> <li>could be usefull with some timestamp combination to know the season(oposite season in hemispeheres) etc.; anything that might affect mood/behaviour</li> </ul>"},{"location":"notebooks/00_auxiliary_features.html#country-gdpp","title":"Country gdpp\u00b6","text":"<ul> <li>check 'wealthiness' of the current and origin country</li> </ul>"},{"location":"notebooks/00_auxiliary_features.html#additional-age-info","title":"Additional age info\u00b6","text":""},{"location":"notebooks/00_auxiliary_features.html#appendix-tbd","title":"Appendix [TBD]\u00b6","text":"<ul> <li>analyze score and probabilities of the sentiment and country detection methods</li> <li>make an object or procedure to do this automatically</li> </ul>"},{"location":"notebooks/00_auxiliary_features_surname_origin_country_classification.html","title":"TBD_00_auxiliary_features_surname_origin_country_classification.ipynb","text":"In\u00a0[1]: Copied! <pre>import os\nimport sys\n\nsys.path.append(os.getcwd())\nos.chdir(\"../../...\")\n\nimport pandas as pd\nimport torch\nfrom churn_pred.preprocessing import surname_classification\nfrom churn_pred import utils\nfrom torch.utils.data import DataLoader\nimport pickle\nfrom transformers import (\n    BertForSequenceClassification,\n    get_linear_schedule_with_warmup,\n    BertTokenizer,\n)\nfrom transformers import BertForSequenceClassification\n</pre> import os import sys  sys.path.append(os.getcwd()) os.chdir(\"../../...\")  import pandas as pd import torch from churn_pred.preprocessing import surname_classification from churn_pred import utils from torch.utils.data import DataLoader import pickle from transformers import (     BertForSequenceClassification,     get_linear_schedule_with_warmup,     BertTokenizer, ) from transformers import BertForSequenceClassification In\u00a0[2]: Copied! <pre>surname_data = pd.read_csv(\"data/surnames/surname-nationality.csv\")\nsplitted_data = pd.read_csv(\"data/surnames/surnames_with_splits.csv\")\n</pre> surname_data = pd.read_csv(\"data/surnames/surname-nationality.csv\") splitted_data = pd.read_csv(\"data/surnames/surnames_with_splits.csv\") In\u00a0[5]: Copied! <pre>splitted_data\n</pre> splitted_data Out[5]: nationality nationality_index split surname 0 Arabic 15 train Totah 1 Arabic 15 train Abboud 2 Arabic 15 train Fakhoury 3 Arabic 15 train Srour 4 Arabic 15 train Sayegh ... ... ... ... ... 10975 Vietnamese 11 test Dinh 10976 Vietnamese 11 test Phung 10977 Vietnamese 11 test Quang 10978 Vietnamese 11 test Vu 10979 Vietnamese 11 test Ha <p>10980 rows \u00d7 4 columns</p> In\u00a0[6]: Copied! <pre>surname_data.surname.nunique()\n</pre> surname_data.surname.nunique() Out[6]: <pre>30923</pre> In\u00a0[4]: Copied! <pre>splitted_data[\"nationality_index\"]\n</pre> splitted_data[\"nationality_index\"] Out[4]: <pre>0        15\n1        15\n2        15\n3        15\n4        15\n         ..\n10975    11\n10976    11\n10977    11\n10978    11\n10979    11\nName: nationality_index, Length: 10980, dtype: int64</pre> In\u00a0[3]: Copied! <pre>labeld_decoder = dict(\n    zip(splitted_data[\"nationality\"], splitted_data[\"nationality_index\"])\n)\ninverse_label_dict = {v: k for k, v in labeld_decoder.items()}\n</pre> labeld_decoder = dict(     zip(splitted_data[\"nationality\"], splitted_data[\"nationality_index\"]) ) inverse_label_dict = {v: k for k, v in labeld_decoder.items()} In\u00a0[4]: Copied! <pre># Split data into train, validation, and test sets\ntrain_df = splitted_data[splitted_data[\"split\"] == \"train\"]\nval_df = splitted_data[\n    splitted_data[\"split\"] == \"val\"\n]  # Assuming \"val\" is used for validation set\ntest_df = splitted_data[splitted_data[\"split\"] == \"test\"]\n</pre> # Split data into train, validation, and test sets train_df = splitted_data[splitted_data[\"split\"] == \"train\"] val_df = splitted_data[     splitted_data[\"split\"] == \"val\" ]  # Assuming \"val\" is used for validation set test_df = splitted_data[splitted_data[\"split\"] == \"test\"] In\u00a0[5]: Copied! <pre># Tokenize each dataset\ntrain_encodings = surname_classification.tokenize_data(train_df)\nval_encodings = surname_classification.tokenize_data(val_df)\ntest_encodings = surname_classification.tokenize_data(test_df)\n</pre> # Tokenize each dataset train_encodings = surname_classification.tokenize_data(train_df) val_encodings = surname_classification.tokenize_data(val_df) test_encodings = surname_classification.tokenize_data(test_df) In\u00a0[8]: Copied! <pre>batch_size = 32\n\ntrain_dataset = surname_classification.create_dataset(train_encodings, train_df)\nval_dataset = surname_classification.create_dataset(val_encodings, val_df)\ntest_dataset = surname_classification.create_dataset(test_encodings, test_df)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n</pre> batch_size = 32  train_dataset = surname_classification.create_dataset(train_encodings, train_df) val_dataset = surname_classification.create_dataset(val_encodings, val_df) test_dataset = surname_classification.create_dataset(test_encodings, test_df)  train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) val_dataloader = DataLoader(val_dataset, batch_size=batch_size) test_dataloader = DataLoader(test_dataset, batch_size=batch_size) In\u00a0[9]: Copied! <pre>num_labels = splitted_data[\"nationality_index\"].nunique()\nnum_epochs = 10\nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-cased\", num_labels=num_labels, hidden_dropout_prob=0.4\n)\n# freeze layers\nfor param in model.bert.parameters():\n    param.requires_grad = False\n\noptimizer = surname_classification.create_optimizer(model, learning_rate=5e-5, eps=1e-8)\ntotal_steps = len(train_dataloader) * num_epochs\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0.2,  # Usually a fraction of total_steps\n    num_training_steps=total_steps,\n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n</pre> num_labels = splitted_data[\"nationality_index\"].nunique() num_epochs = 10 model = BertForSequenceClassification.from_pretrained(     \"bert-base-cased\", num_labels=num_labels, hidden_dropout_prob=0.4 ) # freeze layers for param in model.bert.parameters():     param.requires_grad = False  optimizer = surname_classification.create_optimizer(model, learning_rate=5e-5, eps=1e-8) total_steps = len(train_dataloader) * num_epochs  scheduler = get_linear_schedule_with_warmup(     optimizer,     num_warmup_steps=0.2,  # Usually a fraction of total_steps     num_training_steps=total_steps, )  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") model.to(device) <pre>Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/mnt/c/#work/ecovadis/ecovadis/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n</pre> Out[9]: <pre>BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.4, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.4, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.4, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.4, inplace=False)\n  (classifier): Linear(in_features=768, out_features=18, bias=True)\n)</pre> In\u00a0[10]: Copied! <pre>trained_model = surname_classification.train_model(\n    model,\n    train_dataloader,\n    val_dataloader,\n    optimizer,\n    scheduler,\n    device,\n    num_epochs=num_epochs,\n)\n</pre> trained_model = surname_classification.train_model(     model,     train_dataloader,     val_dataloader,     optimizer,     scheduler,     device,     num_epochs=num_epochs, ) <p>log from running a script on a server</p> <pre><code>(ecovadis) pmulinka@supercom-wssonata:~/assignment/ecovadis_assignment$ python notebooks/eda/surname_classification_with_bert.py\n/home/pmulinka/assignment/ecovadis_assignment\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/home/pmulinka/assignment/ecovadis/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\nEpoch 1/10\nTraining Loss: 2.394\nValidation Loss: 2.256, Validation Accuracy: 0.267\n\nEpoch 2/10\nTraining Loss: 2.267\nValidation Loss: 2.251, Validation Accuracy: 0.267\n\nEpoch 3/10\nTraining Loss: 2.265\nValidation Loss: 2.243, Validation Accuracy: 0.306\n\nEpoch 4/10\nTraining Loss: 2.250\nValidation Loss: 2.237, Validation Accuracy: 0.385\n\nEpoch 5/10\nTraining Loss: 2.251\nValidation Loss: 2.227, Validation Accuracy: 0.317\n\nEpoch 6/10\nTraining Loss: 1.620\nValidation Loss: 0.982, Validation Accuracy: 0.735\n\nEpoch 7/10\nTraining Loss: 1.062\nValidation Loss: 0.826, Validation Accuracy: 0.772\n\nEpoch 8/10\nTraining Loss: 0.911\nValidation Loss: 0.799, Validation Accuracy: 0.785\n\nEpoch 9/10\nTraining Loss: 0.832\nValidation Loss: 0.775, Validation Accuracy: 0.791\n\nEpoch 10/10\nTraining Loss: 0.780\nValidation Loss: 0.768, Validation Accuracy: 0.790\nTraining complete\nEvaluation on test dataset yield\nLoss: 0.7684005849206677\nAccuracy: 0.7960164835164836\n</code></pre> In\u00a0[\u00a0]: Copied! <pre>loss, accuracy = surname_classification.evaluate_model(\n    trained_model, test_dataloader, device\n)\nprint(f\"Evaluation on test dataset yield\\nLoss: {loss}\\nAccuracy: {accuracy}\")\n</pre> loss, accuracy = surname_classification.evaluate_model(     trained_model, test_dataloader, device ) print(f\"Evaluation on test dataset yield\\nLoss: {loss}\\nAccuracy: {accuracy}\") In\u00a0[8]: Copied! <pre>inverse_label_dict\n</pre> inverse_label_dict Out[8]: <pre>{15: 'Arabic',\n 3: 'Chinese',\n 5: 'Czech',\n 2: 'Dutch',\n 12: 'English',\n 8: 'French',\n 9: 'German',\n 4: 'Greek',\n 1: 'Irish',\n 17: 'Italian',\n 7: 'Japanese',\n 16: 'Korean',\n 14: 'Polish',\n 0: 'Portuguese',\n 13: 'Russian',\n 10: 'Scottish',\n 6: 'Spanish',\n 11: 'Vietnamese'}</pre> In\u00a0[7]: Copied! <pre>utils.dill_dump(\n    file_loc=\"data/surnames/inverse_label_dict.dill\", content=inverse_label_dict\n)\ninverse_label_dict = utils.dill_load(file_loc=\"data/surnames/inverse_label_dict.dill\")\n</pre> utils.dill_dump(     file_loc=\"data/surnames/inverse_label_dict.dill\", content=inverse_label_dict ) inverse_label_dict = utils.dill_load(file_loc=\"data/surnames/inverse_label_dict.dill\") In\u00a0[\u00a0]: Copied! <pre># Save the model\ntorch.save(trained_model.state_dict(), \"surname_model_state_dict.pth\")\ntorch.save(trained_model, \"data/surnames/surname_model.pth\")\nutils.json_dump(\n    file_loc=\"data/surnames/inverse_label_dict.json\", content=inverse_label_dict\n)\n</pre> # Save the model torch.save(trained_model.state_dict(), \"surname_model_state_dict.pth\") torch.save(trained_model, \"data/surnames/surname_model.pth\") utils.json_dump(     file_loc=\"data/surnames/inverse_label_dict.json\", content=inverse_label_dict ) In\u00a0[10]: Copied! <pre># Load the model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntrained_model = torch.load(\"data/surnames/surname_model.pth\", map_location=device)\ninverse_label_dict = utils.dill_load(file_loc=\"data/surnames/inverse_label_dict.dill\")\n# model.eval()\n# trained_model.load_state_dict(torch.load(\"surname_model.pth\"))\n</pre> # Load the model device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") trained_model = torch.load(\"data/surnames/surname_model.pth\", map_location=device) inverse_label_dict = utils.dill_load(file_loc=\"data/surnames/inverse_label_dict.dill\") # model.eval() # trained_model.load_state_dict(torch.load(\"surname_model.pth\")) In\u00a0[15]: Copied! <pre>predicted_surnames\n</pre> predicted_surnames Out[15]: <pre>[('Hsieh', 'English'),\n ('McDonald', 'Spanish'),\n ('Kharlamov', 'Arabic'),\n ('Vasiliev', 'English'),\n ('Bellucci', 'English'),\n ('Wallace', 'English'),\n ('Chao', 'Chinese'),\n ('Boylan', 'English'),\n ('Burgess', 'Chinese'),\n ('Cattaneo', 'English')]</pre> In\u00a0[14]: Copied! <pre>df_pd = pd.read_csv(\"data/dataset.csv\")\nuq_surnames = df_pd.Surname.unique()\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\npredicted_surnames = surname_classification.predict_nationality(\n    trained_model, uq_surnames[:10], tokenizer, inverse_label_dict, device\n)\n</pre> df_pd = pd.read_csv(\"data/dataset.csv\") uq_surnames = df_pd.Surname.unique() tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") predicted_surnames = surname_classification.predict_nationality(     trained_model, uq_surnames[:10], tokenizer, inverse_label_dict, device ) <pre>Predicting Nationalities:   0%|          | 0/10 [00:00&lt;?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/mnt/c/#work/ecovadis/ecovadis/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n                                                                         \r</pre> In\u00a0[\u00a0]: Copied! <pre>predicted_df = pd.DataFrame(predicted_surnames, columns=[\"Surname\", \"Nationality\"])\npredicted_df.to_csv(\"predicted_surnames_dataset.csv\")\npredicted_df.head()\n</pre> predicted_df = pd.DataFrame(predicted_surnames, columns=[\"Surname\", \"Nationality\"]) predicted_df.to_csv(\"predicted_surnames_dataset.csv\") predicted_df.head() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/00_auxiliary_features_surname_origin_country_classification.html#this-is-a-work-in-progress","title":"THIS IS A WORK IN PROGRESS\u00b6","text":""},{"location":"notebooks/00_auxiliary_features_surname_origin_country_classification.html#surname-origin-country-classification","title":"Surname origin country classification\u00b6","text":"<ul> <li>approach shamelessly copied from https://www.kaggle.com/code/yonatankpl/surname-classification-with-bert</li> <li>NOTE from author:</li> </ul> <pre><code>Based on the discussion [here](https://www.kaggle.com/competitions/playground-series-s4e1/discussion/465517), I created a Bert based Surname classifier.\n</code></pre> <ul> <li>possible improvement of the base dataset by scraping wiki: https://github.com/greenelab/wiki-nationality-estimate</li> </ul>"},{"location":"notebooks/01_feature_analysis.html","title":"01_feature_analysis","text":"In\u00a0[1]: Copied! <pre>import os\nimport sys\n\nsys.path.append(os.getcwd())\nos.chdir(\"../..\")\n\nimport pandas as pd\n\n# import plotly.graph_objects as go\nfrom churn_pred.eda.features.analysis import (\n    missing,\n    zero,\n    nunique,\n    init_check,\n    std,\n    entropy,\n    nunique,\n)\n\npd.set_option(\"display.max_columns\", 100)\npd.set_option(\"display.max_rows\", 300)\nfrom churn_pred.eda.features.plotting import cross_correlation, distributions\n</pre> import os import sys  sys.path.append(os.getcwd()) os.chdir(\"../..\")  import pandas as pd  # import plotly.graph_objects as go from churn_pred.eda.features.analysis import (     missing,     zero,     nunique,     init_check,     std,     entropy,     nunique, )  pd.set_option(\"display.max_columns\", 100) pd.set_option(\"display.max_rows\", 300) from churn_pred.eda.features.plotting import cross_correlation, distributions In\u00a0[2]: Copied! <pre>df_pd = pd.read_parquet(\"data/dataset_auxiliary_features_cleaned.parquet\")\ndf_pd.head()\n</pre> df_pd = pd.read_parquet(\"data/dataset_auxiliary_features_cleaned.parquet\") df_pd.head() Out[2]: CustomerId CreditScore Country Gender Age Tenure Balance (EUR) NumberOfProducts HasCreditCard IsActiveMember EstimatedSalary Exited CustomerFeedback_sentiment3 CustomerFeedback_sentiment5 Surname_Country Surname_Country_region Surname_Country_subregion Country_region Country_subregion is_native Country_hemisphere Country_gdp_per_capita Country_IncomeGroup Surname_Country_gdp_per_capita Surname_Country_IncomeGroup working_class stage_of_life generation 0 15787619 844 France Male 18 2 160980.03 1 0 0 145936.28 0 neutral 4 stars Taiwan Asia Eastern Asia Europe Western Europe 0 northern 57594.03402 High income 32756.00000 None working_age teen gen_z 1 15770309 656 France Male 18 10 151762.74 1 0 1 127014.32 0 neutral 1 star United States Americas Northern America Europe Western Europe 0 northern 57594.03402 High income 76329.58227 High income working_age teen gen_z 2 15569178 570 France Female 18 4 82767.42 1 1 0 71811.90 0 neutral 2 stars Russian Federation Europe Eastern Europe Europe Western Europe 0 northern 57594.03402 High income 34637.76172 Upper middle income working_age teen gen_z 3 15795519 716 Germany Female 18 3 128743.80 1 0 0 197322.13 0 neutral 2 stars Russian Federation Europe Eastern Europe Europe Western Europe 0 northern 66616.02225 High income 34637.76172 Upper middle income working_age teen gen_z 4 15621893 727 France Male 18 4 133550.67 1 1 1 46941.41 0 positive 1 star Italy Europe Southern Europe Europe Western Europe 0 northern 57594.03402 High income 55442.07843 High income working_age teen gen_z In\u00a0[3]: Copied! <pre>target_col = \"Exited\"\nid_cols = [\"CustomerId\"]\ncat_cols = [\n    \"Country\",\n    \"Gender\",\n    \"HasCreditCard\",\n    \"IsActiveMember\",\n    \"CustomerFeedback_sentiment3\",\n    \"CustomerFeedback_sentiment5\",\n    \"Surname_Country\",\n    \"Surname_Country_region\",\n    \"Surname_Country_subregion\",\n    \"Country_region\",\n    \"Country_subregion\",\n    \"is_native\",\n    \"Country_hemisphere\",\n    \"Country_IncomeGroup\",\n    \"Surname_Country_IncomeGroup\",\n    \"working_class\",\n    \"stage_of_life\",\n    \"generation\",\n]\ncont_cols = df_pd.drop(\n    columns=id_cols + cat_cols + [target_col]\n).columns.values.tolist()\n</pre> target_col = \"Exited\" id_cols = [\"CustomerId\"] cat_cols = [     \"Country\",     \"Gender\",     \"HasCreditCard\",     \"IsActiveMember\",     \"CustomerFeedback_sentiment3\",     \"CustomerFeedback_sentiment5\",     \"Surname_Country\",     \"Surname_Country_region\",     \"Surname_Country_subregion\",     \"Country_region\",     \"Country_subregion\",     \"is_native\",     \"Country_hemisphere\",     \"Country_IncomeGroup\",     \"Surname_Country_IncomeGroup\",     \"working_class\",     \"stage_of_life\",     \"generation\", ] cont_cols = df_pd.drop(     columns=id_cols + cat_cols + [target_col] ).columns.values.tolist() In\u00a0[4]: Copied! <pre>df_pd[cat_cols] = df_pd[cat_cols].astype(str)\n</pre> df_pd[cat_cols] = df_pd[cat_cols].astype(str) In\u00a0[5]: Copied! <pre>duplicated_ids, cont_cols_desc, cat_cols_desc = init_check(\n    df=df_pd,\n    identifier=id_cols,\n    cat_cols=cat_cols,\n    cont_cols=cont_cols,\n    verbose=True,\n)\n\n# duplicated_ids, cont_cols_desc.head(), cat_cols_desc.head()\n</pre> duplicated_ids, cont_cols_desc, cat_cols_desc = init_check(     df=df_pd,     identifier=id_cols,     cat_cols=cat_cols,     cont_cols=cont_cols,     verbose=True, )  # duplicated_ids, cont_cols_desc.head(), cat_cols_desc.head() <pre>[CHECK] Number of duplicated ids: 0\n[CHECK] Numerical columns\n                                  count       mean       std       min  \\\nAge                             10000.0      38.92     10.49     18.00   \nEstimatedSalary                 10000.0  100090.24  57510.49     11.58   \nBalance (EUR)                   10000.0   76485.89  62397.41      0.00   \nCreditScore                     10000.0     650.53     96.65    350.00   \nTenure                          10000.0       5.01      2.89      0.00   \nCountry_gdp_per_capita          10000.0   57651.01   6330.96  48685.50   \nNumberOfProducts                10000.0       1.53      0.58      1.00   \nSurname_Country_gdp_per_capita  10000.0   51228.52  25976.50   1337.83   \n\n                                     25%        50%        75%        max  \nAge                                32.00      37.00      44.00      92.00  \nEstimatedSalary                 51002.11  100193.91  149388.25  199992.48  \nBalance (EUR)                       0.00   97198.54  127644.24  250898.09  \nCreditScore                       584.00     652.00     718.00     850.00  \nTenure                              3.00       5.00       7.00      10.00  \nCountry_gdp_per_capita          57594.03   57594.03   66616.02   66616.02  \nNumberOfProducts                    1.00       1.00       2.00       4.00  \nSurname_Country_gdp_per_capita  33525.30   57460.51   76329.58  133822.76  \n[CHECK] Categorical columns\n                             count unique               top   freq\nGender                       10000      2              Male   5457\nSurname_Country_subregion    10000     18  Northern America   2410\nCountry_subregion            10000      2    Western Europe   7523\nCountry_hemisphere           10000      1          northern  10000\nCountry_region               10000      1            Europe  10000\nis_native                    10000      2                 0   9914\nSurname_Country              10000     89     United States   2401\nCustomerFeedback_sentiment3  10000      3           neutral   8352\nSurname_Country_region       10000      4            Europe   4392\nworking_class                10000      2       working_age   9736\nstage_of_life                10000      4             adult   6330\nIsActiveMember               10000      2                 1   5151\nCustomerFeedback_sentiment5  10000      5           2 stars   7121\nHasCreditCard                10000      2                 1   7055\ngeneration                   10000      6       millennials   6367\nCountry_IncomeGroup          10000      1       High income  10000\nSurname_Country_IncomeGroup  10000      5       High income   6686\nCountry                      10000      3            France   5014\n</pre> In\u00a0[6]: Copied! <pre>missing_val_frac, fig = missing(\n    df=df_pd.drop(columns=id_cols),\n    scale=\"linear\",\n    plot=True,\n)\n\nmissing_val_frac.head()\n</pre> missing_val_frac, fig = missing(     df=df_pd.drop(columns=id_cols),     scale=\"linear\",     plot=True, )  missing_val_frac.head() Out[6]: <pre>CreditScore                    0.0\nSurname_Country_region         0.0\nstage_of_life                  0.0\nworking_class                  0.0\nSurname_Country_IncomeGroup    0.0\ndtype: float64</pre> In\u00a0[7]: Copied! <pre>zero_val_frac, fig = zero(\n    df=df_pd.drop(columns=id_cols),\n    scale=\"linear\",\n    plot=True,\n)\n\nzero_val_frac.head()\n</pre> zero_val_frac, fig = zero(     df=df_pd.drop(columns=id_cols),     scale=\"linear\",     plot=True, )  zero_val_frac.head() Out[7]: <pre>Exited                       0.7963\nBalance (EUR)                0.3617\nTenure                       0.0413\nCreditScore                  0.0000\nSurname_Country_subregion    0.0000\ndtype: float64</pre> In\u00a0[8]: Copied! <pre>data_nunique, fig = nunique(\n    df=df_pd.drop(columns=id_cols),\n    scale=\"log\",\n    plot=True,\n)\n\ndata_nunique.head()\n</pre> data_nunique, fig = nunique(     df=df_pd.drop(columns=id_cols),     scale=\"log\",     plot=True, )  data_nunique.head() Out[8]: <pre>Country_IncomeGroup    1\nCountry_hemisphere     1\nCountry_region         1\nIsActiveMember         2\nis_native              2\ndtype: int64</pre> In\u00a0[9]: Copied! <pre>data_std, fig = std(\n    df=df_pd[cont_cols],\n    scale=\"log\",\n    plot=True,\n)\n\ndata_std.head()\n</pre> data_std, fig = std(     df=df_pd[cont_cols],     scale=\"log\",     plot=True, )  data_std.head() Out[9]: <pre>Balance (EUR)                     62397.405202\nEstimatedSalary                   57510.492818\nSurname_Country_gdp_per_capita    25976.502611\nCountry_gdp_per_capita             6330.960841\nCreditScore                          96.653299\ndtype: float64</pre> In\u00a0[10]: Copied! <pre>col_entropies, fig = entropy(\n    df=df_pd.drop(columns=id_cols),\n    scale=\"linear\",\n    plot=True,\n)\n\ncol_entropies.head()\n</pre> col_entropies, fig = entropy(     df=df_pd.drop(columns=id_cols),     scale=\"linear\",     plot=True, )  col_entropies.head() Out[10]: <pre>EstimatedSalary    9.210202\nBalance (EUR)      6.246510\nCreditScore        5.873574\nAge                3.677614\nSurname_Country    2.481289\ndtype: float64</pre> In\u00a0[11]: Copied! <pre>fig = cross_correlation(df=df_pd[cont_cols], n=10, verbose=True)\n</pre> fig = cross_correlation(df=df_pd[cont_cols], n=10, verbose=True) <pre>Top 10 absolute correlations\nBalance (EUR)     Country_gdp_per_capita            0.329762\n                  NumberOfProducts                  0.304180\nAge               NumberOfProducts                  0.030680\n                  Country_gdp_per_capita            0.029999\n                  Balance (EUR)                     0.028308\nTenure            Surname_Country_gdp_per_capita    0.017138\nNumberOfProducts  EstimatedSalary                   0.014204\nTenure            NumberOfProducts                  0.013444\nBalance (EUR)     EstimatedSalary                   0.012797\nTenure            Balance (EUR)                     0.012254\ndtype: float64\n</pre> In\u00a0[12]: Copied! <pre>fig = distributions(\n    df=df_pd[cont_cols],\n    low_per_cut=0,\n    high_per_cut=1,\n    type=\"box\",\n)\n</pre> fig = distributions(     df=df_pd[cont_cols],     low_per_cut=0,     high_per_cut=1,     type=\"box\", )"},{"location":"notebooks/01_feature_analysis.html#feature-analysis","title":"Feature analysis\u00b6","text":"<p>Purpose:</p> <ul> <li>analyse dataset features without inclusion of target value<ul> <li>if it looks healthy<ul> <li>duplicate values</li> <li>NA values</li> <li>zero/0 values</li> </ul> </li> <li>if the values are \"too constant\", ie. most [robably bad features for classifcation/regression<ul> <li>small std values</li> <li>entropy is too high/too low(not sure right now?) - \"Entropy is a measure of disorder or uncertainty\"</li> <li>number of unique values in categorical features is too high - most probably they are unable to identify any group of targets</li> </ul> </li> <li>drop highly correlated values<ul> <li>to improve performance of the model training</li> <li>to decrease dataset size for further exploration</li> </ul> </li> </ul> </li> </ul>"},{"location":"notebooks/01_feature_analysis.html#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/01_feature_analysis.html#dataset","title":"Dataset\u00b6","text":""},{"location":"notebooks/01_feature_analysis.html#features","title":"Features\u00b6","text":""},{"location":"notebooks/01_feature_analysis.html#analysis","title":"Analysis\u00b6","text":""},{"location":"notebooks/01_feature_analysis.html#plotting","title":"Plotting\u00b6","text":""},{"location":"notebooks/02_target_analysis.html","title":"02_target_analysis","text":"In\u00a0[1]: Copied! <pre>import os\nimport sys\n\nsys.path.append(os.getcwd())\nos.chdir(\"../..\")\n\nimport pandas as pd\nfrom churn_pred.eda.target.analysis import correlation\nfrom churn_pred.eda.target.plotting import (\n    distributions_in_binary_cls,\n)\n</pre> import os import sys  sys.path.append(os.getcwd()) os.chdir(\"../..\")  import pandas as pd from churn_pred.eda.target.analysis import correlation from churn_pred.eda.target.plotting import (     distributions_in_binary_cls, ) In\u00a0[2]: Copied! <pre>df_pd = pd.read_parquet(\"data/dataset_auxiliary_features_cleaned.parquet\")\ndf_pd.head()\n</pre> df_pd = pd.read_parquet(\"data/dataset_auxiliary_features_cleaned.parquet\") df_pd.head() Out[2]: CustomerId CreditScore Country Gender Age Tenure Balance (EUR) NumberOfProducts HasCreditCard IsActiveMember ... Country_subregion is_native Country_hemisphere Country_gdp_per_capita Country_IncomeGroup Surname_Country_gdp_per_capita Surname_Country_IncomeGroup working_class stage_of_life generation 0 15787619 844 France Male 18 2 160980.03 1 0 0 ... Western Europe 0 northern 57594.03402 High income 32756.00000 None working_age teen gen_z 1 15770309 656 France Male 18 10 151762.74 1 0 1 ... Western Europe 0 northern 57594.03402 High income 76329.58227 High income working_age teen gen_z 2 15569178 570 France Female 18 4 82767.42 1 1 0 ... Western Europe 0 northern 57594.03402 High income 34637.76172 Upper middle income working_age teen gen_z 3 15795519 716 Germany Female 18 3 128743.80 1 0 0 ... Western Europe 0 northern 66616.02225 High income 34637.76172 Upper middle income working_age teen gen_z 4 15621893 727 France Male 18 4 133550.67 1 1 1 ... Western Europe 0 northern 57594.03402 High income 55442.07843 High income working_age teen gen_z <p>5 rows \u00d7 28 columns</p> In\u00a0[3]: Copied! <pre>target_col = \"Exited\"\nid_cols = [\"CustomerId\"]\ncat_cols = [\n    \"Country\",\n    \"Gender\",\n    \"HasCreditCard\",\n    \"IsActiveMember\",\n    \"CustomerFeedback_sentiment3\",\n    \"CustomerFeedback_sentiment5\",\n    \"Surname_Country\",\n    \"Surname_Country_region\",\n    \"Surname_Country_subregion\",\n    \"Country_region\",\n    \"Country_subregion\",\n    \"is_native\",\n    \"Country_hemisphere\",\n    \"Country_IncomeGroup\",\n    \"Surname_Country_IncomeGroup\",\n    \"working_class\",\n    \"stage_of_life\",\n    \"generation\",\n]\ncont_cols = df_pd.drop(\n    columns=id_cols + cat_cols + [target_col]\n).columns.values.tolist()\n</pre> target_col = \"Exited\" id_cols = [\"CustomerId\"] cat_cols = [     \"Country\",     \"Gender\",     \"HasCreditCard\",     \"IsActiveMember\",     \"CustomerFeedback_sentiment3\",     \"CustomerFeedback_sentiment5\",     \"Surname_Country\",     \"Surname_Country_region\",     \"Surname_Country_subregion\",     \"Country_region\",     \"Country_subregion\",     \"is_native\",     \"Country_hemisphere\",     \"Country_IncomeGroup\",     \"Surname_Country_IncomeGroup\",     \"working_class\",     \"stage_of_life\",     \"generation\", ] cont_cols = df_pd.drop(     columns=id_cols + cat_cols + [target_col] ).columns.values.tolist() In\u00a0[4]: Copied! <pre>df_pd[cat_cols] = df_pd[cat_cols].astype(str)\n</pre> df_pd[cat_cols] = df_pd[cat_cols].astype(str) In\u00a0[5]: Copied! <pre>sorted_corr_cols, fig = correlation(\n    df=df_pd[cont_cols],\n    target=df_pd[target_col],\n    scale=\"linear\",\n    plot=True,\n)\n\nsorted_corr_cols.head()\n</pre> sorted_corr_cols, fig = correlation(     df=df_pd[cont_cols],     target=df_pd[target_col],     scale=\"linear\",     plot=True, )  sorted_corr_cols.head() Out[5]: <pre>Age                               0.285323\nCountry_gdp_per_capita            0.139180\nBalance (EUR)                     0.118533\nEstimatedSalary                   0.012097\nSurname_Country_gdp_per_capita    0.002470\nName: Exited, dtype: float64</pre> In\u00a0[6]: Copied! <pre>fig = distributions_in_binary_cls(\n    df=df_pd[cont_cols],\n    target=df_pd[target_col],\n    low_per_cut=0,\n    high_per_cut=1,\n)\n</pre> fig = distributions_in_binary_cls(     df=df_pd[cont_cols],     target=df_pd[target_col],     low_per_cut=0,     high_per_cut=1, )"},{"location":"notebooks/02_target_analysis.html#target-analysis","title":"Target analysis\u00b6","text":"<p>Purpose:</p> <ul> <li>put features into context with predicted or actual target values<ul> <li>analyse feature distribution per group in binary classification</li> <li>check correlation of features with target value</li> </ul> </li> <li>check 'certainty' of the model predictions by plotting <code>prob_distrib_per_class</code> to see how certain the model is in predicting each class</li> <li>visually check predicted vs actual(ground truth values)<ul> <li>by simple scatter plot</li> <li>by 'improved scatter plot' (<code>joint_dist</code>) - this can be usefull if the actual values form a cluster (eg. regression applied to clusters of users) and we want check if the model predictions also form a nice cluster with similar distribution as actual values</li> </ul> </li> </ul> <p>Intended use:</p> <ul> <li>check how your model is perfroming</li> <li>check the possible connection between feature and target values (eg. if the distributions of features are different for each class)</li> </ul>"},{"location":"notebooks/02_target_analysis.html#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/02_target_analysis.html#dataset","title":"Dataset\u00b6","text":""},{"location":"notebooks/02_target_analysis.html#analysis","title":"Analysis\u00b6","text":""},{"location":"notebooks/02_target_analysis.html#plotting","title":"Plotting\u00b6","text":"<p>Predicted and actual/ground_truth values were gathered using LightGBM with Optuna optimizer on the dataset</p>"},{"location":"notebooks/03_models.html","title":"03_models","text":"In\u00a0[1]: Copied! <pre>import os\nimport sys\n\nsys.path.append(os.getcwd())\nos.chdir(\"..\")\n\nimport pandas as pd\n\npd.set_option(\"display.max_columns\", 200)\npd.set_option(\"display.max_rows\", 300)\n</pre> import os import sys  sys.path.append(os.getcwd()) os.chdir(\"..\")  import pandas as pd  pd.set_option(\"display.max_columns\", 200) pd.set_option(\"display.max_rows\", 300) In\u00a0[2]: Copied! <pre>import dill\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport h2o\nfrom h2o.automl import H2OAutoML\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, RocCurveDisplay, roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\n\nimport lightgbm as lgbm\nfrom churn_pred.preprocessing.scaler import scaler_mapper\nfrom churn_pred.training.utils import (\n    predict_cls_lgbm_from_raw,\n    predict_proba_lgbm_from_raw,\n)\nfrom churn_pred.preprocessing.label_encoder import LabelEncoder\n\n# import tracemalloc\n# import warnings\n# from typing import Optional, Dict\n# tracemalloc.start()\n</pre> import dill import numpy as np import matplotlib.pyplot as plt  import h2o from h2o.automl import H2OAutoML  from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report, RocCurveDisplay, roc_auc_score from sklearn.linear_model import LogisticRegression  import lightgbm as lgbm from churn_pred.preprocessing.scaler import scaler_mapper from churn_pred.training.utils import (     predict_cls_lgbm_from_raw,     predict_proba_lgbm_from_raw, ) from churn_pred.preprocessing.label_encoder import LabelEncoder  # import tracemalloc # import warnings # from typing import Optional, Dict # tracemalloc.start() In\u00a0[3]: Copied! <pre>valid_size = 0.2\ntest_size = 0.5\nrandom_state = 1\ntest_n_valid_combined = True\n</pre> valid_size = 0.2 test_size = 0.5 random_state = 1 test_n_valid_combined = True In\u00a0[4]: Copied! <pre>df_pd = pd.read_parquet(\"data/dataset_auxiliary_features_cleaned.parquet\")\ndf_pd.head()\n</pre> df_pd = pd.read_parquet(\"data/dataset_auxiliary_features_cleaned.parquet\") df_pd.head() Out[4]: CustomerId CreditScore Country Gender Age Tenure Balance (EUR) NumberOfProducts HasCreditCard IsActiveMember EstimatedSalary Exited CustomerFeedback_sentiment3 CustomerFeedback_sentiment5 Surname_Country Surname_Country_region Surname_Country_subregion Country_region Country_subregion is_native Country_hemisphere Country_gdp_per_capita Country_IncomeGroup Surname_Country_gdp_per_capita Surname_Country_IncomeGroup working_class stage_of_life generation 0 15787619 844 France Male 18 2 160980.03 1 0 0 145936.28 0 neutral 4 stars Taiwan Asia Eastern Asia Europe Western Europe 0 northern 57594.03402 High income 32756.00000 None working_age teen gen_z 1 15770309 656 France Male 18 10 151762.74 1 0 1 127014.32 0 neutral 1 star United States Americas Northern America Europe Western Europe 0 northern 57594.03402 High income 76329.58227 High income working_age teen gen_z 2 15569178 570 France Female 18 4 82767.42 1 1 0 71811.90 0 neutral 2 stars Russian Federation Europe Eastern Europe Europe Western Europe 0 northern 57594.03402 High income 34637.76172 Upper middle income working_age teen gen_z 3 15795519 716 Germany Female 18 3 128743.80 1 0 0 197322.13 0 neutral 2 stars Russian Federation Europe Eastern Europe Europe Western Europe 0 northern 66616.02225 High income 34637.76172 Upper middle income working_age teen gen_z 4 15621893 727 France Male 18 4 133550.67 1 1 1 46941.41 0 positive 1 star Italy Europe Southern Europe Europe Western Europe 0 northern 57594.03402 High income 55442.07843 High income working_age teen gen_z In\u00a0[5]: Copied! <pre>target_col = \"Exited\"\nid_cols = [\"CustomerId\"]\ncat_cols = [\n    \"Country\",\n    \"Gender\",\n    \"HasCreditCard\",\n    \"IsActiveMember\",\n    \"CustomerFeedback_sentiment3\",\n    \"CustomerFeedback_sentiment5\",\n    \"Surname_Country\",\n    \"Surname_Country_region\",\n    \"Surname_Country_subregion\",\n    \"Country_region\",\n    \"Country_subregion\",\n    \"is_native\",\n    \"Country_hemisphere\",\n    \"Country_IncomeGroup\",\n    \"Surname_Country_IncomeGroup\",\n    \"working_class\",\n    \"stage_of_life\",\n    \"generation\",\n]\ncont_cols = df_pd.drop(\n    columns=id_cols + cat_cols + [target_col]\n).columns.values.tolist()\n</pre> target_col = \"Exited\" id_cols = [\"CustomerId\"] cat_cols = [     \"Country\",     \"Gender\",     \"HasCreditCard\",     \"IsActiveMember\",     \"CustomerFeedback_sentiment3\",     \"CustomerFeedback_sentiment5\",     \"Surname_Country\",     \"Surname_Country_region\",     \"Surname_Country_subregion\",     \"Country_region\",     \"Country_subregion\",     \"is_native\",     \"Country_hemisphere\",     \"Country_IncomeGroup\",     \"Surname_Country_IncomeGroup\",     \"working_class\",     \"stage_of_life\",     \"generation\", ] cont_cols = df_pd.drop(     columns=id_cols + cat_cols + [target_col] ).columns.values.tolist() In\u00a0[6]: Copied! <pre>df_pd[cat_cols] = df_pd[cat_cols].astype(str)\n</pre> df_pd[cat_cols] = df_pd[cat_cols].astype(str) <p>check possible class imbalance</p> In\u00a0[7]: Copied! <pre>df_pd[target_col].value_counts()\n</pre> df_pd[target_col].value_counts() Out[7]: <pre>Exited\n0    7963\n1    2037\nName: count, dtype: int64</pre> In\u00a0[8]: Copied! <pre>df_train, df_valid = train_test_split(\n    df_pd, test_size=valid_size, stratify=df_pd[target_col], random_state=random_state\n)\ndf_valid, df_test = train_test_split(\n    df_valid,\n    test_size=test_size,\n    stratify=df_valid[target_col],\n    random_state=random_state,\n)\n\ndf_train.reset_index(inplace=True, drop=True)\ndf_valid.reset_index(inplace=True, drop=True)\ndf_test.reset_index(inplace=True, drop=True)\n\nscaler_mapper_def = {\n    \"cont_cols\": StandardScaler,\n    \"cat_cols\": None,\n    \"id_cols\": None,\n}\nscaler = scaler_mapper(\n    cont_cols=cont_cols,\n    cat_cols=cat_cols,\n    id_cols=[target_col] + id_cols,\n    scaler_mapper_def=scaler_mapper_def,\n)\n\ndf_train_scaled = scaler.fit_transform(df_train)\ndf_test_scaled = scaler.transform(df_test)\ndf_valid_scaled = scaler.transform(df_valid)\n</pre> df_train, df_valid = train_test_split(     df_pd, test_size=valid_size, stratify=df_pd[target_col], random_state=random_state ) df_valid, df_test = train_test_split(     df_valid,     test_size=test_size,     stratify=df_valid[target_col],     random_state=random_state, )  df_train.reset_index(inplace=True, drop=True) df_valid.reset_index(inplace=True, drop=True) df_test.reset_index(inplace=True, drop=True)  scaler_mapper_def = {     \"cont_cols\": StandardScaler,     \"cat_cols\": None,     \"id_cols\": None, } scaler = scaler_mapper(     cont_cols=cont_cols,     cat_cols=cat_cols,     id_cols=[target_col] + id_cols,     scaler_mapper_def=scaler_mapper_def, )  df_train_scaled = scaler.fit_transform(df_train) df_test_scaled = scaler.transform(df_test) df_valid_scaled = scaler.transform(df_valid) In\u00a0[9]: Copied! <pre>LR_clf = LogisticRegression(class_weight=\"balanced\")\nLR_clf.fit(\n    df_train_scaled.drop(columns=[target_col] + id_cols + cat_cols),\n    df_train_scaled[target_col],\n)\nLR_predicted = LR_clf.predict(\n    df_test_scaled.drop(columns=[target_col] + id_cols + cat_cols)\n)\n\nprint(\n    \"LR classification report :\\n\"\n    + str(classification_report(df_test_scaled[target_col], LR_predicted))\n)\n</pre> LR_clf = LogisticRegression(class_weight=\"balanced\") LR_clf.fit(     df_train_scaled.drop(columns=[target_col] + id_cols + cat_cols),     df_train_scaled[target_col], ) LR_predicted = LR_clf.predict(     df_test_scaled.drop(columns=[target_col] + id_cols + cat_cols) )  print(     \"LR classification report :\\n\"     + str(classification_report(df_test_scaled[target_col], LR_predicted)) ) <pre>LR classification report :\n              precision    recall  f1-score   support\n\n           0       0.91      0.71      0.79       796\n           1       0.38      0.71      0.50       204\n\n    accuracy                           0.71      1000\n   macro avg       0.64      0.71      0.65      1000\nweighted avg       0.80      0.71      0.73      1000\n\n</pre> In\u00a0[10]: Copied! <pre># which metrics am I focusing on? it is more importan to precisely predict non spenders or spenders?\nfrom sklearn.metrics import f1_score\n\ncriterion = f1_score\n\nthreshold_score = []\nfor t in np.arange(0.2, 0.8, 0.01):\n    # preds_bin = [int(p &gt; t) for p in y_pred]\n    preds_bin = (\n        LR_clf.predict_proba(\n            df_test_scaled.drop(columns=[target_col] + id_cols + cat_cols)\n        )[:, 1]\n        &gt;= t\n    ).astype(int)\n    threshold_score.append(\n        (t, criterion(df_test_scaled[target_col], preds_bin, average=\"weighted\"))\n    )\n\nthreshold_score = sorted(threshold_score, key=lambda x: x[1], reverse=True)\nbest_threshold, best_score = threshold_score[0][0], threshold_score[0][1]\n\nprint(f\"The best threshold\\n{best_threshold}\\n, with score:\\n{best_score}\")\n</pre> # which metrics am I focusing on? it is more importan to precisely predict non spenders or spenders? from sklearn.metrics import f1_score  criterion = f1_score  threshold_score = [] for t in np.arange(0.2, 0.8, 0.01):     # preds_bin = [int(p &gt; t) for p in y_pred]     preds_bin = (         LR_clf.predict_proba(             df_test_scaled.drop(columns=[target_col] + id_cols + cat_cols)         )[:, 1]         &gt;= t     ).astype(int)     threshold_score.append(         (t, criterion(df_test_scaled[target_col], preds_bin, average=\"weighted\"))     )  threshold_score = sorted(threshold_score, key=lambda x: x[1], reverse=True) best_threshold, best_score = threshold_score[0][0], threshold_score[0][1]  print(f\"The best threshold\\n{best_threshold}\\n, with score:\\n{best_score}\") <pre>The best threshold\n0.6100000000000003\n, with score:\n0.7973245061612856\n</pre> In\u00a0[11]: Copied! <pre>y_onehot_test = pd.get_dummies(df_test_scaled[target_col]).values\ny_score = LR_clf.predict_proba(\n    df_test_scaled.drop(columns=[target_col] + id_cols + cat_cols)\n)\n\nmicro_roc_auc_per_class = roc_auc_score(\n    y_onehot_test,\n    y_score,\n    average=None,\n)\n\nmicro_roc_auc_weighted = roc_auc_score(\n    y_onehot_test,\n    y_score,\n    average=\"weighted\",\n)\n</pre> y_onehot_test = pd.get_dummies(df_test_scaled[target_col]).values y_score = LR_clf.predict_proba(     df_test_scaled.drop(columns=[target_col] + id_cols + cat_cols) )  micro_roc_auc_per_class = roc_auc_score(     y_onehot_test,     y_score,     average=None, )  micro_roc_auc_weighted = roc_auc_score(     y_onehot_test,     y_score,     average=\"weighted\", ) In\u00a0[12]: Copied! <pre>print(f\"Per class AUC:\\n{micro_roc_auc_per_class}\")\nprint(f\"Weighted AUC:\\n{micro_roc_auc_weighted}\")\n</pre> print(f\"Per class AUC:\\n{micro_roc_auc_per_class}\") print(f\"Weighted AUC:\\n{micro_roc_auc_weighted}\") <pre>Per class AUC:\n[0.76928761 0.76928761]\nWeighted AUC:\n0.7692876145433049\n</pre> In\u00a0[13]: Copied! <pre># initialize H2O\nh2o.init(log_dir=\"h2o_logs\", log_level=\"WARN\")\n\n# read as h2o file\nh2o_train = h2o.H2OFrame(df_train_scaled.drop(columns=id_cols))\nh2o_valid = h2o.H2OFrame(df_valid_scaled.drop(columns=id_cols))\nh2o_test = h2o.H2OFrame(df_test_scaled.drop(columns=id_cols))\n\n# For binary classification, response should be a factor\nh2o_train[target_col] = h2o_train[target_col].asfactor()\nh2o_valid[target_col] = h2o_valid[target_col].asfactor()\nh2o_test[target_col] = h2o_test[target_col].asfactor()\n\n# Define AML task\naml = H2OAutoML(seed=random_state, max_runtime_secs=180)\n\n# over/under sample for classification tasks\naml.balance_classes = True\n\n# Run it\n_ = aml.train(\n    x=list(cont_cols + cat_cols),\n    y=target_col,\n    training_frame=h2o_train,\n    leaderboard_frame=h2o_valid,\n)\n\nm = aml.get_best_model()\n\n# Leaderboard, show and save\nlb = h2o.automl.get_leaderboard(aml, extra_columns=\"ALL\")\nprint(lb)\nprint(m.model_performance(h2o_valid))\npredictions = m.predict(h2o_test)\n\n# save results and model\n# h2o.export_file(lb, path=\"h2o_logs/leaderboard.csv\", force=True)\n# MOJO is h2o version agnostic\n# m.save_mojo(\"h2o_logs/bestmodel.zip\")\n</pre> # initialize H2O h2o.init(log_dir=\"h2o_logs\", log_level=\"WARN\")  # read as h2o file h2o_train = h2o.H2OFrame(df_train_scaled.drop(columns=id_cols)) h2o_valid = h2o.H2OFrame(df_valid_scaled.drop(columns=id_cols)) h2o_test = h2o.H2OFrame(df_test_scaled.drop(columns=id_cols))  # For binary classification, response should be a factor h2o_train[target_col] = h2o_train[target_col].asfactor() h2o_valid[target_col] = h2o_valid[target_col].asfactor() h2o_test[target_col] = h2o_test[target_col].asfactor()  # Define AML task aml = H2OAutoML(seed=random_state, max_runtime_secs=180)  # over/under sample for classification tasks aml.balance_classes = True  # Run it _ = aml.train(     x=list(cont_cols + cat_cols),     y=target_col,     training_frame=h2o_train,     leaderboard_frame=h2o_valid, )  m = aml.get_best_model()  # Leaderboard, show and save lb = h2o.automl.get_leaderboard(aml, extra_columns=\"ALL\") print(lb) print(m.model_performance(h2o_valid)) predictions = m.predict(h2o_test)  # save results and model # h2o.export_file(lb, path=\"h2o_logs/leaderboard.csv\", force=True) # MOJO is h2o version agnostic # m.save_mojo(\"h2o_logs/bestmodel.zip\") <pre>Checking whether there is an H2O instance running at http://localhost:54321..... not found.\nAttempting to start a local H2O server...\n  Java Version: openjdk version \"17.0.10\" 2024-01-16; OpenJDK Runtime Environment (build 17.0.10+7-Ubuntu-122.04.1); OpenJDK 64-Bit Server VM (build 17.0.10+7-Ubuntu-122.04.1, mixed mode, sharing)\n  Starting server from /opt/conda/lib/python3.10/site-packages/h2o/backend/bin/h2o.jar\n  Ice root: /tmp/tmpaylgzon8\n  JVM stdout: /tmp/tmpaylgzon8/h2o_unknownUser_started_from_python.out\n  JVM stderr: /tmp/tmpaylgzon8/h2o_unknownUser_started_from_python.err\n  Server is running at http://127.0.0.1:54321\nConnecting to H2O server at http://127.0.0.1:54321 ... successful.\n</pre> H2O_cluster_uptime: 01 secs H2O_cluster_timezone: Etc/UTC H2O_data_parsing_timezone: UTC H2O_cluster_version: 3.46.0.1 H2O_cluster_version_age: 1 month and 18 days H2O_cluster_name: H2O_from_python_unknownUser_3enaho H2O_cluster_total_nodes: 1 H2O_cluster_free_memory: 16 Gb H2O_cluster_total_cores: 12 H2O_cluster_allowed_cores: 12 H2O_cluster_status: locked, healthy H2O_connection_url: http://127.0.0.1:54321 H2O_connection_proxy: {\"http\": null, \"https\": null} H2O_internal_security: False Python_version: 3.10.11 final <pre>Parse progress: |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| (done) 100%\nParse progress: |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| (done) 100%\nParse progress: |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| (done) 100%\nAutoML progress: |\n21:14:36.227: _train param, Dropping bad and constant columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\u2588\u2588\u2588\n21:14:47.43: _train param, Dropping bad and constant columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\u2588\n21:14:50.191: _train param, Dropping bad and constant columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\u2588\n21:14:58.843: _train param, Dropping unused columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\n21:14:59.823: _train param, Dropping bad and constant columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\u2588\n21:15:06.470: _train param, Dropping bad and constant columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\u2588\u2588\n21:15:14.629: _train param, Dropping bad and constant columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\n21:15:18.475: _train param, Dropping bad and constant columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\n21:15:22.46: _train param, Dropping bad and constant columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\n21:15:25.584: _train param, Dropping unused columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\n21:15:26.398: _train param, Dropping unused columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n21:15:27.398: _train param, Dropping bad and constant columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\u2588\n21:15:33.757: _train param, Dropping bad and constant columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\u2588\u2588\n21:15:41.23: _train param, Dropping bad and constant columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\n21:15:44.787: _train param, Dropping bad and constant columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\u2588\n21:15:51.131: _train param, Dropping unused columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\n21:15:52.50: _train param, Dropping unused columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\n21:17:30.497: _train param, Dropping unused columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n21:17:31.185: _train param, Dropping unused columns: [Country_region, Country_IncomeGroup, Country_hemisphere]\n\n\u2588\u2588| (done) 100%\nmodel_id                                                      auc    logloss     aucpr    mean_per_class_error      rmse        mse    training_time_ms    predict_time_per_row_ms  algo\nStackedEnsemble_BestOfFamily_4_AutoML_1_20240501_211436  0.880101   0.321353  0.718049                0.19825   0.313431  0.0982391                 587                   0.08015   StackedEnsemble\nGBM_grid_1_AutoML_1_20240501_211436_model_7              0.880077   0.324523  0.715814                0.227877  0.315328  0.0994315                1275                   0.048422  GBM\nGBM_grid_1_AutoML_1_20240501_211436_model_2              0.879564   0.32755   0.700805                0.214585  0.317341  0.100705                 1284                   0.047805  GBM\nGBM_5_AutoML_1_20240501_211436                           0.879162   0.324106  0.720173                0.206754  0.31347   0.0982632                1324                   0.030257  GBM\nGBM_grid_1_AutoML_1_20240501_211436_model_6              0.876891   0.329434  0.696693                0.223137  0.318794  0.10163                  1338                   0.048563  GBM\nStackedEnsemble_AllModels_3_AutoML_1_20240501_211436     0.876439   0.326157  0.715138                0.201247  0.316194  0.0999788                1252                   0.067674  StackedEnsemble\nStackedEnsemble_BestOfFamily_3_AutoML_1_20240501_211436  0.875775   0.325977  0.719837                0.217583  0.315933  0.0998134                 814                   0.073439  StackedEnsemble\nGBM_3_AutoML_1_20240501_211436                           0.875664   0.333065  0.70305                 0.232269  0.318954  0.101732                 1345                   0.043399  GBM\nStackedEnsemble_BestOfFamily_2_AutoML_1_20240501_211436  0.875284   0.330522  0.690455                0.223718  0.318198  0.10125                   720                   0.060753  StackedEnsemble\nStackedEnsemble_AllModels_2_AutoML_1_20240501_211436     0.875203   0.326942  0.718431                0.225461  0.316482  0.100161                  847                   0.080788  StackedEnsemble\n[36 rows x 10 columns]\n\nModelMetricsBinomialGLM: stackedensemble\n** Reported on test data. **\n\nMSE: 0.09823909719810361\nRMSE: 0.31343116819822436\nLogLoss: 0.3213528582843091\nAUC: 0.8801014889579766\nAUCPR: 0.7180486621898251\nGini: 0.7602029779159531\nNull degrees of freedom: 999\nResidual degrees of freedom: 995\nNull deviance: 1009.0700428262837\nResidual deviance: 642.7057165686182\nAIC: 652.7057165686182\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.28080823635190166\n       0    1    Error    Rate\n-----  ---  ---  -------  --------------\n0      693  104  0.1305   (104.0/797.0)\n1      54   149  0.266    (54.0/203.0)\nTotal  747  253  0.158    (158.0/1000.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.280808     0.653509  191\nmax f2                       0.160323     0.717949  247\nmax f0point5                 0.663482     0.710974  85\nmax accuracy                 0.499443     0.872     122\nmax precision                0.991398     1         0\nmax recall                   0.0175152    1         376\nmax specificity              0.991398     1         0\nmax absolute_mcc             0.449611     0.574975  137\nmax min_per_class_accuracy   0.187182     0.795483  232\nmax mean_per_class_accuracy  0.280808     0.80175   191\nmax tns                      0.991398     797       0\nmax fns                      0.991398     202       0\nmax fps                      0.0032163    797       399\nmax tps                      0.0175152    203       376\nmax tnr                      0.991398     1         0\nmax fnr                      0.991398     0.995074  0\nmax fpr                      0.0032163    1         399\nmax tpr                      0.0175152    1         376\n\nGains/Lift Table: Avg response rate: 20.30 %, avg score: 20.95 %\ngroup    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n1        0.01                        0.940779           4.92611    4.92611            1                0.964295    1                           0.964295            0.0492611       0.0492611                  392.611   392.611            0.0492611\n2        0.02                        0.904438           3.94089    4.4335             0.8              0.92715     0.9                         0.945722            0.0394089       0.08867                    294.089   343.35             0.0861605\n3        0.03                        0.878852           4.92611    4.5977             1                0.893414    0.933333                    0.928286            0.0492611       0.137931                   392.611   359.77             0.135422\n4        0.04                        0.867626           4.92611    4.6798             1                0.871928    0.95                        0.914197            0.0492611       0.187192                   392.611   367.98             0.184683\n5        0.05                        0.834646           4.4335     4.63054            0.9              0.850263    0.94                        0.90141             0.044335        0.231527                   343.35    363.054            0.227763\n6        0.1                         0.687835           3.64532    4.13793            0.74             0.771377    0.84                        0.836393            0.182266        0.413793                   264.532   313.793            0.393718\n7        0.15                        0.508264           2.6601     3.64532            0.54             0.608741    0.74                        0.760509            0.133005        0.546798                   166.01    264.532            0.497865\n8        0.2                         0.388087           1.67488    3.15271            0.34             0.448371    0.64                        0.682474            0.0837438       0.630542                   67.4877   215.271            0.540203\n9        0.3                         0.207693           1.47783    2.59442            0.3              0.291717    0.526667                    0.552222            0.147783        0.778325                   47.7833   159.442            0.600157\n10       0.4                         0.130789           0.640394   2.10591            0.13             0.165365    0.4275                      0.455508            0.0640394       0.842365                   -35.9606  110.591            0.555037\n11       0.5                         0.0857897          0.640394   1.81281            0.13             0.104819    0.368                       0.38537             0.0640394       0.906404                   -35.9606  81.2808            0.509917\n12       0.6                         0.057346           0.44335    1.58456            0.09             0.0704711   0.321667                    0.332887            0.044335        0.950739                   -55.665   58.4565            0.440074\n13       0.7                         0.0338547          0.246305   1.39338            0.05             0.0452273   0.282857                    0.291793            0.0246305       0.975369                   -75.3695  39.3385            0.345507\n14       0.8                         0.0216684          0.147783   1.23768            0.03             0.027519    0.25125                     0.258759            0.0147783       0.990148                   -85.2217  23.7685            0.238579\n15       0.9                         0.0120087          0.0985222  1.11111            0.02             0.0167146   0.225556                    0.231865            0.00985222      1                          -90.1478  11.1111            0.125471\n16       1                           0.0032163          0          1                  0                0.00824799  0.203                       0.209503            0               1                          -100      0                  0\nstackedensemble prediction progress: |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| (done) 100%\n</pre> In\u00a0[14]: Copied! <pre>y_onehot_test = pd.get_dummies(df_test_scaled[target_col]).values\ny_score = h2o.as_list(predictions.drop([\"predict\"])).values\n\nmicro_roc_auc_per_class = roc_auc_score(\n    y_onehot_test,\n    y_score,\n    average=None,\n)\n\nmicro_roc_auc_weighted = roc_auc_score(\n    y_onehot_test,\n    y_score,\n    average=\"weighted\",\n)\n</pre> y_onehot_test = pd.get_dummies(df_test_scaled[target_col]).values y_score = h2o.as_list(predictions.drop([\"predict\"])).values  micro_roc_auc_per_class = roc_auc_score(     y_onehot_test,     y_score,     average=None, )  micro_roc_auc_weighted = roc_auc_score(     y_onehot_test,     y_score,     average=\"weighted\", ) <pre>/opt/conda/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above) and activate it using:\n\nwith h2o.utils.threading.local_context(polars_enabled=True, datatable_enabled=True):\n    pandas_df = h2o_df.as_data_frame()\n\n  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n</pre> In\u00a0[15]: Copied! <pre>print(f\"Per class AUC:\\n{micro_roc_auc_per_class}\")\nprint(f\"Weighted AUC:\\n{micro_roc_auc_weighted}\")\n</pre> print(f\"Per class AUC:\\n{micro_roc_auc_per_class}\") print(f\"Weighted AUC:\\n{micro_roc_auc_weighted}\") <pre>Per class AUC:\n[0.90083383 0.90083383]\nWeighted AUC:\n0.9008338259927087\n</pre> In\u00a0[18]: Copied! <pre>fig, ax = plt.subplots(figsize=(6, 6))\nn_classes = 2\n\nfor class_id in range(n_classes):\n    RocCurveDisplay.from_predictions(\n        y_onehot_test[:, class_id],\n        y_score[:, class_id],\n        name=f\"ROC curve for class {class_id}\",\n        ax=ax,\n        # plot_chance_level=(class_id == 2),\n    )\n</pre> fig, ax = plt.subplots(figsize=(6, 6)) n_classes = 2  for class_id in range(n_classes):     RocCurveDisplay.from_predictions(         y_onehot_test[:, class_id],         y_score[:, class_id],         name=f\"ROC curve for class {class_id}\",         ax=ax,         # plot_chance_level=(class_id == 2),     ) In\u00a0[19]: Copied! <pre>print(\n    \"Classification report:\\n{}\".format(\n        classification_report(df_test[target_col], h2o.as_list(predictions[\"predict\"]))\n    )\n)\n</pre> print(     \"Classification report:\\n{}\".format(         classification_report(df_test[target_col], h2o.as_list(predictions[\"predict\"]))     ) ) <pre>Classification report:\n              precision    recall  f1-score   support\n\n           0       0.94      0.90      0.92       796\n           1       0.66      0.76      0.71       204\n\n    accuracy                           0.87      1000\n   macro avg       0.80      0.83      0.81      1000\nweighted avg       0.88      0.87      0.87      1000\n\n</pre> <pre>/opt/conda/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above) and activate it using:\n\nwith h2o.utils.threading.local_context(polars_enabled=True, datatable_enabled=True):\n    pandas_df = h2o_df.as_data_frame()\n\n  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n</pre> In\u00a0[20]: Copied! <pre>config = {}\nconfig[\"objective\"] = \"binary\"\n\ndf_train_scaled_enc = df_train_scaled.copy()\ndf_valid_scaled_enc = df_valid_scaled.copy()\ndf_test_scaled_enc = df_test_scaled.copy()\nlgb_cat_cols = cat_cols\n\nlabel_encoder = LabelEncoder(lgb_cat_cols)\ndf_train_scaled_enc = label_encoder.fit_transform(df_train_scaled_enc)\ndf_valid_scaled_enc = label_encoder.transform(df_valid_scaled_enc)\ndf_test_scaled_enc = label_encoder.transform(df_test_scaled_enc)\n\nlgbtrain = lgbm.Dataset(\n    df_train_scaled_enc.drop(columns=[target_col] + id_cols),\n    df_train_scaled_enc[target_col],\n    categorical_feature=lgb_cat_cols,\n    free_raw_data=False,\n)\nlgbvalid = lgbm.Dataset(\n    df_valid_scaled_enc.drop(columns=[target_col] + id_cols),\n    df_valid_scaled_enc[target_col],\n    reference=lgbtrain,\n    free_raw_data=False,\n)\n# Final TRAIN/TEST\nftrain = pd.concat([df_train_scaled_enc, df_valid_scaled_enc]).reset_index(drop=True)\nflgbtrain = lgbm.Dataset(\n    ftrain.drop(columns=[target_col] + id_cols),\n    ftrain[target_col],\n    categorical_feature=lgb_cat_cols,\n    free_raw_data=False,\n)\nlgbtest = lgbm.Dataset(\n    df_test_scaled_enc.drop(columns=[target_col] + id_cols),\n    df_test_scaled_enc[target_col],\n    categorical_feature=lgb_cat_cols,\n    reference=flgbtrain,\n    free_raw_data=False,\n)\n</pre> config = {} config[\"objective\"] = \"binary\"  df_train_scaled_enc = df_train_scaled.copy() df_valid_scaled_enc = df_valid_scaled.copy() df_test_scaled_enc = df_test_scaled.copy() lgb_cat_cols = cat_cols  label_encoder = LabelEncoder(lgb_cat_cols) df_train_scaled_enc = label_encoder.fit_transform(df_train_scaled_enc) df_valid_scaled_enc = label_encoder.transform(df_valid_scaled_enc) df_test_scaled_enc = label_encoder.transform(df_test_scaled_enc)  lgbtrain = lgbm.Dataset(     df_train_scaled_enc.drop(columns=[target_col] + id_cols),     df_train_scaled_enc[target_col],     categorical_feature=lgb_cat_cols,     free_raw_data=False, ) lgbvalid = lgbm.Dataset(     df_valid_scaled_enc.drop(columns=[target_col] + id_cols),     df_valid_scaled_enc[target_col],     reference=lgbtrain,     free_raw_data=False, ) # Final TRAIN/TEST ftrain = pd.concat([df_train_scaled_enc, df_valid_scaled_enc]).reset_index(drop=True) flgbtrain = lgbm.Dataset(     ftrain.drop(columns=[target_col] + id_cols),     ftrain[target_col],     categorical_feature=lgb_cat_cols,     free_raw_data=False, ) lgbtest = lgbm.Dataset(     df_test_scaled_enc.drop(columns=[target_col] + id_cols),     df_test_scaled_enc[target_col],     categorical_feature=lgb_cat_cols,     reference=flgbtrain,     free_raw_data=False, ) In\u00a0[21]: Copied! <pre>model = lgbm.train(\n    config,\n    lgbtrain,\n    valid_sets=[lgbvalid],\n    valid_names=[\"\"],\n    feval=None,\n)\n</pre> model = lgbm.train(     config,     lgbtrain,     valid_sets=[lgbvalid],     valid_names=[\"\"],     feval=None, ) <pre>[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 1630, number of negative: 6370\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002671 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1048\n[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 23\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203750 -&gt; initscore=-1.363019\n[LightGBM] [Info] Start training from score -1.363019\n</pre> In\u00a0[22]: Copied! <pre>res = predict_cls_lgbm_from_raw(\n    preds_raw=model.predict(lgbtest.data, raw_score=True),\n    task=\"binary\",\n)\n\nresult = pd.DataFrame(\n    {\n        \"predicted\": res,\n        \"ground_truth\": df_test[target_col].values,\n    }\n)\n\nprint(\n    \"Classification report:\\n{}\".format(\n        classification_report(result[\"ground_truth\"], result[\"predicted\"])\n    )\n)\n</pre> res = predict_cls_lgbm_from_raw(     preds_raw=model.predict(lgbtest.data, raw_score=True),     task=\"binary\", )  result = pd.DataFrame(     {         \"predicted\": res,         \"ground_truth\": df_test[target_col].values,     } )  print(     \"Classification report:\\n{}\".format(         classification_report(result[\"ground_truth\"], result[\"predicted\"])     ) ) <pre>Classification report:\n              precision    recall  f1-score   support\n\n           0       0.90      0.95      0.92       796\n           1       0.76      0.58      0.66       204\n\n    accuracy                           0.88      1000\n   macro avg       0.83      0.77      0.79      1000\nweighted avg       0.87      0.88      0.87      1000\n\n</pre> In\u00a0[23]: Copied! <pre>y_onehot_test = pd.get_dummies(df_test_scaled[target_col]).values\ny_score = predict_proba_lgbm_from_raw(\n    preds_raw=model.predict(lgbtest.data),\n    task=\"binary\",\n    binary2d=True,\n)\n\nmicro_roc_auc_per_class = roc_auc_score(\n    y_onehot_test,\n    y_score,\n    average=None,\n)\n\nmicro_roc_auc_weighted = roc_auc_score(\n    y_onehot_test,\n    y_score,\n    average=\"weighted\",\n)\n\nprint(f\"Per class AUC:\\n{micro_roc_auc_per_class}\")\nprint(f\"Weighted AUC:\\n{micro_roc_auc_weighted}\")\n</pre> y_onehot_test = pd.get_dummies(df_test_scaled[target_col]).values y_score = predict_proba_lgbm_from_raw(     preds_raw=model.predict(lgbtest.data),     task=\"binary\",     binary2d=True, )  micro_roc_auc_per_class = roc_auc_score(     y_onehot_test,     y_score,     average=None, )  micro_roc_auc_weighted = roc_auc_score(     y_onehot_test,     y_score,     average=\"weighted\", )  print(f\"Per class AUC:\\n{micro_roc_auc_per_class}\") print(f\"Weighted AUC:\\n{micro_roc_auc_weighted}\") <pre>Per class AUC:\n[0.89585797 0.89585797]\nWeighted AUC:\n0.8958579663020987\n</pre>"},{"location":"notebooks/03_models.html#models","title":"Models\u00b6","text":""},{"location":"notebooks/03_models.html#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/03_models.html#dataset","title":"Dataset\u00b6","text":""},{"location":"notebooks/03_models.html#preprocessing","title":"Preprocessing\u00b6","text":"<ul> <li>divide dataset into train, test, valid</li> <li>scale continuous columns by standard scaler(not needed for LightGBM but for other mdoels...)</li> </ul>"},{"location":"notebooks/03_models.html#logistic-regression","title":"Logistic Regression\u00b6","text":""},{"location":"notebooks/03_models.html#h2o-automl","title":"H2O AutoML\u00b6","text":"<p>NOTE:</p> <p>java is required: <code>sudo apt install openjdk-17-jdk</code></p>"},{"location":"notebooks/03_models.html#lightgbm","title":"LightGBM\u00b6","text":""},{"location":"notebooks/04_model_training_pipeline.html","title":"04_model_training_pipeline","text":"In\u00a0[1]: Copied! <pre>import os\nimport sys\n\nsys.path.append(os.getcwd())\nos.chdir(\"..\")\n\nimport pandas as pd\nimport mlflow\n\npd.set_option(\"display.max_columns\", 200)\npd.set_option(\"display.max_rows\", 300)\n</pre> import os import sys  sys.path.append(os.getcwd()) os.chdir(\"..\")  import pandas as pd import mlflow  pd.set_option(\"display.max_columns\", 200) pd.set_option(\"display.max_rows\", 300) In\u00a0[2]: Copied! <pre>import os\nimport json\nfrom typing import Literal\nimport pandas as pd\n\nfrom churn_pred.preprocessing.preprocess import PreprocessData\nfrom churn_pred.training.trainer import Trainer\nfrom churn_pred.training.optuna_optimizer import LGBOptunaOptimizer\nfrom churn_pred.training.utils import flatten_dict, get_or_create_experiment\n\nimport dill\nimport numpy as np\nfrom churn_pred.utils import dill_dump, dill_load\nfrom sklearn.model_selection import train_test_split\n\nfrom pprint import pprint\n</pre> import os import json from typing import Literal import pandas as pd  from churn_pred.preprocessing.preprocess import PreprocessData from churn_pred.training.trainer import Trainer from churn_pred.training.optuna_optimizer import LGBOptunaOptimizer from churn_pred.training.utils import flatten_dict, get_or_create_experiment  import dill import numpy as np from churn_pred.utils import dill_dump, dill_load from sklearn.model_selection import train_test_split  from pprint import pprint In\u00a0[3]: Copied! <pre># 1. get the data\ndf_pd = pd.read_parquet(\"data/dataset_auxiliary_features_cleaned.parquet\")\ndf_pd.head()\n</pre> # 1. get the data df_pd = pd.read_parquet(\"data/dataset_auxiliary_features_cleaned.parquet\") df_pd.head() Out[3]: CustomerId CreditScore Country Gender Age Tenure Balance (EUR) NumberOfProducts HasCreditCard IsActiveMember EstimatedSalary Exited CustomerFeedback_sentiment3 CustomerFeedback_sentiment5 Surname_Country Surname_Country_region Surname_Country_subregion Country_region Country_subregion is_native Country_hemisphere Country_gdp_per_capita Country_IncomeGroup Surname_Country_gdp_per_capita Surname_Country_IncomeGroup working_class stage_of_life generation 0 15787619 844 France Male 18 2 160980.03 1 0 0 145936.28 0 neutral 4 stars Taiwan Asia Eastern Asia Europe Western Europe 0 northern 57594.03402 High income 32756.00000 None working_age teen gen_z 1 15770309 656 France Male 18 10 151762.74 1 0 1 127014.32 0 neutral 1 star United States Americas Northern America Europe Western Europe 0 northern 57594.03402 High income 76329.58227 High income working_age teen gen_z 2 15569178 570 France Female 18 4 82767.42 1 1 0 71811.90 0 neutral 2 stars Russian Federation Europe Eastern Europe Europe Western Europe 0 northern 57594.03402 High income 34637.76172 Upper middle income working_age teen gen_z 3 15795519 716 Germany Female 18 3 128743.80 1 0 0 197322.13 0 neutral 2 stars Russian Federation Europe Eastern Europe Europe Western Europe 0 northern 66616.02225 High income 34637.76172 Upper middle income working_age teen gen_z 4 15621893 727 France Male 18 4 133550.67 1 1 1 46941.41 0 positive 1 star Italy Europe Southern Europe Europe Western Europe 0 northern 57594.03402 High income 55442.07843 High income working_age teen gen_z In\u00a0[4]: Copied! <pre>target_col = \"Exited\"\nid_cols = [\"CustomerId\"]\ncat_cols = [\n    \"Country\",\n    \"Gender\",\n    \"HasCreditCard\",\n    \"IsActiveMember\",\n    \"CustomerFeedback_sentiment3\",\n    \"CustomerFeedback_sentiment5\",\n    \"Surname_Country\",\n    \"Surname_Country_region\",\n    \"Surname_Country_subregion\",\n    \"Country_region\",\n    \"Country_subregion\",\n    \"is_native\",\n    \"Country_hemisphere\",\n    \"Country_IncomeGroup\",\n    \"Surname_Country_IncomeGroup\",\n    \"working_class\",\n    \"stage_of_life\",\n    \"generation\",\n]\ncont_cols = df_pd.drop(\n    columns=id_cols + cat_cols + [target_col]\n).columns.values.tolist()\n</pre> target_col = \"Exited\" id_cols = [\"CustomerId\"] cat_cols = [     \"Country\",     \"Gender\",     \"HasCreditCard\",     \"IsActiveMember\",     \"CustomerFeedback_sentiment3\",     \"CustomerFeedback_sentiment5\",     \"Surname_Country\",     \"Surname_Country_region\",     \"Surname_Country_subregion\",     \"Country_region\",     \"Country_subregion\",     \"is_native\",     \"Country_hemisphere\",     \"Country_IncomeGroup\",     \"Surname_Country_IncomeGroup\",     \"working_class\",     \"stage_of_life\",     \"generation\", ] cont_cols = df_pd.drop(     columns=id_cols + cat_cols + [target_col] ).columns.values.tolist() In\u00a0[5]: Copied! <pre>df_pd[cat_cols] = df_pd[cat_cols].astype(str)\n</pre> df_pd[cat_cols] = df_pd[cat_cols].astype(str) In\u00a0[6]: Copied! <pre>valid_size = 0.2\ntest_size = 0.5\nrandom_state = 1\ndf_train, df_valid = train_test_split(\n    df_pd, test_size=valid_size, stratify=df_pd[target_col], random_state=random_state\n)\ndf_valid, df_test = train_test_split(\n    df_valid,\n    test_size=test_size,\n    stratify=df_valid[target_col],\n    random_state=random_state,\n)\n</pre> valid_size = 0.2 test_size = 0.5 random_state = 1 df_train, df_valid = train_test_split(     df_pd, test_size=valid_size, stratify=df_pd[target_col], random_state=random_state ) df_valid, df_test = train_test_split(     df_valid,     test_size=test_size,     stratify=df_valid[target_col],     random_state=random_state, ) In\u00a0[7]: Copied! <pre>prepare_data = PreprocessData(\n    id_cols=id_cols,\n    target_col=target_col,\n    cat_cols=cat_cols,\n    cont_cols=cont_cols,\n)\n# this should be fitted only on training data\n_ = prepare_data.fit(df=df_pd)\n</pre> prepare_data = PreprocessData(     id_cols=id_cols,     target_col=target_col,     cat_cols=cat_cols,     cont_cols=cont_cols, ) # this should be fitted only on training data _ = prepare_data.fit(df=df_pd) In\u00a0[8]: Copied! <pre>optimizer = LGBOptunaOptimizer(\n    objective=\"binary\",\n    n_class=2,\n)\n\ntrainer = Trainer(\n    cat_cols=prepare_data.cat_cols,\n    target_col=prepare_data.target_col,\n    id_cols=id_cols,\n    objective=\"binary\",\n    n_class=2,\n    optimizer=optimizer,\n    preprocessors=[prepare_data],\n)\n\nmetrics_dict = trainer.fit(\n    df_train=df_train,\n    df_valid=df_valid,\n    df_test=df_test,\n)\n</pre> optimizer = LGBOptunaOptimizer(     objective=\"binary\",     n_class=2, )  trainer = Trainer(     cat_cols=prepare_data.cat_cols,     target_col=prepare_data.target_col,     id_cols=id_cols,     objective=\"binary\",     n_class=2,     optimizer=optimizer,     preprocessors=[prepare_data], )  metrics_dict = trainer.fit(     df_train=df_train,     df_valid=df_valid,     df_test=df_test, ) <pre>[I 2024-05-17 10:13:50,499] A new study created in memory with name: no-name-fa589f64-d8f0-4cbb-b929-f47ba65e30cf\nfeature_fraction, val_score: inf:   0%|          | 0/7 [00:00&lt;?, ?it/s]</pre> <pre>Training until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction, val_score: 0.384886:  14%|#4        | 1/7 [00:03&lt;00:18,  3.09s/it][I 2024-05-17 10:13:53,604] Trial 0 finished with value: 0.3848856550710792 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.3848856550710792.\nfeature_fraction, val_score: 0.384886:  14%|#4        | 1/7 [00:03&lt;00:18,  3.09s/it]</pre> <pre>Early stopping, best iteration is:\n[256]\tvalid_0's binary_logloss: 0.384886\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction, val_score: 0.384886:  29%|##8       | 2/7 [00:09&lt;00:24,  4.93s/it][I 2024-05-17 10:13:59,819] Trial 1 finished with value: 0.38876581289974715 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.3848856550710792.\nfeature_fraction, val_score: 0.384886:  29%|##8       | 2/7 [00:09&lt;00:24,  4.93s/it]</pre> <pre>Early stopping, best iteration is:\n[203]\tvalid_0's binary_logloss: 0.388766\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction, val_score: 0.384886:  43%|####2     | 3/7 [00:10&lt;00:13,  3.45s/it][I 2024-05-17 10:14:01,500] Trial 2 finished with value: 0.3871060537924552 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.3848856550710792.\nfeature_fraction, val_score: 0.384886:  43%|####2     | 3/7 [00:10&lt;00:13,  3.45s/it]</pre> <pre>Early stopping, best iteration is:\n[136]\tvalid_0's binary_logloss: 0.387106\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction, val_score: 0.376373:  57%|#####7    | 4/7 [00:13&lt;00:08,  2.95s/it][I 2024-05-17 10:14:03,700] Trial 3 finished with value: 0.37637252943396876 and parameters: {'feature_fraction': 0.8}. Best is trial 3 with value: 0.37637252943396876.\nfeature_fraction, val_score: 0.376373:  57%|#####7    | 4/7 [00:13&lt;00:08,  2.95s/it]</pre> <pre>Early stopping, best iteration is:\n[182]\tvalid_0's binary_logloss: 0.376373\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction, val_score: 0.376373:  71%|#######1  | 5/7 [00:18&lt;00:07,  3.70s/it][I 2024-05-17 10:14:08,731] Trial 4 finished with value: 0.38580891587959387 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.37637252943396876.\nfeature_fraction, val_score: 0.376373:  71%|#######1  | 5/7 [00:18&lt;00:07,  3.70s/it]</pre> <pre>Early stopping, best iteration is:\n[196]\tvalid_0's binary_logloss: 0.385809\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction, val_score: 0.376373:  86%|########5 | 6/7 [00:20&lt;00:03,  3.13s/it][I 2024-05-17 10:14:10,735] Trial 5 finished with value: 0.38034803511400994 and parameters: {'feature_fraction': 0.7}. Best is trial 3 with value: 0.37637252943396876.\nfeature_fraction, val_score: 0.376373:  86%|########5 | 6/7 [00:20&lt;00:03,  3.13s/it]</pre> <pre>Early stopping, best iteration is:\n[178]\tvalid_0's binary_logloss: 0.380348\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction, val_score: 0.376373: 100%|##########| 7/7 [00:25&lt;00:00,  3.83s/it][I 2024-05-17 10:14:16,006] Trial 6 finished with value: 0.38397832605349824 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 3 with value: 0.37637252943396876.\nfeature_fraction, val_score: 0.376373: 100%|##########| 7/7 [00:25&lt;00:00,  3.64s/it]\n</pre> <pre>Early stopping, best iteration is:\n[166]\tvalid_0's binary_logloss: 0.383978\n</pre> <pre>num_leaves, val_score: 0.376373:   0%|          | 0/20 [00:00&lt;?, ?it/s]</pre> <pre>Training until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.376373:   5%|5         | 1/20 [00:02&lt;00:51,  2.69s/it][I 2024-05-17 10:14:18,709] Trial 7 finished with value: 0.38099924239489236 and parameters: {'num_leaves': 176}. Best is trial 7 with value: 0.38099924239489236.\nnum_leaves, val_score: 0.376373:   5%|5         | 1/20 [00:02&lt;00:51,  2.69s/it]</pre> <pre>Early stopping, best iteration is:\n[28]\tvalid_0's binary_logloss: 0.380999\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.373858:  10%|#         | 2/20 [00:06&lt;01:05,  3.64s/it][I 2024-05-17 10:14:23,016] Trial 8 finished with value: 0.37385793384339394 and parameters: {'num_leaves': 222}. Best is trial 8 with value: 0.37385793384339394.\nnum_leaves, val_score: 0.373858:  10%|#         | 2/20 [00:07&lt;01:05,  3.64s/it]</pre> <pre>Early stopping, best iteration is:\n[40]\tvalid_0's binary_logloss: 0.373858\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.373858:  15%|#5        | 3/20 [00:13&lt;01:21,  4.81s/it][I 2024-05-17 10:14:29,219] Trial 9 finished with value: 0.38119071611784033 and parameters: {'num_leaves': 93}. Best is trial 8 with value: 0.37385793384339394.\nnum_leaves, val_score: 0.373858:  15%|#5        | 3/20 [00:13&lt;01:21,  4.81s/it]</pre> <pre>Early stopping, best iteration is:\n[74]\tvalid_0's binary_logloss: 0.381191\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.373858:  20%|##        | 4/20 [00:22&lt;01:46,  6.66s/it][I 2024-05-17 10:14:38,717] Trial 10 finished with value: 0.3773282550132434 and parameters: {'num_leaves': 249}. Best is trial 8 with value: 0.37385793384339394.\nnum_leaves, val_score: 0.373858:  20%|##        | 4/20 [00:22&lt;01:46,  6.66s/it]</pre> <pre>Early stopping, best iteration is:\n[40]\tvalid_0's binary_logloss: 0.377328\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.373858:  25%|##5       | 5/20 [00:24&lt;01:13,  4.88s/it][I 2024-05-17 10:14:40,431] Trial 11 finished with value: 0.39044042093457787 and parameters: {'num_leaves': 19}. Best is trial 8 with value: 0.37385793384339394.\nnum_leaves, val_score: 0.373858:  25%|##5       | 5/20 [00:24&lt;01:13,  4.88s/it]</pre> <pre>Early stopping, best iteration is:\n[244]\tvalid_0's binary_logloss: 0.39044\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.373858:  30%|###       | 6/20 [00:28&lt;01:02,  4.44s/it][I 2024-05-17 10:14:44,030] Trial 12 finished with value: 0.38026069867454104 and parameters: {'num_leaves': 251}. Best is trial 8 with value: 0.37385793384339394.\nnum_leaves, val_score: 0.373858:  30%|###       | 6/20 [00:28&lt;01:02,  4.44s/it]</pre> <pre>Early stopping, best iteration is:\n[28]\tvalid_0's binary_logloss: 0.380261\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.373858:  35%|###5      | 7/20 [00:31&lt;00:52,  4.07s/it][I 2024-05-17 10:14:47,328] Trial 13 finished with value: 0.3753274511816769 and parameters: {'num_leaves': 165}. Best is trial 8 with value: 0.37385793384339394.\nnum_leaves, val_score: 0.373858:  35%|###5      | 7/20 [00:31&lt;00:52,  4.07s/it]</pre> <pre>Early stopping, best iteration is:\n[48]\tvalid_0's binary_logloss: 0.375327\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.373858:  40%|####      | 8/20 [00:38&lt;00:59,  4.99s/it][I 2024-05-17 10:14:54,309] Trial 14 finished with value: 0.3739214777794338 and parameters: {'num_leaves': 162}. Best is trial 8 with value: 0.37385793384339394.\nnum_leaves, val_score: 0.373858:  40%|####      | 8/20 [00:38&lt;00:59,  4.99s/it]</pre> <pre>Early stopping, best iteration is:\n[52]\tvalid_0's binary_logloss: 0.373921\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.371332:  45%|####5     | 9/20 [00:41&lt;00:49,  4.54s/it][I 2024-05-17 10:14:57,829] Trial 15 finished with value: 0.3713317512304886 and parameters: {'num_leaves': 191}. Best is trial 15 with value: 0.3713317512304886.\nnum_leaves, val_score: 0.371332:  45%|####5     | 9/20 [00:41&lt;00:49,  4.54s/it]</pre> <pre>Early stopping, best iteration is:\n[39]\tvalid_0's binary_logloss: 0.371332\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.371332:  50%|#####     | 10/20 [00:45&lt;00:43,  4.31s/it][I 2024-05-17 10:15:01,634] Trial 16 finished with value: 0.37619505728984265 and parameters: {'num_leaves': 215}. Best is trial 15 with value: 0.3713317512304886.\nnum_leaves, val_score: 0.371332:  50%|#####     | 10/20 [00:45&lt;00:43,  4.31s/it]</pre> <pre>Early stopping, best iteration is:\n[39]\tvalid_0's binary_logloss: 0.376195\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.371332:  55%|#####5    | 11/20 [00:48&lt;00:35,  3.94s/it][I 2024-05-17 10:15:04,721] Trial 17 finished with value: 0.3714154578813961 and parameters: {'num_leaves': 105}. Best is trial 15 with value: 0.3713317512304886.\nnum_leaves, val_score: 0.371332:  55%|#####5    | 11/20 [00:48&lt;00:35,  3.94s/it]</pre> <pre>Early stopping, best iteration is:\n[75]\tvalid_0's binary_logloss: 0.371415\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.371332:  60%|######    | 12/20 [00:51&lt;00:27,  3.47s/it][I 2024-05-17 10:15:07,131] Trial 18 finished with value: 0.38587964344293435 and parameters: {'num_leaves': 96}. Best is trial 15 with value: 0.3713317512304886.\nnum_leaves, val_score: 0.371332:  60%|######    | 12/20 [00:51&lt;00:27,  3.47s/it]</pre> <pre>Early stopping, best iteration is:\n[63]\tvalid_0's binary_logloss: 0.38588\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.367410:  65%|######5   | 13/20 [00:54&lt;00:24,  3.45s/it][I 2024-05-17 10:15:10,519] Trial 19 finished with value: 0.36740957414352104 and parameters: {'num_leaves': 109}. Best is trial 19 with value: 0.36740957414352104.\nnum_leaves, val_score: 0.367410:  65%|######5   | 13/20 [00:54&lt;00:24,  3.45s/it]</pre> <pre>Early stopping, best iteration is:\n[75]\tvalid_0's binary_logloss: 0.36741\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.367410:  70%|#######   | 14/20 [00:56&lt;00:18,  3.10s/it][I 2024-05-17 10:15:12,812] Trial 20 finished with value: 0.38156230494038623 and parameters: {'num_leaves': 54}. Best is trial 19 with value: 0.36740957414352104.\nnum_leaves, val_score: 0.367410:  70%|#######   | 14/20 [00:56&lt;00:18,  3.10s/it]</pre> <pre>Early stopping, best iteration is:\n[103]\tvalid_0's binary_logloss: 0.381562\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.367410:  75%|#######5  | 15/20 [00:59&lt;00:15,  3.01s/it][I 2024-05-17 10:15:15,610] Trial 21 finished with value: 0.3792670191593437 and parameters: {'num_leaves': 116}. Best is trial 19 with value: 0.36740957414352104.\nnum_leaves, val_score: 0.367410:  75%|#######5  | 15/20 [00:59&lt;00:15,  3.01s/it]</pre> <pre>Early stopping, best iteration is:\n[41]\tvalid_0's binary_logloss: 0.379267\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.367410:  80%|########  | 16/20 [01:02&lt;00:11,  2.98s/it][I 2024-05-17 10:15:18,526] Trial 22 finished with value: 0.37058611292960486 and parameters: {'num_leaves': 132}. Best is trial 19 with value: 0.36740957414352104.\nnum_leaves, val_score: 0.367410:  80%|########  | 16/20 [01:02&lt;00:11,  2.98s/it]</pre> <pre>Early stopping, best iteration is:\n[53]\tvalid_0's binary_logloss: 0.370586\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.367410:  85%|########5 | 17/20 [01:05&lt;00:08,  2.95s/it][I 2024-05-17 10:15:21,421] Trial 23 finished with value: 0.372527054012802 and parameters: {'num_leaves': 139}. Best is trial 19 with value: 0.36740957414352104.\nnum_leaves, val_score: 0.367410:  85%|########5 | 17/20 [01:05&lt;00:08,  2.95s/it]</pre> <pre>Early stopping, best iteration is:\n[49]\tvalid_0's binary_logloss: 0.372527\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.367410:  90%|######### | 18/20 [01:08&lt;00:05,  2.85s/it][I 2024-05-17 10:15:24,028] Trial 24 finished with value: 0.38036745420691503 and parameters: {'num_leaves': 64}. Best is trial 19 with value: 0.36740957414352104.\nnum_leaves, val_score: 0.367410:  90%|######### | 18/20 [01:08&lt;00:05,  2.85s/it]</pre> <pre>Early stopping, best iteration is:\n[105]\tvalid_0's binary_logloss: 0.380367\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.367410:  95%|#########5| 19/20 [01:11&lt;00:02,  2.96s/it][I 2024-05-17 10:15:27,232] Trial 25 finished with value: 0.3818090274252709 and parameters: {'num_leaves': 194}. Best is trial 19 with value: 0.36740957414352104.\nnum_leaves, val_score: 0.367410:  95%|#########5| 19/20 [01:11&lt;00:02,  2.96s/it]</pre> <pre>Early stopping, best iteration is:\n[37]\tvalid_0's binary_logloss: 0.381809\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>num_leaves, val_score: 0.367410: 100%|##########| 20/20 [01:14&lt;00:00,  3.15s/it][I 2024-05-17 10:15:30,831] Trial 26 finished with value: 0.37252705401280195 and parameters: {'num_leaves': 139}. Best is trial 19 with value: 0.36740957414352104.\nnum_leaves, val_score: 0.367410: 100%|##########| 20/20 [01:14&lt;00:00,  3.74s/it]\n</pre> <pre>Early stopping, best iteration is:\n[49]\tvalid_0's binary_logloss: 0.372527\n</pre> <pre>bagging, val_score: 0.367410:   0%|          | 0/10 [00:00&lt;?, ?it/s]</pre> <pre>Training until validation scores don't improve for 50 rounds\n</pre> <pre>bagging, val_score: 0.367410:  10%|#         | 1/10 [00:02&lt;00:19,  2.20s/it][I 2024-05-17 10:15:33,110] Trial 27 finished with value: 0.3954670757458217 and parameters: {'bagging_fraction': 0.6247871962774826, 'bagging_freq': 1}. Best is trial 27 with value: 0.3954670757458217.\nbagging, val_score: 0.367410:  10%|#         | 1/10 [00:02&lt;00:19,  2.20s/it]</pre> <pre>Early stopping, best iteration is:\n[26]\tvalid_0's binary_logloss: 0.395467\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>bagging, val_score: 0.367410:  20%|##        | 2/10 [00:04&lt;00:19,  2.43s/it][I 2024-05-17 10:15:35,712] Trial 28 finished with value: 0.383350674150879 and parameters: {'bagging_fraction': 0.923285663502434, 'bagging_freq': 7}. Best is trial 28 with value: 0.383350674150879.\nbagging, val_score: 0.367410:  20%|##        | 2/10 [00:04&lt;00:19,  2.43s/it]</pre> <pre>Early stopping, best iteration is:\n[53]\tvalid_0's binary_logloss: 0.383351\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>bagging, val_score: 0.367410:  30%|###       | 3/10 [00:07&lt;00:17,  2.47s/it][I 2024-05-17 10:15:38,221] Trial 29 finished with value: 0.37923553921285863 and parameters: {'bagging_fraction': 0.420843204313341, 'bagging_freq': 4}. Best is trial 29 with value: 0.37923553921285863.\nbagging, val_score: 0.367410:  30%|###       | 3/10 [00:07&lt;00:17,  2.47s/it]</pre> <pre>Early stopping, best iteration is:\n[48]\tvalid_0's binary_logloss: 0.379236\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>bagging, val_score: 0.367410:  40%|####      | 4/10 [00:10&lt;00:16,  2.75s/it][I 2024-05-17 10:15:41,400] Trial 30 finished with value: 0.37765693537413436 and parameters: {'bagging_fraction': 0.9878318604557115, 'bagging_freq': 7}. Best is trial 30 with value: 0.37765693537413436.\nbagging, val_score: 0.367410:  40%|####      | 4/10 [00:10&lt;00:16,  2.75s/it]</pre> <pre>Early stopping, best iteration is:\n[54]\tvalid_0's binary_logloss: 0.377657\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>bagging, val_score: 0.367410:  50%|#####     | 5/10 [00:13&lt;00:13,  2.78s/it][I 2024-05-17 10:15:44,233] Trial 31 finished with value: 0.37280801864840957 and parameters: {'bagging_fraction': 0.7481148208250323, 'bagging_freq': 2}. Best is trial 31 with value: 0.37280801864840957.\nbagging, val_score: 0.367410:  50%|#####     | 5/10 [00:13&lt;00:13,  2.78s/it]</pre> <pre>Early stopping, best iteration is:\n[49]\tvalid_0's binary_logloss: 0.372808\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>bagging, val_score: 0.367410:  60%|######    | 6/10 [00:14&lt;00:09,  2.38s/it][I 2024-05-17 10:15:45,825] Trial 32 finished with value: 0.3842362749848752 and parameters: {'bagging_fraction': 0.4391676469093167, 'bagging_freq': 4}. Best is trial 31 with value: 0.37280801864840957.\nbagging, val_score: 0.367410:  60%|######    | 6/10 [00:14&lt;00:09,  2.38s/it]</pre> <pre>Early stopping, best iteration is:\n[19]\tvalid_0's binary_logloss: 0.384236\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>bagging, val_score: 0.367410:  70%|#######   | 7/10 [00:17&lt;00:07,  2.38s/it][I 2024-05-17 10:15:48,226] Trial 33 finished with value: 0.38045738974897325 and parameters: {'bagging_fraction': 0.7379269104820864, 'bagging_freq': 5}. Best is trial 31 with value: 0.37280801864840957.\nbagging, val_score: 0.367410:  70%|#######   | 7/10 [00:17&lt;00:07,  2.38s/it]</pre> <pre>Early stopping, best iteration is:\n[46]\tvalid_0's binary_logloss: 0.380457\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>bagging, val_score: 0.367410:  80%|########  | 8/10 [00:20&lt;00:05,  2.55s/it][I 2024-05-17 10:15:51,131] Trial 34 finished with value: 0.39307944210588885 and parameters: {'bagging_fraction': 0.5892054794337009, 'bagging_freq': 2}. Best is trial 31 with value: 0.37280801864840957.\nbagging, val_score: 0.367410:  80%|########  | 8/10 [00:20&lt;00:05,  2.55s/it]</pre> <pre>Early stopping, best iteration is:\n[70]\tvalid_0's binary_logloss: 0.393079\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>bagging, val_score: 0.367410:  90%|######### | 9/10 [00:23&lt;00:02,  2.75s/it][I 2024-05-17 10:15:54,323] Trial 35 finished with value: 0.37565759644445834 and parameters: {'bagging_fraction': 0.8753010476839909, 'bagging_freq': 5}. Best is trial 31 with value: 0.37280801864840957.\nbagging, val_score: 0.367410:  90%|######### | 9/10 [00:23&lt;00:02,  2.75s/it]</pre> <pre>Early stopping, best iteration is:\n[61]\tvalid_0's binary_logloss: 0.375658\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>bagging, val_score: 0.367410: 100%|##########| 10/10 [00:25&lt;00:00,  2.64s/it][I 2024-05-17 10:15:56,727] Trial 36 finished with value: 0.38695330483645435 and parameters: {'bagging_fraction': 0.5402623279814973, 'bagging_freq': 3}. Best is trial 31 with value: 0.37280801864840957.\nbagging, val_score: 0.367410: 100%|##########| 10/10 [00:25&lt;00:00,  2.58s/it]\n</pre> <pre>Early stopping, best iteration is:\n[54]\tvalid_0's binary_logloss: 0.386953\n</pre> <pre>feature_fraction_stage2, val_score: 0.367410:   0%|          | 0/6 [00:00&lt;?, ?it/s]</pre> <pre>Training until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction_stage2, val_score: 0.367410:  17%|#6        | 1/6 [00:02&lt;00:14,  2.91s/it][I 2024-05-17 10:15:59,715] Trial 37 finished with value: 0.3750569994664222 and parameters: {'feature_fraction': 0.88}. Best is trial 37 with value: 0.3750569994664222.\nfeature_fraction_stage2, val_score: 0.367410:  17%|#6        | 1/6 [00:02&lt;00:14,  2.91s/it]</pre> <pre>Early stopping, best iteration is:\n[75]\tvalid_0's binary_logloss: 0.375057\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction_stage2, val_score: 0.367410:  33%|###3      | 2/6 [00:07&lt;00:15,  3.84s/it][I 2024-05-17 10:16:04,209] Trial 38 finished with value: 0.36740957414352116 and parameters: {'feature_fraction': 0.784}. Best is trial 38 with value: 0.36740957414352116.\nfeature_fraction_stage2, val_score: 0.367410:  33%|###3      | 2/6 [00:07&lt;00:15,  3.84s/it]</pre> <pre>Early stopping, best iteration is:\n[75]\tvalid_0's binary_logloss: 0.36741\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction_stage2, val_score: 0.367410:  50%|#####     | 3/6 [00:10&lt;00:10,  3.42s/it][I 2024-05-17 10:16:07,121] Trial 39 finished with value: 0.37661326532050776 and parameters: {'feature_fraction': 0.7520000000000001}. Best is trial 38 with value: 0.36740957414352116.\nfeature_fraction_stage2, val_score: 0.367410:  50%|#####     | 3/6 [00:10&lt;00:10,  3.42s/it]</pre> <pre>Early stopping, best iteration is:\n[80]\tvalid_0's binary_logloss: 0.376613\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction_stage2, val_score: 0.367410:  67%|######6   | 4/6 [00:18&lt;00:10,  5.27s/it][I 2024-05-17 10:16:15,229] Trial 40 finished with value: 0.3766132653205076 and parameters: {'feature_fraction': 0.7200000000000001}. Best is trial 38 with value: 0.36740957414352116.\nfeature_fraction_stage2, val_score: 0.367410:  67%|######6   | 4/6 [00:18&lt;00:10,  5.27s/it]</pre> <pre>Early stopping, best iteration is:\n[80]\tvalid_0's binary_logloss: 0.376613\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction_stage2, val_score: 0.367410:  83%|########3 | 5/6 [00:24&lt;00:05,  5.57s/it][I 2024-05-17 10:16:21,324] Trial 41 finished with value: 0.37205822085312645 and parameters: {'feature_fraction': 0.8160000000000001}. Best is trial 38 with value: 0.36740957414352116.\nfeature_fraction_stage2, val_score: 0.367410:  83%|########3 | 5/6 [00:24&lt;00:05,  5.57s/it]</pre> <pre>Early stopping, best iteration is:\n[48]\tvalid_0's binary_logloss: 0.372058\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>feature_fraction_stage2, val_score: 0.367410: 100%|##########| 6/6 [00:33&lt;00:00,  6.63s/it][I 2024-05-17 10:16:30,027] Trial 42 finished with value: 0.375056999466422 and parameters: {'feature_fraction': 0.8480000000000001}. Best is trial 38 with value: 0.36740957414352116.\nfeature_fraction_stage2, val_score: 0.367410: 100%|##########| 6/6 [00:33&lt;00:00,  5.54s/it]\n</pre> <pre>Early stopping, best iteration is:\n[75]\tvalid_0's binary_logloss: 0.375057\n</pre> <pre>regularization_factors, val_score: 0.367410:   0%|          | 0/20 [00:00&lt;?, ?it/s]</pre> <pre>Training until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:   5%|5         | 1/20 [00:04&lt;01:19,  4.20s/it][I 2024-05-17 10:16:34,305] Trial 43 finished with value: 0.4000754351948232 and parameters: {'lambda_l1': 9.735476402093866, 'lambda_l2': 1.1885650284878641e-05}. Best is trial 43 with value: 0.4000754351948232.\nregularization_factors, val_score: 0.367410:   5%|5         | 1/20 [00:04&lt;01:19,  4.20s/it]</pre> <pre>Early stopping, best iteration is:\n[175]\tvalid_0's binary_logloss: 0.400075\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  10%|#         | 2/20 [00:06&lt;00:59,  3.33s/it][I 2024-05-17 10:16:37,029] Trial 44 finished with value: 0.3842358602524559 and parameters: {'lambda_l1': 1.3624272314789979e-08, 'lambda_l2': 4.53719639040893}. Best is trial 44 with value: 0.3842358602524559.\nregularization_factors, val_score: 0.367410:  10%|#         | 2/20 [00:06&lt;00:59,  3.33s/it]</pre> <pre>Early stopping, best iteration is:\n[63]\tvalid_0's binary_logloss: 0.384236\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  15%|#5        | 3/20 [00:09&lt;00:51,  3.04s/it][I 2024-05-17 10:16:39,718] Trial 45 finished with value: 0.3768392688529174 and parameters: {'lambda_l1': 0.0006052551309667524, 'lambda_l2': 1.0805462176025796e-08}. Best is trial 45 with value: 0.3768392688529174.\nregularization_factors, val_score: 0.367410:  15%|#5        | 3/20 [00:09&lt;00:51,  3.04s/it]</pre> <pre>Early stopping, best iteration is:\n[59]\tvalid_0's binary_logloss: 0.376839\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  20%|##        | 4/20 [00:13&lt;00:52,  3.26s/it][I 2024-05-17 10:16:43,314] Trial 46 finished with value: 0.38300850920886864 and parameters: {'lambda_l1': 1.8958239622988977e-08, 'lambda_l2': 6.020371560207324}. Best is trial 45 with value: 0.3768392688529174.\nregularization_factors, val_score: 0.367410:  20%|##        | 4/20 [00:13&lt;00:52,  3.26s/it]</pre> <pre>Early stopping, best iteration is:\n[102]\tvalid_0's binary_logloss: 0.383009\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  25%|##5       | 5/20 [00:15&lt;00:45,  3.03s/it][I 2024-05-17 10:16:45,926] Trial 47 finished with value: 0.3979727901107469 and parameters: {'lambda_l1': 9.028443418520673, 'lambda_l2': 0.0008471787212032551}. Best is trial 45 with value: 0.3768392688529174.\nregularization_factors, val_score: 0.367410:  25%|##5       | 5/20 [00:15&lt;00:45,  3.03s/it]</pre> <pre>Early stopping, best iteration is:\n[176]\tvalid_0's binary_logloss: 0.397973\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  30%|###       | 6/20 [00:18&lt;00:38,  2.78s/it][I 2024-05-17 10:16:48,219] Trial 48 finished with value: 0.38142112717658005 and parameters: {'lambda_l1': 0.0002499516385751432, 'lambda_l2': 0.0010381660654697966}. Best is trial 45 with value: 0.3768392688529174.\nregularization_factors, val_score: 0.367410:  30%|###       | 6/20 [00:18&lt;00:38,  2.78s/it]</pre> <pre>Early stopping, best iteration is:\n[43]\tvalid_0's binary_logloss: 0.381421\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  35%|###5      | 7/20 [00:20&lt;00:36,  2.79s/it][I 2024-05-17 10:16:51,026] Trial 49 finished with value: 0.3827689612973024 and parameters: {'lambda_l1': 0.00010166999713623285, 'lambda_l2': 1.606135170483702e-08}. Best is trial 45 with value: 0.3768392688529174.\nregularization_factors, val_score: 0.367410:  35%|###5      | 7/20 [00:20&lt;00:36,  2.79s/it]</pre> <pre>Early stopping, best iteration is:\n[68]\tvalid_0's binary_logloss: 0.382769\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  40%|####      | 8/20 [00:23&lt;00:34,  2.85s/it][I 2024-05-17 10:16:54,004] Trial 50 finished with value: 0.3717680065875255 and parameters: {'lambda_l1': 0.05452714002013461, 'lambda_l2': 4.088790430612965e-06}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410:  40%|####      | 8/20 [00:23&lt;00:34,  2.85s/it]</pre> <pre>Early stopping, best iteration is:\n[72]\tvalid_0's binary_logloss: 0.371768\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  45%|####5     | 9/20 [00:26&lt;00:29,  2.72s/it][I 2024-05-17 10:16:56,427] Trial 51 finished with value: 0.3761342067809677 and parameters: {'lambda_l1': 0.0369066143307944, 'lambda_l2': 3.2663806162439897e-06}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410:  45%|####5     | 9/20 [00:26&lt;00:29,  2.72s/it]</pre> <pre>Early stopping, best iteration is:\n[54]\tvalid_0's binary_logloss: 0.376134\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  50%|#####     | 10/20 [00:29&lt;00:27,  2.74s/it][I 2024-05-17 10:16:59,219] Trial 52 finished with value: 0.37432924731676614 and parameters: {'lambda_l1': 0.054816809029998775, 'lambda_l2': 0.024999499348712872}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410:  50%|#####     | 10/20 [00:29&lt;00:27,  2.74s/it]</pre> <pre>Early stopping, best iteration is:\n[70]\tvalid_0's binary_logloss: 0.374329\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  55%|#####5    | 11/20 [00:32&lt;00:25,  2.79s/it][I 2024-05-17 10:17:02,121] Trial 53 finished with value: 0.3802377964900833 and parameters: {'lambda_l1': 2.316914347130571e-06, 'lambda_l2': 5.795374367862176e-06}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410:  55%|#####5    | 11/20 [00:32&lt;00:25,  2.79s/it]</pre> <pre>Early stopping, best iteration is:\n[65]\tvalid_0's binary_logloss: 0.380238\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  60%|######    | 12/20 [00:34&lt;00:21,  2.73s/it][I 2024-05-17 10:17:04,708] Trial 54 finished with value: 0.3824576314527321 and parameters: {'lambda_l1': 0.06822102509516187, 'lambda_l2': 8.792255957217181e-07}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410:  60%|######    | 12/20 [00:34&lt;00:21,  2.73s/it]</pre> <pre>Early stopping, best iteration is:\n[59]\tvalid_0's binary_logloss: 0.382458\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  65%|######5   | 13/20 [00:37&lt;00:19,  2.78s/it][I 2024-05-17 10:17:07,622] Trial 55 finished with value: 0.3746797506374062 and parameters: {'lambda_l1': 0.004203813235193917, 'lambda_l2': 0.0746628734826108}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410:  65%|######5   | 13/20 [00:37&lt;00:19,  2.78s/it]</pre> <pre>Early stopping, best iteration is:\n[80]\tvalid_0's binary_logloss: 0.37468\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  70%|#######   | 14/20 [00:40&lt;00:16,  2.79s/it][I 2024-05-17 10:17:10,426] Trial 56 finished with value: 0.380237800076126 and parameters: {'lambda_l1': 3.697476359113887e-06, 'lambda_l2': 2.228738169703633e-07}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410:  70%|#######   | 14/20 [00:40&lt;00:16,  2.79s/it]</pre> <pre>Early stopping, best iteration is:\n[65]\tvalid_0's binary_logloss: 0.380238\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  75%|#######5  | 15/20 [00:43&lt;00:14,  2.88s/it][I 2024-05-17 10:17:13,525] Trial 57 finished with value: 0.3819070958826241 and parameters: {'lambda_l1': 0.810771895442005, 'lambda_l2': 6.377701924975795e-05}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410:  75%|#######5  | 15/20 [00:43&lt;00:14,  2.88s/it]</pre> <pre>Early stopping, best iteration is:\n[80]\tvalid_0's binary_logloss: 0.381907\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  80%|########  | 16/20 [00:46&lt;00:11,  2.95s/it][I 2024-05-17 10:17:16,619] Trial 58 finished with value: 0.3722284134939273 and parameters: {'lambda_l1': 7.86173966634575e-06, 'lambda_l2': 0.009668553543780791}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410:  80%|########  | 16/20 [00:46&lt;00:11,  2.95s/it]</pre> <pre>Early stopping, best iteration is:\n[80]\tvalid_0's binary_logloss: 0.372228\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  85%|########5 | 17/20 [00:48&lt;00:08,  2.73s/it][I 2024-05-17 10:17:18,897] Trial 59 finished with value: 0.3728074176393718 and parameters: {'lambda_l1': 0.6306947740321641, 'lambda_l2': 1.013819292434261e-07}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410:  85%|########5 | 17/20 [00:48&lt;00:08,  2.73s/it]</pre> <pre>Early stopping, best iteration is:\n[56]\tvalid_0's binary_logloss: 0.372807\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  90%|######### | 18/20 [00:50&lt;00:05,  2.57s/it][I 2024-05-17 10:17:21,098] Trial 60 finished with value: 0.383089180978512 and parameters: {'lambda_l1': 0.005507471755818934, 'lambda_l2': 5.575100781579365e-05}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410:  90%|######### | 18/20 [00:50&lt;00:05,  2.57s/it]</pre> <pre>Early stopping, best iteration is:\n[39]\tvalid_0's binary_logloss: 0.383089\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410:  95%|#########5| 19/20 [00:53&lt;00:02,  2.69s/it][I 2024-05-17 10:17:24,001] Trial 61 finished with value: 0.37251331352332 and parameters: {'lambda_l1': 2.1575640685639232e-07, 'lambda_l2': 0.5104002702883277}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410:  95%|#########5| 19/20 [00:53&lt;00:02,  2.69s/it]</pre> <pre>Early stopping, best iteration is:\n[65]\tvalid_0's binary_logloss: 0.372513\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>regularization_factors, val_score: 0.367410: 100%|##########| 20/20 [00:56&lt;00:00,  2.64s/it][I 2024-05-17 10:17:26,515] Trial 62 finished with value: 0.3751039420293567 and parameters: {'lambda_l1': 0.8971910981660706, 'lambda_l2': 0.00011633445362150633}. Best is trial 50 with value: 0.3717680065875255.\nregularization_factors, val_score: 0.367410: 100%|##########| 20/20 [00:56&lt;00:00,  2.82s/it]\n</pre> <pre>Early stopping, best iteration is:\n[66]\tvalid_0's binary_logloss: 0.375104\n</pre> <pre>min_child_samples, val_score: 0.367410:   0%|          | 0/5 [00:00&lt;?, ?it/s]</pre> <pre>Training until validation scores don't improve for 50 rounds\n</pre> <pre>min_child_samples, val_score: 0.367410:  20%|##        | 1/5 [00:07&lt;00:31,  7.91s/it][I 2024-05-17 10:17:34,430] Trial 63 finished with value: 0.37088802049847946 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.37088802049847946.\nmin_child_samples, val_score: 0.367410:  20%|##        | 1/5 [00:07&lt;00:31,  7.91s/it]</pre> <pre>Early stopping, best iteration is:\n[54]\tvalid_0's binary_logloss: 0.370888\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>min_child_samples, val_score: 0.367410:  40%|####      | 2/5 [00:10&lt;00:14,  4.77s/it][I 2024-05-17 10:17:37,008] Trial 64 finished with value: 0.3893329770050149 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.37088802049847946.\nmin_child_samples, val_score: 0.367410:  40%|####      | 2/5 [00:10&lt;00:14,  4.77s/it]</pre> <pre>Early stopping, best iteration is:\n[68]\tvalid_0's binary_logloss: 0.389333\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>min_child_samples, val_score: 0.367410:  60%|######    | 3/5 [00:13&lt;00:07,  3.88s/it][I 2024-05-17 10:17:39,898] Trial 65 finished with value: 0.3788845205095279 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.37088802049847946.\nmin_child_samples, val_score: 0.367410:  60%|######    | 3/5 [00:13&lt;00:07,  3.88s/it]</pre> <pre>Early stopping, best iteration is:\n[68]\tvalid_0's binary_logloss: 0.378885\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>min_child_samples, val_score: 0.367410:  80%|########  | 4/5 [00:15&lt;00:03,  3.21s/it][I 2024-05-17 10:17:42,014] Trial 66 finished with value: 0.39615198116336536 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.37088802049847946.\nmin_child_samples, val_score: 0.367410:  80%|########  | 4/5 [00:15&lt;00:03,  3.21s/it]</pre> <pre>Early stopping, best iteration is:\n[97]\tvalid_0's binary_logloss: 0.396152\nTraining until validation scores don't improve for 50 rounds\n</pre> <pre>min_child_samples, val_score: 0.367410: 100%|##########| 5/5 [00:17&lt;00:00,  2.92s/it][I 2024-05-17 10:17:44,414] Trial 67 finished with value: 0.3804781158926489 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.37088802049847946.\nmin_child_samples, val_score: 0.367410: 100%|##########| 5/5 [00:17&lt;00:00,  3.58s/it]</pre> <pre>Early stopping, best iteration is:\n[55]\tvalid_0's binary_logloss: 0.380478\n</pre> <pre>\n</pre> In\u00a0[9]: Copied! <pre># save/load trainer\ndill_dump(\"lgbm_trainer.dill\", trainer)\ntrainer = dill_load(\"lgbm_trainer.dill\")\n</pre> # save/load trainer dill_dump(\"lgbm_trainer.dill\", trainer) trainer = dill_load(\"lgbm_trainer.dill\") In\u00a0[10]: Copied! <pre>pprint(metrics_dict)\n</pre> pprint(metrics_dict) <pre>{'cls_report': {'0': {'f1-score': 0.9218559218559219,\n                      'precision': 0.8966745843230404,\n                      'recall': 0.9484924623115578,\n                      'support': 796},\n                '1': {'f1-score': 0.6464088397790054,\n                      'precision': 0.740506329113924,\n                      'recall': 0.5735294117647058,\n                      'support': 204},\n                'accuracy': 0.872,\n                'macro avg': {'f1-score': 0.7841323808174636,\n                              'precision': 0.8185904567184822,\n                              'recall': 0.7610109370381318,\n                              'support': 1000},\n                'weighted avg': {'f1-score': 0.8656647171122308,\n                                 'precision': 0.8648162602603806,\n                                 'recall': 0.872,\n                                 'support': 1000}},\n 'cm': [[755, 41], [87, 117]],\n 'prec_rec_curve': [[0.204, 0.740506329113924, 1.0],\n                    [1.0, 0.5735294117647058, 0.0],\n                    [0.0, 1.0]]}\n</pre> In\u00a0[11]: Copied! <pre>pprint(trainer.compute_metrics(df_test, with_dynamic_binary_threshold=True))\n</pre> pprint(trainer.compute_metrics(df_test, with_dynamic_binary_threshold=True)) <pre>{'cls_report': {'0': {'f1-score': 0.9244823386114495,\n                      'precision': 0.8971631205673759,\n                      'recall': 0.9535175879396985,\n                      'support': 796},\n                '1': {'f1-score': 0.6536312849162011,\n                      'precision': 0.7597402597402597,\n                      'recall': 0.5735294117647058,\n                      'support': 204},\n                'accuracy': 0.876,\n                'macro avg': {'f1-score': 0.7890568117638252,\n                              'precision': 0.8284516901538178,\n                              'recall': 0.7635234998522022,\n                              'support': 1000},\n                'weighted avg': {'f1-score': 0.8692287236576187,\n                                 'precision': 0.8691288569586443,\n                                 'recall': 0.876,\n                                 'support': 1000}},\n 'cm': [[759, 37], [87, 117]],\n 'prec_rec_curve': [[0.204, 0.7597402597402597, 1.0],\n                    [1.0, 0.5735294117647058, 0.0],\n                    [0.0, 1.0]]}\n</pre> In\u00a0[12]: Copied! <pre>mlflow_host = \"10.152.183.54\"\nmlflow_host_url = \"mlflow.mlflow.svc.cluster.local\"\nmlflow_port = \"5000\"\nos.environ[\"AWS_ACCESS_KEY_ID\"] = \"minioadmin\"\nos.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin\"\nos.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = f\"http://10.152.183.156:9000\"\n\nmlflow.set_tracking_uri(\"http://\" + mlflow_host + \":\" + mlflow_port)\nexperiment_id = get_or_create_experiment(\"ecovadis_assignment\")\nmlflow.set_experiment(experiment_id=experiment_id)\n</pre> mlflow_host = \"10.152.183.54\" mlflow_host_url = \"mlflow.mlflow.svc.cluster.local\" mlflow_port = \"5000\" os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minioadmin\" os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin\" os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = f\"http://10.152.183.156:9000\"  mlflow.set_tracking_uri(\"http://\" + mlflow_host + \":\" + mlflow_port) experiment_id = get_or_create_experiment(\"ecovadis_assignment\") mlflow.set_experiment(experiment_id=experiment_id) Out[12]: <pre>&lt;Experiment: artifact_location='s3://mlflow/2', creation_time=1715939157478, experiment_id='2', last_update_time=1715939157478, lifecycle_stage='active', name='ecovadis_assignment', tags={}&gt;</pre> In\u00a0[13]: Copied! <pre>metrics_dict_flattened = flatten_dict(metrics_dict)\n</pre> metrics_dict_flattened = flatten_dict(metrics_dict) In\u00a0[14]: Copied! <pre># mlflow metrics can be only int, float not list\ndel metrics_dict_flattened[\"cm\"]\ndel metrics_dict_flattened[\"prec_rec_curve\"]\n</pre> # mlflow metrics can be only int, float not list del metrics_dict_flattened[\"cm\"] del metrics_dict_flattened[\"prec_rec_curve\"] In\u00a0[15]: Copied! <pre>run_name = \"init_run\"\nwith mlflow.start_run(\n    experiment_id=experiment_id, run_name=run_name, nested=True\n) as run:\n    mlflow.log_params(trainer.optimizer.best)\n    mlflow.log_metrics(metrics_dict_flattened)\n\n    # Log tags\n    mlflow.set_tags(\n        tags={\n            \"project\": \"SUCCESS6G\",\n            \"optimizer_engine\": \"optuna\",\n            \"model_family\": \"ligtgbm\",\n            \"feature_set_version\": 1,\n        }\n    )\n    # Log figure - for future fun\n    # mlflow.log_figure(figure=correlation_plot, artifact_file=\"correlation_plot.png\")\n\n    artifact_path = \"ecovadis_model\"\n    registered_model_name = \"ecovadis_lgbm_model\"\n    mlflow.pyfunc.log_model(\n        python_model=trainer,\n        artifact_path=artifact_path,\n        registered_model_name=registered_model_name,\n    )\n    model_uri = mlflow.get_artifact_uri(artifact_path)\n    print(f\"Run ID:\\n{run.info.run_id}\\nModel uri:\\n{model_uri}\")\n</pre> run_name = \"init_run\" with mlflow.start_run(     experiment_id=experiment_id, run_name=run_name, nested=True ) as run:     mlflow.log_params(trainer.optimizer.best)     mlflow.log_metrics(metrics_dict_flattened)      # Log tags     mlflow.set_tags(         tags={             \"project\": \"SUCCESS6G\",             \"optimizer_engine\": \"optuna\",             \"model_family\": \"ligtgbm\",             \"feature_set_version\": 1,         }     )     # Log figure - for future fun     # mlflow.log_figure(figure=correlation_plot, artifact_file=\"correlation_plot.png\")      artifact_path = \"ecovadis_model\"     registered_model_name = \"ecovadis_lgbm_model\"     mlflow.pyfunc.log_model(         python_model=trainer,         artifact_path=artifact_path,         registered_model_name=registered_model_name,     )     model_uri = mlflow.get_artifact_uri(artifact_path)     print(f\"Run ID:\\n{run.info.run_id}\\nModel uri:\\n{model_uri}\") <pre>2024/05/17 10:18:43 INFO mlflow.types.utils: Unsupported type hint: &lt;class 'pandas.core.frame.DataFrame'&gt;, skipping schema inference\n2024/05/17 10:18:43 INFO mlflow.types.utils: Unsupported type hint: &lt;class 'pandas.core.frame.DataFrame'&gt;, skipping schema inference\nRegistered model 'ecovadis_lgbm_model' already exists. Creating a new version of this model...\n2024/05/17 10:18:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ecovadis_lgbm_model, version 2\n</pre> <pre>Run ID:\n18b4ab4d40bb4476b2cbb70b4b6a72a0\nModel uri:\ns3://mlflow/2/18b4ab4d40bb4476b2cbb70b4b6a72a0/artifacts/ecovadis_model\n</pre> <pre>Created version '2' of model 'ecovadis_lgbm_model'.\n</pre> In\u00a0[16]: Copied! <pre>df_pd.iloc[:2]\n</pre> df_pd.iloc[:2] Out[16]: CustomerId CreditScore Country Gender Age Tenure Balance (EUR) NumberOfProducts HasCreditCard IsActiveMember EstimatedSalary Exited CustomerFeedback_sentiment3 CustomerFeedback_sentiment5 Surname_Country Surname_Country_region Surname_Country_subregion Country_region Country_subregion is_native Country_hemisphere Country_gdp_per_capita Country_IncomeGroup Surname_Country_gdp_per_capita Surname_Country_IncomeGroup working_class stage_of_life generation 0 15787619 844 France Male 18 2 160980.03 1 0 0 145936.28 0 neutral 4 stars Taiwan Asia Eastern Asia Europe Western Europe 0 northern 57594.03402 High income 32756.00000 None working_age teen gen_z 1 15770309 656 France Male 18 10 151762.74 1 0 1 127014.32 0 neutral 1 star United States Americas Northern America Europe Western Europe 0 northern 57594.03402 High income 76329.58227 High income working_age teen gen_z In\u00a0[17]: Copied! <pre>df_pd.iloc[:2].transpose().to_dict(orient=\"index\")\n</pre> df_pd.iloc[:2].transpose().to_dict(orient=\"index\") Out[17]: <pre>{'CustomerId': {0: 15787619, 1: 15770309},\n 'CreditScore': {0: 844, 1: 656},\n 'Country': {0: 'France', 1: 'France'},\n 'Gender': {0: 'Male', 1: 'Male'},\n 'Age': {0: 18, 1: 18},\n 'Tenure': {0: 2, 1: 10},\n 'Balance (EUR)': {0: 160980.03, 1: 151762.74},\n 'NumberOfProducts': {0: 1, 1: 1},\n 'HasCreditCard': {0: '0', 1: '0'},\n 'IsActiveMember': {0: '0', 1: '1'},\n 'EstimatedSalary': {0: 145936.28, 1: 127014.32},\n 'Exited': {0: 0, 1: 0},\n 'CustomerFeedback_sentiment3': {0: 'neutral', 1: 'neutral'},\n 'CustomerFeedback_sentiment5': {0: '4 stars', 1: '1 star'},\n 'Surname_Country': {0: 'Taiwan', 1: 'United States'},\n 'Surname_Country_region': {0: 'Asia', 1: 'Americas'},\n 'Surname_Country_subregion': {0: 'Eastern Asia', 1: 'Northern America'},\n 'Country_region': {0: 'Europe', 1: 'Europe'},\n 'Country_subregion': {0: 'Western Europe', 1: 'Western Europe'},\n 'is_native': {0: '0', 1: '0'},\n 'Country_hemisphere': {0: 'northern', 1: 'northern'},\n 'Country_gdp_per_capita': {0: 57594.03402, 1: 57594.03402},\n 'Country_IncomeGroup': {0: 'High income', 1: 'High income'},\n 'Surname_Country_gdp_per_capita': {0: 32756.0, 1: 76329.58227},\n 'Surname_Country_IncomeGroup': {0: 'None', 1: 'High income'},\n 'working_class': {0: 'working_age', 1: 'working_age'},\n 'stage_of_life': {0: 'teen', 1: 'teen'},\n 'generation': {0: 'gen_z', 1: 'gen_z'}}</pre> <p>after some notepad magic:</p> <pre><code>{\n    \"CustomerId\": [15787619, 15770309],\n    \"CreditScore\": [844, 656],\n    \"Country\": [\"France\", \"France\"],\n    \"Gender\": [\"Male\", \"Male\"],\n    \"Age\": [18, 18],\n    \"Tenure\": [2, 10],\n    \"Balance (EUR)\": [160980.03, 151762.74],\n    \"NumberOfProducts\": [1, 1],\n    \"HasCreditCard\": [\"0\", \"0\"],\n    \"IsActiveMember\": [\"0\", \"1\"],\n    \"EstimatedSalary\": [145936.28, 127014.32],\n    \"Exited\": [0, 0],\n    \"CustomerFeedback_sentiment3\": [\"neutral\", \"neutral\"],\n    \"CustomerFeedback_sentiment5\": [\"4 stars\", \"1 star\"],\n    \"Surname_Country\": [\"Taiwan\", \"United States\"],\n    \"Surname_Country_region\": [\"Asia\", \"Americas\"],\n    \"Surname_Country_subregion\": [\"Eastern Asia\", \"Northern America\"],\n    \"Country_region\": [\"Europe\", \"Europe\"],\n    \"Country_subregion\": [\"Western Europe\", \"Western Europe\"],\n    \"is_native\": [\"0\", \"0\"],\n    \"Country_hemisphere\": [\"northern\", \"northern\"],\n    \"Country_gdp_per_capita\": [57594.03402, 57594.03402],\n    \"Country_IncomeGroup\": [\"High income\", \"High income\"],\n    \"Surname_Country_gdp_per_capita\": [32756.0, 76329.58227],\n    \"Surname_Country_IncomeGroup\": [\"None\", \"High income\"],\n    \"working_class\": [\"working_age\", \"working_age\"],\n    \"stage_of_life\": [\"teen\", \"teen\"],\n    \"generation\": [\"gen_z\", \"gen_z\"],\n}\n</code></pre> In\u00a0[18]: Copied! <pre>trainer.predict(df=df_pd.iloc[:2].drop(columns=[\"Exited\"]), context={})\n</pre> trainer.predict(df=df_pd.iloc[:2].drop(columns=[\"Exited\"]), context={}) Out[18]: Exited 0 -17.300401 1 -15.238104 In\u00a0[19]: Copied! <pre>model_uri\n</pre> model_uri Out[19]: <pre>'s3://mlflow/2/18b4ab4d40bb4476b2cbb70b4b6a72a0/artifacts/ecovadis_model'</pre> In\u00a0[20]: Copied! <pre>loaded_trainer = mlflow.pyfunc.load_model(model_uri)\n</pre> loaded_trainer = mlflow.pyfunc.load_model(model_uri) <pre>Downloading artifacts:   0%|          | 0/9 [00:00&lt;?, ?it/s]</pre> In\u00a0[21]: Copied! <pre>loaded_trainer.predict(df_pd.iloc[:2].drop(columns=[\"Exited\"]))\n</pre> loaded_trainer.predict(df_pd.iloc[:2].drop(columns=[\"Exited\"])) Out[21]: Exited 0 -17.300401 1 -15.238104 In\u00a0[22]: Copied! <pre>model_uri\n</pre> model_uri Out[22]: <pre>'s3://mlflow/2/18b4ab4d40bb4476b2cbb70b4b6a72a0/artifacts/ecovadis_model'</pre> In\u00a0[23]: Copied! <pre>! mlflow models serve -m \"s3://mlflow/2/18b4ab4d40bb4476b2cbb70b4b6a72a0/artifacts/ecovadis_model\" --env-manager local -p 5000\n</pre> ! mlflow models serve -m \"s3://mlflow/2/18b4ab4d40bb4476b2cbb70b4b6a72a0/artifacts/ecovadis_model\" --env-manager local -p 5000 <pre>Downloading artifacts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00, 577.81it/s]\n2024/05/17 10:19:38 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\nDownloading artifacts: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:00&lt;00:00, 44.62it/s]\n2024/05/17 10:19:38 INFO mlflow.pyfunc.backend: === Running command 'exec gunicorn --timeout=60 -b 127.0.0.1:5000 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n[2024-05-17 10:19:39 +0000] [8811] [INFO] Starting gunicorn 22.0.0\n[2024-05-17 10:19:39 +0000] [8811] [INFO] Listening at: http://127.0.0.1:5000 (8811)\n[2024-05-17 10:19:39 +0000] [8811] [INFO] Using worker: sync\n[2024-05-17 10:19:39 +0000] [8812] [INFO] Booting worker with pid: 8812\n^C\n[2024-05-17 10:23:52 +0000] [8811] [INFO] Handling signal: int\n[2024-05-17 10:23:52 +0000] [8812] [INFO] Worker exiting (pid: 8812)\n</pre> <p>output from terminal:</p> <pre><code>root@jupyter-5uperpalo:~# curl -X POST -H \"Content-Type:application/json\" --data '{\"inputs\": {\"CustomerId\": [15787619, 15770309], \"CreditScore\": [844, 656], \"Country\": [\"France\", \"France\"], \"Gender\": [\"Male\", \"Male\"], \"Age\": [18, 18], \"Tenure\": [2, 10], \"Balance (EUR)\": [160980.03, 151762.74], \"NumberOfProducts\": [1, 1], \"HasCreditCard\": [\"0\", \"0\"], \"IsActiveMember\": [\"0\", \"1\"], \"EstimatedSalary\": [145936.28, 127014.32], \"CustomerFeedback_sentiment3\": [\"neutral\", \"neutral\"], \"CustomerFeedback_sentiment5\": [\"4 stars\", \"1 star\"], \"Surname_Country\": [\"Taiwan\", \"United States\"], \"Surname_Country_region\": [\"Asia\", \"Americas\"], \"Surname_Country_subregion\": [\"Eastern Asia\", \"Northern America\"], \"Country_region\": [\"Europe\", \"Europe\"], \"Country_subregion\": [\"Western Europe\", \"Western Europe\"], \"is_native\": [\"0\", \"0\"], \"Country_hemisphere\": [\"northern\", \"northern\"], \"Country_gdp_per_capita\": [57594.03402, 57594.03402], \"Country_IncomeGroup\": [\"High income\", \"High income\"], \"Surname_Country_gdp_per_capita\": [32756.0, 76329.58227], \"Surname_Country_IncomeGroup\": [\"None\", \"High income\"], \"working_class\": [\"working_age\", \"working_age\"], \"stage_of_life\": [\"teen\", \"teen\"], \"generation\": [\"gen_z\", \"gen_z\"]}}' http://127.0.0.1:5000/invocations\n{\"predictions\": [{\"Exited\": -17.300400783182656}, {\"Exited\": -15.2381037279264}]}\n</code></pre>"},{"location":"notebooks/04_model_training_pipeline.html#example-usage-notebook","title":"Example usage notebook\u00b6","text":"<p>Objects and functions in this notebook are listed with all paramaters to ilustrate their capabillities. Most of the paramaters have default values in the implementation</p>"},{"location":"notebooks/04_model_training_pipeline.html#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/04_model_training_pipeline.html#train-a-testing-model","title":"Train a testing model\u00b6","text":""},{"location":"notebooks/04_model_training_pipeline.html#mlflow","title":"Mlflow\u00b6","text":"<ul> <li>tracking</li> <li>model registration in Minio</li> </ul>"},{"location":"notebooks/04_model_training_pipeline.html#screenshots-from-mlflow-gui-nodeport-service-in-kubernetes","title":"Screenshots from MLflow GUI (Nodeport service in Kubernetes)\u00b6","text":""},{"location":"notebooks/04_model_training_pipeline.html#predictions-testing","title":"Predictions testing\u00b6","text":"<p>IMPORTANT: the predictions are in raw_score format(for testing to see if I get same predictions), i.e. strange numbers and not classes in t</p>"},{"location":"notebooks/04_model_training_pipeline.html#example-data","title":"Example data\u00b6","text":""},{"location":"notebooks/04_model_training_pipeline.html#trainer","title":"Trainer\u00b6","text":""},{"location":"notebooks/04_model_training_pipeline.html#downloaded-trainer","title":"Downloaded Trainer\u00b6","text":""},{"location":"notebooks/04_model_training_pipeline.html#downloadedserved-trainer","title":"Downloaded/Served Trainer\u00b6","text":"<ul> <li>i.e. testing model locally</li> </ul>"},{"location":"notebooks/04_model_training_pipeline.html#tbd-model-deployment-using-kserve","title":"[TBD] Model deployment using Kserve\u00b6","text":"<ul> <li>https://mlflow.org/docs/latest/deployment/deploy-model-to-kubernetes/tutorial.html?highlight=kserve#step-7-deploying-the-model-to-kserve</li> </ul> <p>Current ISSUE: the readiness probe is killing the pod: <code>Readiness probe failed: Get \"http://10.1.4.209:8012/\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)</code></p>"},{"location":"notebooks/05_model_analysis.html","title":"05_model_analysis.ipynb","text":"In\u00a0[1]: Copied! <pre>import os\nimport sys\n\nsys.path.append(os.getcwd())\nos.chdir(\"..\")\n\nimport pandas as pd\n\npd.set_option(\"display.max_columns\", 200)\npd.set_option(\"display.max_rows\", 300)\n</pre> import os import sys  sys.path.append(os.getcwd()) os.chdir(\"..\")  import pandas as pd  pd.set_option(\"display.max_columns\", 200) pd.set_option(\"display.max_rows\", 300) In\u00a0[2]: Copied! <pre>from churn_pred.utils import dill_load\nfrom churn_pred.training.utils import get_feature_importance\nfrom churn_pred.eda.target.analysis import correlation\nfrom churn_pred.eda.target.plotting import prob_distrib_per_class\nfrom sklearn.model_selection import train_test_split\nfrom pprint import pprint\nimport lightgbm as lgb\nfrom churn_pred.training.utils import to_lgbdataset\nimport shap\nimport warnings\nimport numpy as np\n</pre> from churn_pred.utils import dill_load from churn_pred.training.utils import get_feature_importance from churn_pred.eda.target.analysis import correlation from churn_pred.eda.target.plotting import prob_distrib_per_class from sklearn.model_selection import train_test_split from pprint import pprint import lightgbm as lgb from churn_pred.training.utils import to_lgbdataset import shap import warnings import numpy as np In\u00a0[3]: Copied! <pre>trainer = dill_load(\"data/model/lgbm_trainer.dill\")\n</pre> trainer = dill_load(\"data/model/lgbm_trainer.dill\") In\u00a0[4]: Copied! <pre>df_pd = pd.read_parquet(\"data/dataset_auxiliary_features_cleaned.parquet\")\ncat_cols = [\n    \"Country\",\n    \"Gender\",\n    \"HasCreditCard\",\n    \"IsActiveMember\",\n    \"CustomerFeedback_sentiment3\",\n    \"CustomerFeedback_sentiment5\",\n    \"Surname_Country\",\n    \"Surname_Country_region\",\n    \"Surname_Country_subregion\",\n    \"Country_region\",\n    \"Country_subregion\",\n    \"is_native\",\n    \"Country_hemisphere\",\n    \"Country_IncomeGroup\",\n    \"Surname_Country_IncomeGroup\",\n    \"working_class\",\n    \"stage_of_life\",\n    \"generation\",\n]\ndf_pd[cat_cols] = df_pd[cat_cols].astype(str)\n\nvalid_size = 0.2\ntest_size = 0.5\n\nrandom_state = 1\ndf_train, df_valid = train_test_split(\n    df_pd,\n    test_size=valid_size,\n    stratify=df_pd[trainer.target_col],\n    random_state=random_state,\n)\ndf_valid, df_test = train_test_split(\n    df_valid,\n    test_size=test_size,\n    stratify=df_valid[trainer.target_col],\n    random_state=random_state,\n)\n</pre> df_pd = pd.read_parquet(\"data/dataset_auxiliary_features_cleaned.parquet\") cat_cols = [     \"Country\",     \"Gender\",     \"HasCreditCard\",     \"IsActiveMember\",     \"CustomerFeedback_sentiment3\",     \"CustomerFeedback_sentiment5\",     \"Surname_Country\",     \"Surname_Country_region\",     \"Surname_Country_subregion\",     \"Country_region\",     \"Country_subregion\",     \"is_native\",     \"Country_hemisphere\",     \"Country_IncomeGroup\",     \"Surname_Country_IncomeGroup\",     \"working_class\",     \"stage_of_life\",     \"generation\", ] df_pd[cat_cols] = df_pd[cat_cols].astype(str)  valid_size = 0.2 test_size = 0.5  random_state = 1 df_train, df_valid = train_test_split(     df_pd,     test_size=valid_size,     stratify=df_pd[trainer.target_col],     random_state=random_state, ) df_valid, df_test = train_test_split(     df_valid,     test_size=test_size,     stratify=df_valid[trainer.target_col],     random_state=random_state, ) In\u00a0[5]: Copied! <pre>df_predicted_proba = trainer.predict_proba(\n    df=df_test.drop(columns=trainer.target_col), binary2d=False\n)\ndf_predicted_cls = trainer.predict_cls(df=df_test.drop(columns=trainer.target_col))\n</pre> df_predicted_proba = trainer.predict_proba(     df=df_test.drop(columns=trainer.target_col), binary2d=False ) df_predicted_cls = trainer.predict_cls(df=df_test.drop(columns=trainer.target_col)) In\u00a0[6]: Copied! <pre>lgb.plot_importance(trainer.model, importance_type=\"split\")\n# lgb.plot_importance(trainer.model, importance_type=\"gain\")\n</pre> lgb.plot_importance(trainer.model, importance_type=\"split\") # lgb.plot_importance(trainer.model, importance_type=\"gain\") Out[6]: <pre>&lt;Axes: title={'center': 'Feature importance'}, xlabel='Feature importance', ylabel='Features'&gt;</pre> In\u00a0[7]: Copied! <pre>fig = prob_distrib_per_class(\n    predicted_probs=df_predicted_proba.values.flatten(),\n    actual=df_test[trainer.target_col].values.flatten(),\n    task=\"binary\",\n)\n</pre> fig = prob_distrib_per_class(     predicted_probs=df_predicted_proba.values.flatten(),     actual=df_test[trainer.target_col].values.flatten(),     task=\"binary\", ) In\u00a0[8]: Copied! <pre>df_test_prep = trainer.preprocessors[0].transform(\n    df_test.drop(columns=[trainer.target_col])\n)\ndf_test_prep[trainer.target_col] = df_test[trainer.target_col].astype(int)\n\nlgb_test, _ = to_lgbdataset(\n    train=df_test_prep,\n    cat_cols=trainer.cat_cols,\n    target_col=trainer.target_col,\n    id_cols=trainer.id_cols,\n)\n</pre> df_test_prep = trainer.preprocessors[0].transform(     df_test.drop(columns=[trainer.target_col]) ) df_test_prep[trainer.target_col] = df_test[trainer.target_col].astype(int)  lgb_test, _ = to_lgbdataset(     train=df_test_prep,     cat_cols=trainer.cat_cols,     target_col=trainer.target_col,     id_cols=trainer.id_cols, ) In\u00a0[9]: Copied! <pre>base_value = trainer.model.predict(data=lgb_test.data, pred_contrib=True)\nshap_values = base_value[:, :-1]\nbase_value = np.mean(base_value[:, -1])\n</pre> base_value = trainer.model.predict(data=lgb_test.data, pred_contrib=True) shap_values = base_value[:, :-1] base_value = np.mean(base_value[:, -1]) In\u00a0[10]: Copied! <pre>shap.summary_plot(\n    shap_values, features=lgb_test.data, plot_type=\"dot\", sort=False, show=True\n)\n</pre> shap.summary_plot(     shap_values, features=lgb_test.data, plot_type=\"dot\", sort=False, show=True ) In\u00a0[11]: Copied! <pre>df_predicted_cls[28:30]\n</pre> df_predicted_cls[28:30] Out[11]: Exited 28 0 29 1 In\u00a0[12]: Copied! <pre>df_test.iloc[28:30]\n</pre> df_test.iloc[28:30] Out[12]: CustomerId CreditScore Country Gender Age Tenure Balance (EUR) NumberOfProducts HasCreditCard IsActiveMember EstimatedSalary Exited CustomerFeedback_sentiment3 CustomerFeedback_sentiment5 Surname_Country Surname_Country_region Surname_Country_subregion Country_region Country_subregion is_native Country_hemisphere Country_gdp_per_capita Country_IncomeGroup Surname_Country_gdp_per_capita Surname_Country_IncomeGroup working_class stage_of_life generation 9941 15714240 712 Spain Male 74 5 0.0 2 0 0 151425.82 0 neutral 2 stars Russian Federation Europe Eastern Europe Europe Southern Europe 0 northern 48685.49631 High income 34637.76172 Upper middle income elderly senior_adult boomers_1 7444 15658057 812 Spain Female 44 8 0.0 3 1 0 66926.83 1 neutral 1 star Italy Europe Southern Europe Europe Southern Europe 0 northern 48685.49631 High income 55442.07843 High income working_age middle_age_adult millennials In\u00a0[13]: Copied! <pre>shap_decision_plot = shap.decision_plot(\n    base_value=base_value,\n    shap_values=shap_values[28:30],\n    features=trainer.model.feature_name(),\n    feature_names=trainer.model.feature_name(),\n    # legend_labels=legend_labels,\n    link=\"logit\",\n    # row_index=0,\n    # feature_order=list(range(len(trainer.model.feature_name()))),\n)\n</pre> shap_decision_plot = shap.decision_plot(     base_value=base_value,     shap_values=shap_values[28:30],     features=trainer.model.feature_name(),     feature_names=trainer.model.feature_name(),     # legend_labels=legend_labels,     link=\"logit\",     # row_index=0,     # feature_order=list(range(len(trainer.model.feature_name()))), )"},{"location":"notebooks/05_model_analysis.html#model-analysis","title":"Model analysis\u00b6","text":""},{"location":"notebooks/05_model_analysis.html#model-feature-importance-and-certainty-of-the-model-in-predicting-classes-probability-density-per-class","title":"Model feature importance and \"certainty\" of the model in predicting classes - probability density per class\u00b6","text":""},{"location":"notebooks/05_model_analysis.html#shap-analysis","title":"SHAP analysis\u00b6","text":""}]}